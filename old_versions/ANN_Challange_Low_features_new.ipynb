{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy5OeJu9o8Rt"
      },
      "source": [
        "# üè¥‚Äç‚ò†Ô∏è Pirate Pain Classification Challenge\n",
        "\n",
        "> ‚öì *\"Even pirates feel pain ‚Äî let's teach the model to feel it too.\"*\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Table of Contents\n",
        "0. [README](#readme)  \n",
        "1. [Setup & Configuration](#setup)  \n",
        "2. [Data Loading](#data-loading)  \n",
        "3. [Import Libraries](#import-libraries)  \n",
        "4. [Data Preprocessing](#data-preprocessing)  \n",
        "5. [Sequence Building](#sequence-building)  \n",
        "6. [DataLoaders](#dataloaders)  \n",
        "7. [Network Hyperparameters](#hyperparameters)\n",
        "8. [Model Architecture](#model-architecture)  \n",
        "9. [Training Functions](#training-functions)  \n",
        "10. [Model Training](#model-training)  \n",
        "11. [Evaluation & Metrics](#evaluation)  \n",
        "12. [Model Loading & Final Testing](#model-loading)  \n",
        "13. [Competition Submission](#submission)\n",
        "\n",
        "---\n",
        "\n",
        "### ‚öôÔ∏è Quick Configuration Map\n",
        "\n",
        "> üß≠ *\"If ye seek to tweak the code, here be where to look!\"*\n",
        "\n",
        "- üß∫ **Batch Size:** ‚Üí [DataLoaders](#dataloaders)  \n",
        "- ‚öóÔ∏è **Hyperparameters:** ‚Üí [Network Hyperparameters](#hyperparameters)  \n",
        "- ü™û **Window Size & Stride:** ‚Üí [Sequence Building](#sequence-building)  \n",
        "- ‚öôÔ∏è **Model Type:** ‚Üí [Setup & Configuration](#setup)  \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### üí∞ Treasure Storage ‚Äî Models & Submissions\n",
        "> üè¥‚Äç‚ò†Ô∏è *\"A wise pirate always knows where his treasure be buried ‚Äî guard yer models and submissions well!\"*\n",
        "\n",
        "- üíæ **Model & Submission Save/Load Path:** ‚Üí [Setup & Configuration](#setup)  \n",
        "  - üóÇÔ∏è Models be saved in a **`models/`** folder with the name:\n",
        "    **`experiment_name_dd-mm-HH-MM.pt`** (day-month-hour-minute).\n",
        "  - üìú Submissions be saved in a **`submissions/`** folder with the filename format:  \n",
        "    **`experiment_name_dd-mm-HH-MM.csv`** .\n",
        "  - üî° All related model parameters are saved in **`models/`** folder with the  name **`experiment_name_dd-mm-HH-MM_config.json`** .\n",
        "\n",
        "  \n",
        "  *‚ùóThe experiment name is set as **`RnnType_Bi_dd-mm-HH-MM`** or **`RnnType_dd-mm-HH-MM`** depending on if it is bidirectional or not*\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oU_xMZwJUrZ"
      },
      "source": [
        "<a id=\"readme\"></a>\n",
        "## 0. Info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjy_NO-5HPw3"
      },
      "source": [
        "\n",
        "\n",
        "This section lists all the main parameters that can be modified to control data loading, model behavior, and training.\n",
        "\n",
        "---\n",
        "\n",
        "### üìÅ File Paths\n",
        "| Variable | Description | Default Value |\n",
        "|-----------|--------------|----------------|\n",
        "| `TRAIN_DATA_PATH` | Training features | `'pirate_pain_train.csv'` |\n",
        "| `TRAIN_LABELS_PATH` | Training labels | `'pirate_pain_train_labels.csv'` |\n",
        "| `TEST_DATA_PATH` | Test set for inference | `'pirate_pain_test.csv'` *(optional)* |\n",
        "| `MODEL_SAVE_PATH` | Output model file | `'pirate_model.pt'` |\n",
        "| `RESULTS_FILE` | CSV for predictions | `'results_<date-time>.csv'` |\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Model & Architecture\n",
        "| Parameter | Description | Typical Values |\n",
        "|------------|--------------|----------------|\n",
        "| `model_type` | Choose model class | `'RNN'`, `'LSTM'`, `'GRU'`, `'ANN'` |\n",
        "| `input_size` | Number of features per time step | *auto-detected from data* |\n",
        "| `hidden_size` | Hidden layer size | `64`, `128`, `256` |\n",
        "| `num_layers` | Number of RNN layers | `1-4` |\n",
        "| `dropout` | Dropout probability | `0.2‚Äì0.5` |\n",
        "| `num_classes` | Output classes (pain levels) | *from label set* |\n",
        "\n",
        "---\n",
        "\n",
        "### üèãÔ∏è Training Hyperparameters\n",
        "| Parameter | Description | Default / Range |\n",
        "|------------|--------------|-----------------|\n",
        "| `batch_size` | Samples per batch | `512/2^n` |\n",
        "| `learning_rate` | Optimizer learning rate | `1e-3` |\n",
        "| `num_epochs` | Training iterations | `500` |\n",
        "| `optimizer` | Optimization algorithm | `'AdamW'` |\n",
        "| `criterion` | Loss function | `CrossEntropyLoss()` |\n",
        "| `seed` | Random seed for reproducibility | `42` |\n",
        "\n",
        "---\n",
        "\n",
        "### üì§ Inference\n",
        "| Parameter | Description |\n",
        "|------------|--------------|\n",
        "| `LOAD_MODEL_PATH` | Path to pretrained `.pt` model (optional) |\n",
        "| `save_results` | Whether to write output CSV | `True` |\n",
        "\n",
        "---\n",
        "\n",
        "> üí° *Tip:* Adjust hyperparameters in the ‚ÄúConfiguration‚Äù or ‚ÄúTraining Setup‚Äù cell before running the notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZLBQ6tJrcBB"
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "## 1. Setup & Configuration\n",
        "\n",
        "*Optional: Connect to Google Drive (for Colab users)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nig16xZNnmnz",
        "outputId": "6019acc8-506f-46ef-a6b6-38155d647c14"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/gdrive\")\n",
        "# current_dir = \"/gdrive/My\\\\ Drive/[2025 - 2026]\\\\ AN2DL/Challenge 1/Personal Challenge 1\"\n",
        "# %cd $current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL1iYHipaeMD"
      },
      "source": [
        "*Set Model Type*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "uWaTlLkTKgk5"
      },
      "outputs": [],
      "source": [
        "RNN_TYPE = 'LSTM'            # 'RNN', 'LSTM', or 'GRU'\n",
        "BIDIRECTIONAL = True        # True / False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up7Qo6v-o8Ru"
      },
      "source": [
        "*Set Model Save Name*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkBnTJHuo8Rv",
        "outputId": "c6448339-e8f8-47b5-85bb-e748a1711f6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment name: LSTM_bi_12-11-18-59\n",
            "Submission filename: LSTM_bi_12-11-18-59.csv\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get current date and time for submission filename\n",
        "current_datetime = datetime.now().strftime(\"%d-%m-%H-%M\")\n",
        "\n",
        "if BIDIRECTIONAL:\n",
        "    EXPERIMENT_NAME = f\"{RNN_TYPE}_bi_{current_datetime}\"\n",
        "else:\n",
        "    EXPERIMENT_NAME = f\"{RNN_TYPE}_{current_datetime}\"\n",
        "\n",
        "SUBMISSION_FILENAME = f\"{EXPERIMENT_NAME}.csv\"\n",
        "print(f\"Experiment name: {EXPERIMENT_NAME}\")\n",
        "print(f\"Submission filename: {SUBMISSION_FILENAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdaKCgHVvvHX"
      },
      "source": [
        "<a id=\"data-loading\"></a>\n",
        "## 2. Data Loading\n",
        "\n",
        "Load training and test datasets from CSV files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "oLyI938Jvn-J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "X_train = pd.read_csv('an2dl2526c1/pirate_pain_train.csv')\n",
        "y_train = pd.read_csv('an2dl2526c1/pirate_pain_train_labels.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3Lre5NWwCyk"
      },
      "source": [
        "<a id=\"import-libraries\"></a>\n",
        "## 3. Import Libraries\n",
        "\n",
        "Set random seeds for reproducibility and import all necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt3AnE8SwJg1",
        "outputId": "3ba118b9-ca73-4e73-b4c1-7b7aa92c2472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'pkill' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.10.0.dev20251109+cu128\n",
            "Device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A subdirectory or file -p already exists.\n",
            "Error occurred while processing: -p.\n",
            "A subdirectory or file models already exists.\n",
            "Error occurred while processing: models.\n"
          ]
        }
      ],
      "source": [
        "# Set seed for reproducibility\n",
        "SEED = 42\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "\n",
        "# Set environment variables before importing modules\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Import PyTorch\n",
        "import torch\n",
        "torch.manual_seed(SEED)\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Directory configuration\n",
        "logs_dir = \"tensorboard\"\n",
        "models_dir = \"models\"\n",
        "\n",
        "\n",
        "\n",
        "# Model save/load paths\n",
        "MODEL_SAVE_PATH = f\"{models_dir}/{EXPERIMENT_NAME}_model.pt\"\n",
        "MODEL_LOAD_PATH = f\"{models_dir}/{EXPERIMENT_NAME}_model.pt\"\n",
        "\n",
        "!pkill -f tensorboard\n",
        "%load_ext tensorboard\n",
        "!mkdir -p {models_dir}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Import other libraries\n",
        "import copy\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from itertools import product\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "# Configure plot display settings\n",
        "sns.set(font_scale=1.4)\n",
        "sns.set_style('white')\n",
        "plt.rc('font', size=14)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWnQz-p-xyhD"
      },
      "source": [
        "<a id=\"data-preprocessing\"></a>\n",
        "## 4. Data Preprocessing\n",
        "\n",
        "Explore data, split into train/val/test sets, normalize features, and encode labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "hHK2Aw7Ix4S8",
        "outputId": "a9c63a8a-6f8e-40d5-ba1a-a0ce6d0a5d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (105760, 40)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_21</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "      <th>joint_30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.094705</td>\n",
              "      <td>...</td>\n",
              "      <td>3.499558e-06</td>\n",
              "      <td>1.945042e-06</td>\n",
              "      <td>3.999558e-06</td>\n",
              "      <td>1.153299e-05</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.017592</td>\n",
              "      <td>0.013508</td>\n",
              "      <td>0.026798</td>\n",
              "      <td>0.027815</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.135183</td>\n",
              "      <td>...</td>\n",
              "      <td>3.976952e-07</td>\n",
              "      <td>6.765107e-07</td>\n",
              "      <td>6.019627e-06</td>\n",
              "      <td>4.643774e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013377</td>\n",
              "      <td>0.013716</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.080745</td>\n",
              "      <td>...</td>\n",
              "      <td>1.533820e-07</td>\n",
              "      <td>1.698525e-07</td>\n",
              "      <td>1.446051e-06</td>\n",
              "      <td>2.424536e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.016225</td>\n",
              "      <td>0.008110</td>\n",
              "      <td>0.024097</td>\n",
              "      <td>0.023105</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>0.938017</td>\n",
              "      <td>...</td>\n",
              "      <td>1.006865e-05</td>\n",
              "      <td>5.511079e-07</td>\n",
              "      <td>1.847597e-06</td>\n",
              "      <td>5.432416e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011832</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.028613</td>\n",
              "      <td>0.024648</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.090185</td>\n",
              "      <td>...</td>\n",
              "      <td>4.437266e-06</td>\n",
              "      <td>1.735459e-07</td>\n",
              "      <td>1.552722e-06</td>\n",
              "      <td>5.825366e-08</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.005360</td>\n",
              "      <td>0.002532</td>\n",
              "      <td>0.033026</td>\n",
              "      <td>0.025328</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.146031</td>\n",
              "      <td>...</td>\n",
              "      <td>1.073167e-06</td>\n",
              "      <td>1.753837e-07</td>\n",
              "      <td>2.957340e-07</td>\n",
              "      <td>6.217311e-08</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.006444</td>\n",
              "      <td>0.033101</td>\n",
              "      <td>0.023767</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.025870</td>\n",
              "      <td>...</td>\n",
              "      <td>1.074800e-06</td>\n",
              "      <td>1.772156e-07</td>\n",
              "      <td>1.976558e-06</td>\n",
              "      <td>1.576086e-06</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.006495</td>\n",
              "      <td>0.006421</td>\n",
              "      <td>0.031804</td>\n",
              "      <td>0.019056</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.038597</td>\n",
              "      <td>...</td>\n",
              "      <td>8.829074e-07</td>\n",
              "      <td>1.790415e-07</td>\n",
              "      <td>2.210562e-06</td>\n",
              "      <td>1.485741e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015998</td>\n",
              "      <td>0.005397</td>\n",
              "      <td>0.035552</td>\n",
              "      <td>0.015732</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>0.984251</td>\n",
              "      <td>...</td>\n",
              "      <td>1.621055e-06</td>\n",
              "      <td>1.165161e-06</td>\n",
              "      <td>3.030164e-07</td>\n",
              "      <td>5.416678e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020539</td>\n",
              "      <td>0.008517</td>\n",
              "      <td>0.008635</td>\n",
              "      <td>0.015257</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.054999</td>\n",
              "      <td>...</td>\n",
              "      <td>1.609114e-06</td>\n",
              "      <td>3.959558e-06</td>\n",
              "      <td>2.017157e-06</td>\n",
              "      <td>1.154349e-06</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.007682</td>\n",
              "      <td>0.021383</td>\n",
              "      <td>0.034006</td>\n",
              "      <td>0.028966</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows √ó 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
              "0             0     0              2              0              2   \n",
              "1             0     1              2              2              2   \n",
              "2             0     2              2              0              2   \n",
              "3             0     3              2              2              2   \n",
              "4             0     4              2              2              2   \n",
              "5             0     5              2              0              2   \n",
              "6             0     6              2              1              2   \n",
              "7             0     7              2              2              2   \n",
              "8             0     8              2              2              0   \n",
              "9             0     9              0              2              2   \n",
              "\n",
              "   pain_survey_4 n_legs n_hands n_eyes  joint_00  ...      joint_21  \\\n",
              "0              1    two     two    two  1.094705  ...  3.499558e-06   \n",
              "1              2    two     two    two  1.135183  ...  3.976952e-07   \n",
              "2              2    two     two    two  1.080745  ...  1.533820e-07   \n",
              "3              2    two     two    two  0.938017  ...  1.006865e-05   \n",
              "4              2    two     two    two  1.090185  ...  4.437266e-06   \n",
              "5              1    two     two    two  1.146031  ...  1.073167e-06   \n",
              "6              1    two     two    two  1.025870  ...  1.074800e-06   \n",
              "7              2    two     two    two  1.038597  ...  8.829074e-07   \n",
              "8              1    two     two    two  0.984251  ...  1.621055e-06   \n",
              "9              2    two     two    two  1.054999  ...  1.609114e-06   \n",
              "\n",
              "       joint_22      joint_23      joint_24  joint_25  joint_26  joint_27  \\\n",
              "0  1.945042e-06  3.999558e-06  1.153299e-05  0.000004  0.017592  0.013508   \n",
              "1  6.765107e-07  6.019627e-06  4.643774e-08  0.000000  0.013352  0.000000   \n",
              "2  1.698525e-07  1.446051e-06  2.424536e-06  0.000003  0.016225  0.008110   \n",
              "3  5.511079e-07  1.847597e-06  5.432416e-08  0.000000  0.011832  0.007450   \n",
              "4  1.735459e-07  1.552722e-06  5.825366e-08  0.000007  0.005360  0.002532   \n",
              "5  1.753837e-07  2.957340e-07  6.217311e-08  0.000007  0.006150  0.006444   \n",
              "6  1.772156e-07  1.976558e-06  1.576086e-06  0.000005  0.006495  0.006421   \n",
              "7  1.790415e-07  2.210562e-06  1.485741e-06  0.000000  0.015998  0.005397   \n",
              "8  1.165161e-06  3.030164e-07  5.416678e-07  0.000000  0.020539  0.008517   \n",
              "9  3.959558e-06  2.017157e-06  1.154349e-06  0.000007  0.007682  0.021383   \n",
              "\n",
              "   joint_28  joint_29  joint_30  \n",
              "0  0.026798  0.027815       0.5  \n",
              "1  0.013377  0.013716       0.5  \n",
              "2  0.024097  0.023105       0.5  \n",
              "3  0.028613  0.024648       0.5  \n",
              "4  0.033026  0.025328       0.5  \n",
              "5  0.033101  0.023767       0.5  \n",
              "6  0.031804  0.019056       0.5  \n",
              "7  0.035552  0.015732       0.5  \n",
              "8  0.008635  0.015257       0.5  \n",
              "9  0.034006  0.028966       0.5  \n",
              "\n",
              "[10 rows x 40 columns]"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print the shape of the dataset\n",
        "print(f\"Dataset shape: {X_train.shape}\")\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPMtvy5Fo8Rw"
      },
      "source": [
        "### 4.1 Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfBKIdsrQDW3",
        "outputId": "8edb194f-5607-4d4b-87dd-77da58975dee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_legs': ['two', 'one+peg_leg'],\n",
              " 'n_hands': ['two', 'one+hook_hand'],\n",
              " 'n_eyes': ['two', 'one+eye_patch']}"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Merge features and labels\n",
        "data = X_train.merge(y_train, on='sample_index')\n",
        "\n",
        "# Create a mapping dictionary to convert categorical labels to numerical values\n",
        "# map_dict = {'none': 0, 'one': 1, 'two': 2}\n",
        "# data['n_legs'] = data['n_legs'].map(map_dict)\n",
        "# data['n_hands'] = data['n_hands'].map(map_dict)\n",
        "# data['n_eyes'] = data['n_eyes'].map(map_dict)\n",
        "\n",
        "# print(\"Loading test dataset for final evaluation...\")\n",
        "\n",
        "cols = ['n_legs', 'n_hands', 'n_eyes']\n",
        "unique_values = {col: X_train[col].unique().tolist() for col in cols}\n",
        "\n",
        "unique_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN-gWBGzuxfE",
        "outputId": "7c084992-fb0e-40ac-8c59-8e8842845226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mapped string columns to numeric values!\n",
            "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
            "0             0     0              2              0              2   \n",
            "1             0     1              2              2              2   \n",
            "2             0     2              2              0              2   \n",
            "3             0     3              2              2              2   \n",
            "4             0     4              2              2              2   \n",
            "\n",
            "   pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...      joint_22  \\\n",
            "0              1       2        2       2  1.094705  ...  1.945042e-06   \n",
            "1              2       2        2       2  1.135183  ...  6.765107e-07   \n",
            "2              2       2        2       2  1.080745  ...  1.698525e-07   \n",
            "3              2       2        2       2  0.938017  ...  5.511079e-07   \n",
            "4              2       2        2       2  1.090185  ...  1.735459e-07   \n",
            "\n",
            "   joint_23      joint_24  joint_25  joint_26  joint_27  joint_28  joint_29  \\\n",
            "0  0.000004  1.153299e-05  0.000004  0.017592  0.013508  0.026798  0.027815   \n",
            "1  0.000006  4.643774e-08  0.000000  0.013352  0.000000  0.013377  0.013716   \n",
            "2  0.000001  2.424536e-06  0.000003  0.016225  0.008110  0.024097  0.023105   \n",
            "3  0.000002  5.432416e-08  0.000000  0.011832  0.007450  0.028613  0.024648   \n",
            "4  0.000002  5.825366e-08  0.000007  0.005360  0.002532  0.033026  0.025328   \n",
            "\n",
            "   joint_30    label  \n",
            "0       0.5  no_pain  \n",
            "1       0.5  no_pain  \n",
            "2       0.5  no_pain  \n",
            "3       0.5  no_pain  \n",
            "4       0.5  no_pain  \n",
            "\n",
            "[5 rows x 41 columns]\n",
            "Mapped string columns to numeric values!\n",
            "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
            "0             0     0              2              0              2   \n",
            "1             0     1              2              2              2   \n",
            "2             0     2              2              0              2   \n",
            "3             0     3              2              2              2   \n",
            "4             0     4              2              2              2   \n",
            "\n",
            "   pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...      joint_22  \\\n",
            "0              1     NaN      NaN     NaN  1.094705  ...  1.945042e-06   \n",
            "1              2     NaN      NaN     NaN  1.135183  ...  6.765107e-07   \n",
            "2              2     NaN      NaN     NaN  1.080745  ...  1.698525e-07   \n",
            "3              2     NaN      NaN     NaN  0.938017  ...  5.511079e-07   \n",
            "4              2     NaN      NaN     NaN  1.090185  ...  1.735459e-07   \n",
            "\n",
            "   joint_23      joint_24  joint_25  joint_26  joint_27  joint_28  joint_29  \\\n",
            "0  0.000004  1.153299e-05  0.000004  0.017592  0.013508  0.026798  0.027815   \n",
            "1  0.000006  4.643774e-08  0.000000  0.013352  0.000000  0.013377  0.013716   \n",
            "2  0.000001  2.424536e-06  0.000003  0.016225  0.008110  0.024097  0.023105   \n",
            "3  0.000002  5.432416e-08  0.000000  0.011832  0.007450  0.028613  0.024648   \n",
            "4  0.000002  5.825366e-08  0.000007  0.005360  0.002532  0.033026  0.025328   \n",
            "\n",
            "   joint_30    label  \n",
            "0       0.5  no_pain  \n",
            "1       0.5  no_pain  \n",
            "2       0.5  no_pain  \n",
            "3       0.5  no_pain  \n",
            "4       0.5  no_pain  \n",
            "\n",
            "[5 rows x 41 columns]\n"
          ]
        }
      ],
      "source": [
        "map_dict = {'two': 2, 'one+peg_leg': 1}\n",
        "data['n_legs'] = data['n_legs'].map(map_dict)\n",
        "\n",
        "map_dict = {'two': 2, 'one+hook_hand': 1}\n",
        "data['n_hands'] = data['n_hands'].map(map_dict)\n",
        "\n",
        "map_dict = {'two': 2, 'one+eye_patch': 1}\n",
        "data['n_eyes'] = data['n_eyes'].map(map_dict)\n",
        "\n",
        "print(\"Mapped string columns to numeric values!\")\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "map_dict = {'two': 2, 'one+peg_leg': 1}\n",
        "data['n_legs'] = data['n_legs'].map(map_dict)\n",
        "\n",
        "map_dict = {'two': 2, 'one+hook_hand': 1}\n",
        "data['n_hands'] = data['n_hands'].map(map_dict)\n",
        "\n",
        "map_dict = {'two': 2, 'one+eye_patch': 1}\n",
        "data['n_eyes'] = data['n_eyes'].map(map_dict)\n",
        "\n",
        "print(\"Mapped string columns to numeric values!\")\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(np.float64(nan), np.float64(nan))"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['n_hands'].max(), data['n_hands'].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "yiX54ULeXQdV",
        "outputId": "b93025e1-f251-4b23-f864-1325cdd1afc3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_21</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "      <th>joint_30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.057600e+05</td>\n",
              "      <td>1.057600e+05</td>\n",
              "      <td>1.057600e+05</td>\n",
              "      <td>1.057600e+05</td>\n",
              "      <td>1.057600e+05</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.000000</td>\n",
              "      <td>105760.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>330.000000</td>\n",
              "      <td>79.500000</td>\n",
              "      <td>1.633746</td>\n",
              "      <td>1.654851</td>\n",
              "      <td>1.653640</td>\n",
              "      <td>1.663134</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.943095</td>\n",
              "      <td>...</td>\n",
              "      <td>3.972126e-05</td>\n",
              "      <td>4.176794e-05</td>\n",
              "      <td>3.561780e-05</td>\n",
              "      <td>3.138109e-05</td>\n",
              "      <td>1.024604e-04</td>\n",
              "      <td>0.041905</td>\n",
              "      <td>0.058244</td>\n",
              "      <td>0.049886</td>\n",
              "      <td>0.062273</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>190.814948</td>\n",
              "      <td>46.187338</td>\n",
              "      <td>0.682423</td>\n",
              "      <td>0.669639</td>\n",
              "      <td>0.666649</td>\n",
              "      <td>0.661994</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.202051</td>\n",
              "      <td>...</td>\n",
              "      <td>4.974496e-03</td>\n",
              "      <td>5.472244e-03</td>\n",
              "      <td>1.235450e-03</td>\n",
              "      <td>4.062914e-04</td>\n",
              "      <td>3.206128e-03</td>\n",
              "      <td>0.060293</td>\n",
              "      <td>0.079819</td>\n",
              "      <td>0.060773</td>\n",
              "      <td>0.072597</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.510494e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.063144e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000203</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>165.000000</td>\n",
              "      <td>39.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.828277</td>\n",
              "      <td>...</td>\n",
              "      <td>6.545878e-08</td>\n",
              "      <td>3.321650e-07</td>\n",
              "      <td>3.275038e-07</td>\n",
              "      <td>2.841805e-07</td>\n",
              "      <td>7.161332e-07</td>\n",
              "      <td>0.009885</td>\n",
              "      <td>0.012652</td>\n",
              "      <td>0.016290</td>\n",
              "      <td>0.019638</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>330.000000</td>\n",
              "      <td>79.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.005126</td>\n",
              "      <td>...</td>\n",
              "      <td>8.302747e-07</td>\n",
              "      <td>1.095971e-06</td>\n",
              "      <td>1.024209e-06</td>\n",
              "      <td>8.746147e-07</td>\n",
              "      <td>3.126723e-06</td>\n",
              "      <td>0.021898</td>\n",
              "      <td>0.031739</td>\n",
              "      <td>0.031843</td>\n",
              "      <td>0.039041</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>495.000000</td>\n",
              "      <td>119.250000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.081039</td>\n",
              "      <td>...</td>\n",
              "      <td>2.800090e-06</td>\n",
              "      <td>3.079465e-06</td>\n",
              "      <td>3.021830e-06</td>\n",
              "      <td>2.507548e-06</td>\n",
              "      <td>9.946107e-06</td>\n",
              "      <td>0.048579</td>\n",
              "      <td>0.071051</td>\n",
              "      <td>0.058741</td>\n",
              "      <td>0.079518</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>660.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.407968</td>\n",
              "      <td>...</td>\n",
              "      <td>1.442198e+00</td>\n",
              "      <td>1.305001e+00</td>\n",
              "      <td>2.742411e-01</td>\n",
              "      <td>3.643074e-02</td>\n",
              "      <td>9.473540e-01</td>\n",
              "      <td>1.223617</td>\n",
              "      <td>1.187419</td>\n",
              "      <td>1.412037</td>\n",
              "      <td>1.370765</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows √ó 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        sample_index           time  pain_survey_1  pain_survey_2  \\\n",
              "count  105760.000000  105760.000000  105760.000000  105760.000000   \n",
              "mean      330.000000      79.500000       1.633746       1.654851   \n",
              "std       190.814948      46.187338       0.682423       0.669639   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%       165.000000      39.750000       2.000000       2.000000   \n",
              "50%       330.000000      79.500000       2.000000       2.000000   \n",
              "75%       495.000000     119.250000       2.000000       2.000000   \n",
              "max       660.000000     159.000000       2.000000       2.000000   \n",
              "\n",
              "       pain_survey_3  pain_survey_4  n_legs  n_hands  n_eyes       joint_00  \\\n",
              "count  105760.000000  105760.000000     0.0      0.0     0.0  105760.000000   \n",
              "mean        1.653640       1.663134     NaN      NaN     NaN       0.943095   \n",
              "std         0.666649       0.661994     NaN      NaN     NaN       0.202051   \n",
              "min         0.000000       0.000000     NaN      NaN     NaN       0.000000   \n",
              "25%         2.000000       2.000000     NaN      NaN     NaN       0.828277   \n",
              "50%         2.000000       2.000000     NaN      NaN     NaN       1.005126   \n",
              "75%         2.000000       2.000000     NaN      NaN     NaN       1.081039   \n",
              "max         2.000000       2.000000     NaN      NaN     NaN       1.407968   \n",
              "\n",
              "       ...      joint_21      joint_22      joint_23      joint_24  \\\n",
              "count  ...  1.057600e+05  1.057600e+05  1.057600e+05  1.057600e+05   \n",
              "mean   ...  3.972126e-05  4.176794e-05  3.561780e-05  3.138109e-05   \n",
              "std    ...  4.974496e-03  5.472244e-03  1.235450e-03  4.062914e-04   \n",
              "min    ...  0.000000e+00  1.510494e-07  0.000000e+00  1.063144e-08   \n",
              "25%    ...  6.545878e-08  3.321650e-07  3.275038e-07  2.841805e-07   \n",
              "50%    ...  8.302747e-07  1.095971e-06  1.024209e-06  8.746147e-07   \n",
              "75%    ...  2.800090e-06  3.079465e-06  3.021830e-06  2.507548e-06   \n",
              "max    ...  1.442198e+00  1.305001e+00  2.742411e-01  3.643074e-02   \n",
              "\n",
              "           joint_25       joint_26       joint_27       joint_28  \\\n",
              "count  1.057600e+05  105760.000000  105760.000000  105760.000000   \n",
              "mean   1.024604e-04       0.041905       0.058244       0.049886   \n",
              "std    3.206128e-03       0.060293       0.079819       0.060773   \n",
              "min    0.000000e+00       0.000203       0.000000       0.000000   \n",
              "25%    7.161332e-07       0.009885       0.012652       0.016290   \n",
              "50%    3.126723e-06       0.021898       0.031739       0.031843   \n",
              "75%    9.946107e-06       0.048579       0.071051       0.058741   \n",
              "max    9.473540e-01       1.223617       1.187419       1.412037   \n",
              "\n",
              "            joint_29  joint_30  \n",
              "count  105760.000000  105760.0  \n",
              "mean        0.062273       0.5  \n",
              "std         0.072597       0.0  \n",
              "min         0.000000       0.5  \n",
              "25%         0.019638       0.5  \n",
              "50%         0.039041       0.5  \n",
              "75%         0.079518       0.5  \n",
              "max         1.370765       0.5  \n",
              "\n",
              "[8 rows x 40 columns]"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "6pqnMiAQHmlK",
        "outputId": "eabfd096-94eb-4416-82b1-bd2fd59a05df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "      <th>joint_30</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.094705</td>\n",
              "      <td>...</td>\n",
              "      <td>1.945042e-06</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>1.153299e-05</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.017592</td>\n",
              "      <td>0.013508</td>\n",
              "      <td>0.026798</td>\n",
              "      <td>0.027815</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.135183</td>\n",
              "      <td>...</td>\n",
              "      <td>6.765107e-07</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>4.643774e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013377</td>\n",
              "      <td>0.013716</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.080745</td>\n",
              "      <td>...</td>\n",
              "      <td>1.698525e-07</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>2.424536e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.016225</td>\n",
              "      <td>0.008110</td>\n",
              "      <td>0.024097</td>\n",
              "      <td>0.023105</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.938017</td>\n",
              "      <td>...</td>\n",
              "      <td>5.511079e-07</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>5.432416e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011832</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.028613</td>\n",
              "      <td>0.024648</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.090185</td>\n",
              "      <td>...</td>\n",
              "      <td>1.735459e-07</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>5.825366e-08</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.005360</td>\n",
              "      <td>0.002532</td>\n",
              "      <td>0.033026</td>\n",
              "      <td>0.025328</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
              "0             0     0              2              0              2   \n",
              "1             0     1              2              2              2   \n",
              "2             0     2              2              0              2   \n",
              "3             0     3              2              2              2   \n",
              "4             0     4              2              2              2   \n",
              "\n",
              "   pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...      joint_22  \\\n",
              "0              1     NaN      NaN     NaN  1.094705  ...  1.945042e-06   \n",
              "1              2     NaN      NaN     NaN  1.135183  ...  6.765107e-07   \n",
              "2              2     NaN      NaN     NaN  1.080745  ...  1.698525e-07   \n",
              "3              2     NaN      NaN     NaN  0.938017  ...  5.511079e-07   \n",
              "4              2     NaN      NaN     NaN  1.090185  ...  1.735459e-07   \n",
              "\n",
              "   joint_23      joint_24  joint_25  joint_26  joint_27  joint_28  joint_29  \\\n",
              "0  0.000004  1.153299e-05  0.000004  0.017592  0.013508  0.026798  0.027815   \n",
              "1  0.000006  4.643774e-08  0.000000  0.013352  0.000000  0.013377  0.013716   \n",
              "2  0.000001  2.424536e-06  0.000003  0.016225  0.008110  0.024097  0.023105   \n",
              "3  0.000002  5.432416e-08  0.000000  0.011832  0.007450  0.028613  0.024648   \n",
              "4  0.000002  5.825366e-08  0.000007  0.005360  0.002532  0.033026  0.025328   \n",
              "\n",
              "   joint_30    label  \n",
              "0       0.5  no_pain  \n",
              "1       0.5  no_pain  \n",
              "2       0.5  no_pain  \n",
              "3       0.5  no_pain  \n",
              "4       0.5  no_pain  \n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojlNM9r8u8x8"
      },
      "source": [
        "## Preprocessing testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBEcYysvu8A9",
        "outputId": "c5ab2676-26b0-4d01-fcbd-f638be75dc46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mapped string columns to numeric values!\n",
            "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
            "0             0     0              2              2              2   \n",
            "1             0     1              2              2              2   \n",
            "2             0     2              2              2              2   \n",
            "3             0     3              1              2              2   \n",
            "4             0     4              2              2              2   \n",
            "\n",
            "   pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...  joint_21  joint_22  \\\n",
            "0              2       2        2       2  0.842535  ...  0.000003  0.000004   \n",
            "1              2       2        2       2  0.898836  ...  0.000003  0.000004   \n",
            "2              2       2        2       2  0.957765  ...  0.000006  0.000004   \n",
            "3              2       2        2       2  0.832596  ...  0.000005  0.000004   \n",
            "4              0       2        2       2  0.805971  ...  0.000006  0.000004   \n",
            "\n",
            "   joint_23  joint_24  joint_25  joint_26  joint_27  joint_28  joint_29  \\\n",
            "0  0.000003  0.000003  0.000068  0.019372  0.066324  0.022228  0.013576   \n",
            "1  0.000004  0.000003  0.000029  0.069747  0.080417  0.023650  0.038793   \n",
            "2  0.000009  0.000004  0.000008  0.054968  0.058811  0.027023  0.054202   \n",
            "3  0.000003  0.000004  0.000015  0.048695  0.047128  0.016151  0.024983   \n",
            "4  0.000003  0.000003  0.000008  0.019762  0.031116  0.015618  0.017931   \n",
            "\n",
            "   joint_30  \n",
            "0       0.5  \n",
            "1       0.5  \n",
            "2       0.5  \n",
            "3       0.5  \n",
            "4       0.5  \n",
            "\n",
            "[5 rows x 40 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load the actual test dataset (this doesn't have labels)\n",
        "X_test_final_df = pd.read_csv('an2dl2526c1/pirate_pain_test.csv')\n",
        "\n",
        "# Map string columns to numeric values first\n",
        "map_dict = {'two': 2, 'one+peg_leg': 1}\n",
        "X_test_final_df['n_legs'] = X_test_final_df['n_legs'].map(map_dict)\n",
        "\n",
        "map_dict = {'two': 2, 'one+hook_hand': 1}\n",
        "X_test_final_df['n_hands'] = X_test_final_df['n_hands'].map(map_dict)\n",
        "\n",
        "map_dict = {'two': 2, 'one+eye_patch': 1}\n",
        "X_test_final_df['n_eyes'] = X_test_final_df['n_eyes'].map(map_dict)\n",
        "\n",
        "print(\"Mapped string columns to numeric values!\")\n",
        "print(X_test_final_df.head())\n",
        "\n",
        "# Now convert inputs from float64 to float32\n",
        "X_test_final_df = X_test_final_df.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "OoKAZSkvvEam"
      },
      "outputs": [],
      "source": [
        "def build_sequences_test(df, window=200, stride=200):\n",
        "    assert window % stride == 0\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    # Get feature columns (exclude sample_index and time)\n",
        "    columns = [col for col in df.columns if col not in ['sample_index', 'time']]\n",
        "\n",
        "    for id in df['sample_index'].unique():\n",
        "        temp = df[df['sample_index'] == id][columns].values\n",
        "\n",
        "        # Padding\n",
        "        padding_len = (window - len(temp) % window) % window\n",
        "        padding = np.zeros((padding_len, len(columns)), dtype='float32')\n",
        "        temp = np.concatenate((temp, padding))\n",
        "\n",
        "        # Build windows\n",
        "        idx = 0\n",
        "        while idx + window <= len(temp):\n",
        "            dataset.append(temp[idx:idx + window])\n",
        "            idx += stride\n",
        "\n",
        "    return np.array(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "EEu1WYIgvMvl",
        "outputId": "3715b1ec-5932-4b0c-c3c4-eba1caebea53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_21</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "      <th>joint_30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.561563</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>0.014909</td>\n",
              "      <td>0.045098</td>\n",
              "      <td>0.012882</td>\n",
              "      <td>0.010178</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006289</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.599088</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.053679</td>\n",
              "      <td>0.055375</td>\n",
              "      <td>0.013892</td>\n",
              "      <td>0.029085</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012579</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.638365</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.042305</td>\n",
              "      <td>0.039620</td>\n",
              "      <td>0.016286</td>\n",
              "      <td>0.040638</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018868</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.554938</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.037477</td>\n",
              "      <td>0.031101</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025157</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.537192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.015210</td>\n",
              "      <td>0.019426</td>\n",
              "      <td>0.008189</td>\n",
              "      <td>0.013444</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample_index      time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
              "0           0.0  0.000000            1.0            1.0            1.0   \n",
              "1           0.0  0.006289            1.0            1.0            1.0   \n",
              "2           0.0  0.012579            1.0            1.0            1.0   \n",
              "3           0.0  0.018868            0.5            1.0            1.0   \n",
              "4           0.0  0.025157            1.0            1.0            1.0   \n",
              "\n",
              "   pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...  joint_21  joint_22  \\\n",
              "0            1.0     1.0      1.0     1.0  0.561563  ...  0.000003  0.000033   \n",
              "1            1.0     1.0      1.0     1.0  0.599088  ...  0.000003  0.000033   \n",
              "2            1.0     1.0      1.0     1.0  0.638365  ...  0.000009  0.000033   \n",
              "3            1.0     1.0      1.0     1.0  0.554938  ...  0.000006  0.000033   \n",
              "4            0.0     1.0      1.0     1.0  0.537192  ...  0.000008  0.000045   \n",
              "\n",
              "   joint_23  joint_24  joint_25  joint_26  joint_27  joint_28  joint_29  \\\n",
              "0  0.000048  0.000027  0.000406  0.014909  0.045098  0.012882  0.010178   \n",
              "1  0.000060  0.000021  0.000176  0.053679  0.055375  0.013892  0.029085   \n",
              "2  0.000146  0.000031  0.000049  0.042305  0.039620  0.016286  0.040638   \n",
              "3  0.000047  0.000032  0.000088  0.037477  0.031101  0.008568  0.018730   \n",
              "4  0.000047  0.000021  0.000048  0.015210  0.019426  0.008189  0.013444   \n",
              "\n",
              "   joint_30  \n",
              "0       0.5  \n",
              "1       0.5  \n",
              "2       0.5  \n",
              "3       0.5  \n",
              "4       0.5  \n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ------ Normalize test data ------\n",
        "\n",
        "# --- Load and preprocess the actual test dataset ---\n",
        "# Define the columns to be normalised (use training statistics for proper normalization)\n",
        "# Exclude 'sample_index', 'time', and 'label' as they were excluded during training sequence building\n",
        "# Also exclude 'joint_30' as it was removed from training data\n",
        "scale_columns = [col for col in X_test_final_df.columns\n",
        "                 if col != 'sample_index' and col != 'joint_30']\n",
        "\n",
        "# Calculate the minimum and maximum values from the training data only\n",
        "mins_train = X_test_final_df[scale_columns].min()\n",
        "maxs_train = X_test_final_df[scale_columns].max()\n",
        "\n",
        "# Apply normalisation to the specified columns in all datasets\n",
        "for column in scale_columns:\n",
        "    # Normalise the testing set\n",
        "    if maxs_train[column] != mins_train[column]:\n",
        "      X_test_final_df[column] = (X_test_final_df[column] - mins_train[column]) / (maxs_train[column] - mins_train[column])\n",
        "\n",
        "X_test_final_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlDwxJ38o8Rw"
      },
      "source": [
        "### 4.2 Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original label distribution: {'no_pain': 511, 'low_pain': 94, 'high_pain': 56}\n",
            "Train label counts before balancing: {'no_pain': 385, 'low_pain': 71, 'high_pain': 42}\n",
            "Train label counts after balancing: {'no_pain': 385, 'low_pain': 71, 'high_pain': 42}\n",
            "\n",
            "Label proportions:\n",
            "Train:\n",
            " label\n",
            "no_pain      0.773092\n",
            "low_pain     0.142570\n",
            "high_pain    0.084337\n",
            "Name: proportion, dtype: float64\n",
            "Val:\n",
            " label\n",
            "no_pain      0.7750\n",
            "low_pain     0.1375\n",
            "high_pain    0.0875\n",
            "Name: proportion, dtype: float64\n",
            "Test:\n",
            " label\n",
            "no_pain     0.666667\n",
            "low_pain    0.333333\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# df has columns: ['sample_index', 'label']\n",
        "N_NO_PAIN_KEEP = 1000   # how many \"no_pain\" users to keep\n",
        "N_LOW_PAIN_KEEP = 150   # how many \"low_pain\" users to keep\n",
        "N_VAL_USERS = 160\n",
        "N_TEST_USERS = 3\n",
        "\n",
        "# --- Step 1: Compute each user's dominant label ---\n",
        "user_labels = (\n",
        "    data.groupby('sample_index')['label']\n",
        "    .agg(lambda x: x.value_counts().index[0])  # dominant label per user\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "print(\"Original label distribution:\", user_labels['label'].value_counts().to_dict())\n",
        "\n",
        "# --- Step 2: Stratified Shuffle Split for train/val/test ---\n",
        "n_total = len(user_labels)\n",
        "test_size = (N_VAL_USERS + N_TEST_USERS) / n_total\n",
        "\n",
        "sss_outer = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
        "for train_idx, temp_idx in sss_outer.split(user_labels['sample_index'], user_labels['label']):\n",
        "    train_users = user_labels.iloc[train_idx]['sample_index']\n",
        "    temp_users = user_labels.iloc[temp_idx]['sample_index']\n",
        "\n",
        "temp_labels = user_labels[user_labels['sample_index'].isin(temp_users)]\n",
        "\n",
        "# Split temp into val/test (also stratified)\n",
        "sss_inner = StratifiedShuffleSplit(n_splits=1, test_size=N_TEST_USERS / (N_VAL_USERS + N_TEST_USERS), random_state=42)\n",
        "for val_idx, test_idx in sss_inner.split(temp_labels['sample_index'], temp_labels['label']):\n",
        "    val_users = temp_labels.iloc[val_idx]['sample_index']\n",
        "    test_users = temp_labels.iloc[test_idx]['sample_index']\n",
        "\n",
        "# --- Step 3: Partial balancing of the training set ---\n",
        "train_labels = user_labels[user_labels['sample_index'].isin(train_users)]\n",
        "\n",
        "print(\"Train label counts before balancing:\", train_labels['label'].value_counts().to_dict())\n",
        "\n",
        "rng = random.Random(42)\n",
        "no_pain_users = train_labels[train_labels['label'] == 'no_pain']['sample_index'].tolist()\n",
        "low_pain_users = train_labels[train_labels['label'] == 'low_pain']['sample_index'].tolist()\n",
        "high_pain_users = train_labels[train_labels['label'] == 'high_pain']['sample_index'].tolist()\n",
        "\n",
        "no_pain_keep = min(N_NO_PAIN_KEEP, len(no_pain_users))\n",
        "low_pain_keep = min(N_LOW_PAIN_KEEP, len(low_pain_users))\n",
        "high_pain_keep = len(high_pain_users)\n",
        "\n",
        "selected_no_pain = rng.sample(no_pain_users, no_pain_keep)\n",
        "selected_low_pain = rng.sample(low_pain_users, low_pain_keep)\n",
        "selected_high_pain = high_pain_users  # keep all\n",
        "\n",
        "selected_users = selected_no_pain + selected_low_pain + selected_high_pain\n",
        "balanced_train_labels = train_labels[train_labels['sample_index'].isin(selected_users)]\n",
        "\n",
        "print(\"Train label counts after balancing:\", balanced_train_labels['label'].value_counts().to_dict())\n",
        "\n",
        "train_users = balanced_train_labels['sample_index']\n",
        "\n",
        "# --- Step 4: Filter the main dataframe ---\n",
        "df_train = data[data['sample_index'].isin(train_users)]\n",
        "df_val = data[data['sample_index'].isin(val_users)]\n",
        "df_test = data[data['sample_index'].isin(test_users)]\n",
        "\n",
        "# --- Step 5: Display final distributions ---\n",
        "print(\"\\nLabel proportions:\")\n",
        "print(\"Train:\\n\", df_train['label'].value_counts(normalize=True))\n",
        "print(\"Val:\\n\", df_val['label'].value_counts(normalize=True))\n",
        "print(\"Test:\\n\", df_test['label'].value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "      <th>joint_30</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.094705</td>\n",
              "      <td>...</td>\n",
              "      <td>1.945042e-06</td>\n",
              "      <td>3.999558e-06</td>\n",
              "      <td>1.153299e-05</td>\n",
              "      <td>3.805930e-06</td>\n",
              "      <td>0.017592</td>\n",
              "      <td>0.013508</td>\n",
              "      <td>0.026798</td>\n",
              "      <td>0.027815</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.135183</td>\n",
              "      <td>...</td>\n",
              "      <td>6.765107e-07</td>\n",
              "      <td>6.019627e-06</td>\n",
              "      <td>4.643774e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.013352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013377</td>\n",
              "      <td>0.013716</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.080745</td>\n",
              "      <td>...</td>\n",
              "      <td>1.698525e-07</td>\n",
              "      <td>1.446051e-06</td>\n",
              "      <td>2.424536e-06</td>\n",
              "      <td>2.513519e-06</td>\n",
              "      <td>0.016225</td>\n",
              "      <td>0.008110</td>\n",
              "      <td>0.024097</td>\n",
              "      <td>0.023105</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.938017</td>\n",
              "      <td>...</td>\n",
              "      <td>5.511079e-07</td>\n",
              "      <td>1.847597e-06</td>\n",
              "      <td>5.432416e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.011832</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.028613</td>\n",
              "      <td>0.024648</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.090185</td>\n",
              "      <td>...</td>\n",
              "      <td>1.735459e-07</td>\n",
              "      <td>1.552722e-06</td>\n",
              "      <td>5.825366e-08</td>\n",
              "      <td>7.044832e-06</td>\n",
              "      <td>0.005360</td>\n",
              "      <td>0.002532</td>\n",
              "      <td>0.033026</td>\n",
              "      <td>0.025328</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105755</th>\n",
              "      <td>660</td>\n",
              "      <td>155</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.051738</td>\n",
              "      <td>...</td>\n",
              "      <td>3.586810e-07</td>\n",
              "      <td>2.929207e-09</td>\n",
              "      <td>3.722175e-07</td>\n",
              "      <td>9.919764e-07</td>\n",
              "      <td>0.007856</td>\n",
              "      <td>0.026876</td>\n",
              "      <td>0.173566</td>\n",
              "      <td>0.221921</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105756</th>\n",
              "      <td>660</td>\n",
              "      <td>156</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.027651</td>\n",
              "      <td>...</td>\n",
              "      <td>3.588733e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.059047e-07</td>\n",
              "      <td>3.802923e-06</td>\n",
              "      <td>0.026795</td>\n",
              "      <td>0.012778</td>\n",
              "      <td>0.075945</td>\n",
              "      <td>0.116763</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105757</th>\n",
              "      <td>660</td>\n",
              "      <td>157</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.113381</td>\n",
              "      <td>...</td>\n",
              "      <td>3.590534e-07</td>\n",
              "      <td>2.422390e-06</td>\n",
              "      <td>2.029416e-07</td>\n",
              "      <td>6.218436e-06</td>\n",
              "      <td>0.036982</td>\n",
              "      <td>0.028014</td>\n",
              "      <td>0.075978</td>\n",
              "      <td>0.078339</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105758</th>\n",
              "      <td>660</td>\n",
              "      <td>158</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.058100</td>\n",
              "      <td>...</td>\n",
              "      <td>3.592213e-07</td>\n",
              "      <td>6.060577e-07</td>\n",
              "      <td>1.999436e-07</td>\n",
              "      <td>9.895764e-07</td>\n",
              "      <td>0.046405</td>\n",
              "      <td>0.017922</td>\n",
              "      <td>0.097109</td>\n",
              "      <td>0.106807</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105759</th>\n",
              "      <td>660</td>\n",
              "      <td>159</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.008509</td>\n",
              "      <td>...</td>\n",
              "      <td>3.593769e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.431643e-06</td>\n",
              "      <td>9.883298e-07</td>\n",
              "      <td>0.033489</td>\n",
              "      <td>0.041909</td>\n",
              "      <td>0.084751</td>\n",
              "      <td>0.163532</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>79680 rows √ó 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
              "0                  0     0              2              0              2   \n",
              "1                  0     1              2              2              2   \n",
              "2                  0     2              2              0              2   \n",
              "3                  0     3              2              2              2   \n",
              "4                  0     4              2              2              2   \n",
              "...              ...   ...            ...            ...            ...   \n",
              "105755           660   155              2              2              0   \n",
              "105756           660   156              2              2              0   \n",
              "105757           660   157              0              2              2   \n",
              "105758           660   158              2              2              2   \n",
              "105759           660   159              2              2              2   \n",
              "\n",
              "        pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...      joint_22  \\\n",
              "0                   1     NaN      NaN     NaN  1.094705  ...  1.945042e-06   \n",
              "1                   2     NaN      NaN     NaN  1.135183  ...  6.765107e-07   \n",
              "2                   2     NaN      NaN     NaN  1.080745  ...  1.698525e-07   \n",
              "3                   2     NaN      NaN     NaN  0.938017  ...  5.511079e-07   \n",
              "4                   2     NaN      NaN     NaN  1.090185  ...  1.735459e-07   \n",
              "...               ...     ...      ...     ...       ...  ...           ...   \n",
              "105755              0     NaN      NaN     NaN  1.051738  ...  3.586810e-07   \n",
              "105756              2     NaN      NaN     NaN  1.027651  ...  3.588733e-07   \n",
              "105757              2     NaN      NaN     NaN  1.113381  ...  3.590534e-07   \n",
              "105758              2     NaN      NaN     NaN  1.058100  ...  3.592213e-07   \n",
              "105759              0     NaN      NaN     NaN  1.008509  ...  3.593769e-07   \n",
              "\n",
              "            joint_23      joint_24      joint_25  joint_26  joint_27  \\\n",
              "0       3.999558e-06  1.153299e-05  3.805930e-06  0.017592  0.013508   \n",
              "1       6.019627e-06  4.643774e-08  0.000000e+00  0.013352  0.000000   \n",
              "2       1.446051e-06  2.424536e-06  2.513519e-06  0.016225  0.008110   \n",
              "3       1.847597e-06  5.432416e-08  0.000000e+00  0.011832  0.007450   \n",
              "4       1.552722e-06  5.825366e-08  7.044832e-06  0.005360  0.002532   \n",
              "...              ...           ...           ...       ...       ...   \n",
              "105755  2.929207e-09  3.722175e-07  9.919764e-07  0.007856  0.026876   \n",
              "105756  0.000000e+00  2.059047e-07  3.802923e-06  0.026795  0.012778   \n",
              "105757  2.422390e-06  2.029416e-07  6.218436e-06  0.036982  0.028014   \n",
              "105758  6.060577e-07  1.999436e-07  9.895764e-07  0.046405  0.017922   \n",
              "105759  0.000000e+00  2.431643e-06  9.883298e-07  0.033489  0.041909   \n",
              "\n",
              "        joint_28  joint_29  joint_30    label  \n",
              "0       0.026798  0.027815       0.5  no_pain  \n",
              "1       0.013377  0.013716       0.5  no_pain  \n",
              "2       0.024097  0.023105       0.5  no_pain  \n",
              "3       0.028613  0.024648       0.5  no_pain  \n",
              "4       0.033026  0.025328       0.5  no_pain  \n",
              "...          ...       ...       ...      ...  \n",
              "105755  0.173566  0.221921       0.5  no_pain  \n",
              "105756  0.075945  0.116763       0.5  no_pain  \n",
              "105757  0.075978  0.078339       0.5  no_pain  \n",
              "105758  0.097109  0.106807       0.5  no_pain  \n",
              "105759  0.084751  0.163532       0.5  no_pain  \n",
              "\n",
              "[79680 rows x 41 columns]"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqptiNjNQDW3",
        "outputId": "9508d195-0874-46fe-e29e-1780b753be9e"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import random\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # df has columns: ['sample_index', 'label']\n",
        "# N_NO_PAIN_KEEP = 1000   # how many \"no_pain\" pirates to keep in the training set (lower it to have a more balanced distribution of the labels)\n",
        "# N_LOW_PAIN_KEEP = 150   # how many \"low_pain\" pirates to keep in the training set\n",
        "# N_VAL_USERS = 160\n",
        "# N_TEST_USERS = 3\n",
        "\n",
        "# # --- Step 1: Compute each user's dominant label (or label distribution)\n",
        "# user_labels = (\n",
        "#     data.groupby('sample_index')['label']\n",
        "#     .agg(lambda x: x.value_counts().index[0])  # dominant label per user\n",
        "#     .reset_index()\n",
        "# )\n",
        "\n",
        "# print(\"Original label distribution:\", user_labels['label'].value_counts().to_dict())\n",
        "\n",
        "# # --- Step 2: Split into train/val/test keeping real label proportions\n",
        "# train_users, temp_users = train_test_split(\n",
        "#     user_labels['sample_index'],\n",
        "#     test_size=(N_VAL_USERS + N_TEST_USERS) / len(user_labels),\n",
        "#     stratify=user_labels['label'],\n",
        "#     random_state=None\n",
        "# )\n",
        "\n",
        "# # Split temp into val/test (also stratified)\n",
        "# temp_labels = user_labels[user_labels['sample_index'].isin(temp_users)]\n",
        "\n",
        "# val_users, test_users = train_test_split(\n",
        "#     temp_labels['sample_index'],\n",
        "#     test_size=N_TEST_USERS / (N_VAL_USERS + N_TEST_USERS),\n",
        "#     stratify=temp_labels['label'],\n",
        "#     random_state=None\n",
        "# )\n",
        "\n",
        "\n",
        "# # === Step 3: Create a partially balanced training set keeping a fixed number of pirates per label ===\n",
        "# train_labels = user_labels[user_labels['sample_index'].isin(train_users)]\n",
        "\n",
        "# # Count of how many pirates are present for each label in training set\n",
        "# label_counts = train_labels['label'].value_counts()\n",
        "# print(\"Train label counts before balancing:\", label_counts.to_dict())\n",
        "\n",
        "# # --- Custom undersampling logic ---\n",
        "# rng = random.Random()\n",
        "\n",
        "# no_pain_users = train_labels[train_labels['label'] == 'no_pain']['sample_index'].tolist()\n",
        "# low_pain_users = train_labels[train_labels['label'] == 'low_pain']['sample_index'].tolist()\n",
        "# high_pain_users = train_labels[train_labels['label'] == 'high_pain']['sample_index'].tolist()\n",
        "\n",
        "# # Choose how many to keep for each label\n",
        "# no_pain_keep = min(N_NO_PAIN_KEEP, len(no_pain_users))\n",
        "# low_pain_keep = min(N_LOW_PAIN_KEEP, len(low_pain_users))\n",
        "# high_pain_keep = len(high_pain_users)  # keep all high_pain pirates\n",
        "\n",
        "# selected_no_pain = rng.sample(no_pain_users, no_pain_keep)\n",
        "# selected_low_pain = rng.sample(low_pain_users, low_pain_keep)\n",
        "# selected_high_pain = high_pain_users  # keep all\n",
        "\n",
        "# # Combine the selected users\n",
        "# selected_users = selected_no_pain + selected_low_pain + selected_high_pain\n",
        "# balanced_train_labels = train_labels[train_labels['sample_index'].isin(selected_users)]\n",
        "\n",
        "# print(\"Train label counts after balancing:\", balanced_train_labels['label'].value_counts().to_dict())\n",
        "\n",
        "# train_users = balanced_train_labels['sample_index']\n",
        "\n",
        "# # Compute validation and test label distributions\n",
        "# val_label_counts = user_labels[user_labels['sample_index'].isin(val_users)]['label'].value_counts().to_dict()\n",
        "# test_label_counts = user_labels[user_labels['sample_index'].isin(test_users)]['label'].value_counts().to_dict()\n",
        "# print(\"Validation and Test distributions:\")\n",
        "# print(\"Validation label counts:\", val_label_counts)\n",
        "# print(\"Test label counts:\", test_label_counts)\n",
        "\n",
        "\n",
        "# # --- Step 4: Filter your main df\n",
        "# df_train = data[data['sample_index'].isin(train_users)]\n",
        "# df_val = data[data['sample_index'].isin(val_users)]\n",
        "# df_test = data[data['sample_index'].isin(test_users)]\n",
        "\n",
        "# # --- Step 5: Check label proportions\n",
        "# print(\"Label proportions:\")\n",
        "# print(\"Train:\\n\", df_train['label'].value_counts(normalize=True))\n",
        "# print(\"Val:\\n\", df_val['label'].value_counts(normalize=True))\n",
        "# print(\"Test:\\n\", df_test['label'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUwlOzWBo8Rx"
      },
      "source": [
        "### 4.3 Stratified Train/Val/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI13WygTQDW4",
        "outputId": "776ed4b5-8c1e-4c78-9b5f-b56edc16c8b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((79680, 41), (25600, 41), (480, 41))"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsE1KsTTQDW4",
        "outputId": "7f6d07d9-0a3c-4101-ec98-d50212c38e8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total pirates in training set: 498\n",
            "Total pirates in validation set: 160\n",
            "Total pirates in test set: 3\n"
          ]
        }
      ],
      "source": [
        "# Print the total number of pirates for each dataset\n",
        "print(f\"Total pirates in training set: {df_train['sample_index'].nunique()}\")\n",
        "print(f\"Total pirates in validation set: {df_val['sample_index'].nunique()}\")\n",
        "print(f\"Total pirates in test set: {df_test['sample_index'].nunique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "A35PiqdxJsLQ",
        "outputId": "788a1f6b-f591-4a54-e20c-293fb592f296"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "      <th>joint_30</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.094705</td>\n",
              "      <td>...</td>\n",
              "      <td>1.945042e-06</td>\n",
              "      <td>3.999558e-06</td>\n",
              "      <td>1.153299e-05</td>\n",
              "      <td>3.805930e-06</td>\n",
              "      <td>0.017592</td>\n",
              "      <td>0.013508</td>\n",
              "      <td>0.026798</td>\n",
              "      <td>0.027815</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.135183</td>\n",
              "      <td>...</td>\n",
              "      <td>6.765107e-07</td>\n",
              "      <td>6.019627e-06</td>\n",
              "      <td>4.643774e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.013352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013377</td>\n",
              "      <td>0.013716</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.080745</td>\n",
              "      <td>...</td>\n",
              "      <td>1.698525e-07</td>\n",
              "      <td>1.446051e-06</td>\n",
              "      <td>2.424536e-06</td>\n",
              "      <td>2.513519e-06</td>\n",
              "      <td>0.016225</td>\n",
              "      <td>0.008110</td>\n",
              "      <td>0.024097</td>\n",
              "      <td>0.023105</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.938017</td>\n",
              "      <td>...</td>\n",
              "      <td>5.511079e-07</td>\n",
              "      <td>1.847597e-06</td>\n",
              "      <td>5.432416e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.011832</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.028613</td>\n",
              "      <td>0.024648</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.090185</td>\n",
              "      <td>...</td>\n",
              "      <td>1.735459e-07</td>\n",
              "      <td>1.552722e-06</td>\n",
              "      <td>5.825366e-08</td>\n",
              "      <td>7.044832e-06</td>\n",
              "      <td>0.005360</td>\n",
              "      <td>0.002532</td>\n",
              "      <td>0.033026</td>\n",
              "      <td>0.025328</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105755</th>\n",
              "      <td>660</td>\n",
              "      <td>155</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.051738</td>\n",
              "      <td>...</td>\n",
              "      <td>3.586810e-07</td>\n",
              "      <td>2.929207e-09</td>\n",
              "      <td>3.722175e-07</td>\n",
              "      <td>9.919764e-07</td>\n",
              "      <td>0.007856</td>\n",
              "      <td>0.026876</td>\n",
              "      <td>0.173566</td>\n",
              "      <td>0.221921</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105756</th>\n",
              "      <td>660</td>\n",
              "      <td>156</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.027651</td>\n",
              "      <td>...</td>\n",
              "      <td>3.588733e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.059047e-07</td>\n",
              "      <td>3.802923e-06</td>\n",
              "      <td>0.026795</td>\n",
              "      <td>0.012778</td>\n",
              "      <td>0.075945</td>\n",
              "      <td>0.116763</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105757</th>\n",
              "      <td>660</td>\n",
              "      <td>157</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.113381</td>\n",
              "      <td>...</td>\n",
              "      <td>3.590534e-07</td>\n",
              "      <td>2.422390e-06</td>\n",
              "      <td>2.029416e-07</td>\n",
              "      <td>6.218436e-06</td>\n",
              "      <td>0.036982</td>\n",
              "      <td>0.028014</td>\n",
              "      <td>0.075978</td>\n",
              "      <td>0.078339</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105758</th>\n",
              "      <td>660</td>\n",
              "      <td>158</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.058100</td>\n",
              "      <td>...</td>\n",
              "      <td>3.592213e-07</td>\n",
              "      <td>6.060577e-07</td>\n",
              "      <td>1.999436e-07</td>\n",
              "      <td>9.895764e-07</td>\n",
              "      <td>0.046405</td>\n",
              "      <td>0.017922</td>\n",
              "      <td>0.097109</td>\n",
              "      <td>0.106807</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105759</th>\n",
              "      <td>660</td>\n",
              "      <td>159</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.008509</td>\n",
              "      <td>...</td>\n",
              "      <td>3.593769e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.431643e-06</td>\n",
              "      <td>9.883298e-07</td>\n",
              "      <td>0.033489</td>\n",
              "      <td>0.041909</td>\n",
              "      <td>0.084751</td>\n",
              "      <td>0.163532</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>79680 rows √ó 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
              "0                  0     0              2              0              2   \n",
              "1                  0     1              2              2              2   \n",
              "2                  0     2              2              0              2   \n",
              "3                  0     3              2              2              2   \n",
              "4                  0     4              2              2              2   \n",
              "...              ...   ...            ...            ...            ...   \n",
              "105755           660   155              2              2              0   \n",
              "105756           660   156              2              2              0   \n",
              "105757           660   157              0              2              2   \n",
              "105758           660   158              2              2              2   \n",
              "105759           660   159              2              2              2   \n",
              "\n",
              "        pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...      joint_22  \\\n",
              "0                   1     NaN      NaN     NaN  1.094705  ...  1.945042e-06   \n",
              "1                   2     NaN      NaN     NaN  1.135183  ...  6.765107e-07   \n",
              "2                   2     NaN      NaN     NaN  1.080745  ...  1.698525e-07   \n",
              "3                   2     NaN      NaN     NaN  0.938017  ...  5.511079e-07   \n",
              "4                   2     NaN      NaN     NaN  1.090185  ...  1.735459e-07   \n",
              "...               ...     ...      ...     ...       ...  ...           ...   \n",
              "105755              0     NaN      NaN     NaN  1.051738  ...  3.586810e-07   \n",
              "105756              2     NaN      NaN     NaN  1.027651  ...  3.588733e-07   \n",
              "105757              2     NaN      NaN     NaN  1.113381  ...  3.590534e-07   \n",
              "105758              2     NaN      NaN     NaN  1.058100  ...  3.592213e-07   \n",
              "105759              0     NaN      NaN     NaN  1.008509  ...  3.593769e-07   \n",
              "\n",
              "            joint_23      joint_24      joint_25  joint_26  joint_27  \\\n",
              "0       3.999558e-06  1.153299e-05  3.805930e-06  0.017592  0.013508   \n",
              "1       6.019627e-06  4.643774e-08  0.000000e+00  0.013352  0.000000   \n",
              "2       1.446051e-06  2.424536e-06  2.513519e-06  0.016225  0.008110   \n",
              "3       1.847597e-06  5.432416e-08  0.000000e+00  0.011832  0.007450   \n",
              "4       1.552722e-06  5.825366e-08  7.044832e-06  0.005360  0.002532   \n",
              "...              ...           ...           ...       ...       ...   \n",
              "105755  2.929207e-09  3.722175e-07  9.919764e-07  0.007856  0.026876   \n",
              "105756  0.000000e+00  2.059047e-07  3.802923e-06  0.026795  0.012778   \n",
              "105757  2.422390e-06  2.029416e-07  6.218436e-06  0.036982  0.028014   \n",
              "105758  6.060577e-07  1.999436e-07  9.895764e-07  0.046405  0.017922   \n",
              "105759  0.000000e+00  2.431643e-06  9.883298e-07  0.033489  0.041909   \n",
              "\n",
              "        joint_28  joint_29  joint_30    label  \n",
              "0       0.026798  0.027815       0.5  no_pain  \n",
              "1       0.013377  0.013716       0.5  no_pain  \n",
              "2       0.024097  0.023105       0.5  no_pain  \n",
              "3       0.028613  0.024648       0.5  no_pain  \n",
              "4       0.033026  0.025328       0.5  no_pain  \n",
              "...          ...       ...       ...      ...  \n",
              "105755  0.173566  0.221921       0.5  no_pain  \n",
              "105756  0.075945  0.116763       0.5  no_pain  \n",
              "105757  0.075978  0.078339       0.5  no_pain  \n",
              "105758  0.097109  0.106807       0.5  no_pain  \n",
              "105759  0.084751  0.163532       0.5  no_pain  \n",
              "\n",
              "[79680 rows x 41 columns]"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEWHqic_7Tnr",
        "outputId": "0827d071-17a4-451d-e100-47ef04c9ed92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.9600490053935573)"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_no_pain = data[data['label'] == 'no_pain']\n",
        "data_no_pain['joint_00'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5iE2M_b8T_R",
        "outputId": "f90a0fce-09c1-46ed-b3c8-0cae47b7299c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.03259213768774184)"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_no_pain['joint_00'].var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gySJCMPg7W3s",
        "outputId": "52bd0f35-baf4-440d-da6f-c87e919b286a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.8776655637118013)"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_low_pain = data[data['label'] == 'low_pain']\n",
        "data_low_pain['joint_00'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "YkF51CmhQDW5"
      },
      "outputs": [],
      "source": [
        "scale_columns = [col for col in data.columns\n",
        "                 if col != 'sample_index' and col != 'joint_30' and col != 'label']\n",
        "\n",
        "# Calculate the minimum and maximum values from the training data only\n",
        "mins_train = df_train[scale_columns].min()\n",
        "maxs_train = df_train[scale_columns].max()\n",
        "\n",
        "mins_val = df_val[scale_columns].min()\n",
        "maxs_val = df_val[scale_columns].max()\n",
        "\n",
        "mins_test = df_test[scale_columns].min()\n",
        "maxs_test = df_test[scale_columns].max()\n",
        "\n",
        "# Apply normalisation to the specified columns in all datasets\n",
        "for column in scale_columns:\n",
        "    if maxs_train[column] != mins_train[column] and mins_val[column] != maxs_val[column] and mins_test[column] != maxs_test[column]:\n",
        "      df_train[column] = (df_train[column] - mins_train[column]) / (maxs_train[column] - mins_train[column])\n",
        "\n",
        "      # Normalise the validation set\n",
        "      df_val[column] = (df_val[column] - mins_val[column]) / (maxs_val[column] - mins_val[column])\n",
        "\n",
        "      # Normalise the test set\n",
        "      df_test[column] = (df_test[column] - mins_test[column]) / (maxs_test[column] - mins_test[column])\n",
        "\n",
        "    # elif column == 'n_hands' or column == 'n_eyes' or column == 'n_legs':\n",
        "    #   df_train[column] = 0.5\n",
        "    #   df_val[column] = 0.5\n",
        "    #   df_test[column] = 0.5\n",
        "\n",
        "# Check if the n_legs, n_hands, n_eyes columns have nan values after normalization\n",
        "for col in ['n_legs', 'n_hands', 'n_eyes']:\n",
        "    if df_train[col].isnull().any():\n",
        "        df_train[col] = 1.0\n",
        "    if df_val[col].isnull().any():\n",
        "        df_val[col] = 1.0\n",
        "    if df_test[col].isnull().any():\n",
        "        df_test[col] = 1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(np.float64(1.0), np.float64(1.0))"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['n_eyes'].max(), df_train['n_eyes'].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "R-cyjeAuYt4D",
        "outputId": "35b4f68a-acbd-48dc-b117-b2e549b26811"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "      <th>joint_30</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.777046</td>\n",
              "      <td>...</td>\n",
              "      <td>1.503263e-06</td>\n",
              "      <td>1.052579e-04</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.014214</td>\n",
              "      <td>0.011376</td>\n",
              "      <td>0.018978</td>\n",
              "      <td>0.020291</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.006289</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.805855</td>\n",
              "      <td>...</td>\n",
              "      <td>4.403064e-07</td>\n",
              "      <td>1.584208e-04</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009473</td>\n",
              "      <td>0.010006</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.012579</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.767110</td>\n",
              "      <td>...</td>\n",
              "      <td>1.575589e-08</td>\n",
              "      <td>3.805628e-05</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.013097</td>\n",
              "      <td>0.006830</td>\n",
              "      <td>0.017065</td>\n",
              "      <td>0.016856</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.018868</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.665528</td>\n",
              "      <td>...</td>\n",
              "      <td>3.352260e-07</td>\n",
              "      <td>4.862392e-05</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009505</td>\n",
              "      <td>0.006274</td>\n",
              "      <td>0.020264</td>\n",
              "      <td>0.017981</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.025157</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.773829</td>\n",
              "      <td>...</td>\n",
              "      <td>1.885071e-08</td>\n",
              "      <td>4.086358e-05</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.004216</td>\n",
              "      <td>0.002132</td>\n",
              "      <td>0.023389</td>\n",
              "      <td>0.018477</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105755</th>\n",
              "      <td>660</td>\n",
              "      <td>0.974843</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.746465</td>\n",
              "      <td>...</td>\n",
              "      <td>1.739834e-07</td>\n",
              "      <td>7.708907e-08</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.006255</td>\n",
              "      <td>0.022634</td>\n",
              "      <td>0.122919</td>\n",
              "      <td>0.161896</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105756</th>\n",
              "      <td>660</td>\n",
              "      <td>0.981132</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.729322</td>\n",
              "      <td>...</td>\n",
              "      <td>1.741445e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.021736</td>\n",
              "      <td>0.010761</td>\n",
              "      <td>0.053784</td>\n",
              "      <td>0.085181</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105757</th>\n",
              "      <td>660</td>\n",
              "      <td>0.987421</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.790338</td>\n",
              "      <td>...</td>\n",
              "      <td>1.742954e-07</td>\n",
              "      <td>6.375097e-05</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.030063</td>\n",
              "      <td>0.023592</td>\n",
              "      <td>0.053808</td>\n",
              "      <td>0.057150</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105758</th>\n",
              "      <td>660</td>\n",
              "      <td>0.993711</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.750993</td>\n",
              "      <td>...</td>\n",
              "      <td>1.744361e-07</td>\n",
              "      <td>1.594985e-05</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.037765</td>\n",
              "      <td>0.015093</td>\n",
              "      <td>0.068772</td>\n",
              "      <td>0.077918</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105759</th>\n",
              "      <td>660</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.715698</td>\n",
              "      <td>...</td>\n",
              "      <td>1.745665e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.027207</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>0.060020</td>\n",
              "      <td>0.119300</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>79680 rows √ó 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        sample_index      time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
              "0                  0  0.000000            1.0            0.0            1.0   \n",
              "1                  0  0.006289            1.0            1.0            1.0   \n",
              "2                  0  0.012579            1.0            0.0            1.0   \n",
              "3                  0  0.018868            1.0            1.0            1.0   \n",
              "4                  0  0.025157            1.0            1.0            1.0   \n",
              "...              ...       ...            ...            ...            ...   \n",
              "105755           660  0.974843            1.0            1.0            0.0   \n",
              "105756           660  0.981132            1.0            1.0            0.0   \n",
              "105757           660  0.987421            0.0            1.0            1.0   \n",
              "105758           660  0.993711            1.0            1.0            1.0   \n",
              "105759           660  1.000000            1.0            1.0            1.0   \n",
              "\n",
              "        pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...      joint_22  \\\n",
              "0                 0.5     1.0      1.0     1.0  0.777046  ...  1.503263e-06   \n",
              "1                 1.0     1.0      1.0     1.0  0.805855  ...  4.403064e-07   \n",
              "2                 1.0     1.0      1.0     1.0  0.767110  ...  1.575589e-08   \n",
              "3                 1.0     1.0      1.0     1.0  0.665528  ...  3.352260e-07   \n",
              "4                 1.0     1.0      1.0     1.0  0.773829  ...  1.885071e-08   \n",
              "...               ...     ...      ...     ...       ...  ...           ...   \n",
              "105755            0.0     1.0      1.0     1.0  0.746465  ...  1.739834e-07   \n",
              "105756            1.0     1.0      1.0     1.0  0.729322  ...  1.741445e-07   \n",
              "105757            1.0     1.0      1.0     1.0  0.790338  ...  1.742954e-07   \n",
              "105758            1.0     1.0      1.0     1.0  0.750993  ...  1.744361e-07   \n",
              "105759            0.0     1.0      1.0     1.0  0.715698  ...  1.745665e-07   \n",
              "\n",
              "            joint_23  joint_24  joint_25  joint_26  joint_27  joint_28  \\\n",
              "0       1.052579e-04  0.000405  0.000004  0.014214  0.011376  0.018978   \n",
              "1       1.584208e-04  0.000001  0.000000  0.010748  0.000000  0.009473   \n",
              "2       3.805628e-05  0.000085  0.000003  0.013097  0.006830  0.017065   \n",
              "3       4.862392e-05  0.000002  0.000000  0.009505  0.006274  0.020264   \n",
              "4       4.086358e-05  0.000002  0.000007  0.004216  0.002132  0.023389   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "105755  7.708907e-08  0.000013  0.000001  0.006255  0.022634  0.122919   \n",
              "105756  0.000000e+00  0.000007  0.000004  0.021736  0.010761  0.053784   \n",
              "105757  6.375097e-05  0.000007  0.000007  0.030063  0.023592  0.053808   \n",
              "105758  1.594985e-05  0.000007  0.000001  0.037765  0.015093  0.068772   \n",
              "105759  0.000000e+00  0.000085  0.000001  0.027207  0.035294  0.060020   \n",
              "\n",
              "        joint_29  joint_30    label  \n",
              "0       0.020291       0.5  no_pain  \n",
              "1       0.010006       0.5  no_pain  \n",
              "2       0.016856       0.5  no_pain  \n",
              "3       0.017981       0.5  no_pain  \n",
              "4       0.018477       0.5  no_pain  \n",
              "...          ...       ...      ...  \n",
              "105755  0.161896       0.5  no_pain  \n",
              "105756  0.085181       0.5  no_pain  \n",
              "105757  0.057150       0.5  no_pain  \n",
              "105758  0.077918       0.5  no_pain  \n",
              "105759  0.119300       0.5  no_pain  \n",
              "\n",
              "[79680 rows x 41 columns]"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NiqXdpBj0089"
      },
      "outputs": [],
      "source": [
        "# Define a function to inspect sensor data for a specific label\n",
        "def inspect_label(label, df):\n",
        "    # Filter the DataFrame for the specified label and limit to 159 rows\n",
        "    data = df[df['label'] == label][['pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4']][:159]\n",
        "\n",
        "    # Plot the sensor data for each axis\n",
        "    axis = data.plot(subplots=True, figsize=(17, 9), title=label)\n",
        "\n",
        "    # Adjust legend position for each subplot\n",
        "    for ax in axis:\n",
        "        ax.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9Pp8l1bo8Rx"
      },
      "source": [
        "### 4.4 Feature Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDhUJUrkQDW6",
        "outputId": "51693a47-f2d4-479c-f0cc-87c702d83c0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training labels: {'no_pain': 385, 'low_pain': 71, 'high_pain': 42}\n",
            "Validation labels: {'no_pain': 124, 'low_pain': 22, 'high_pain': 14}\n",
            "Test labels: {'no_pain': 2, 'low_pain': 1, 'high_pain': 0}\n"
          ]
        }
      ],
      "source": [
        "# Initialise a dictionary to count occurrences of each activity in the training set\n",
        "training_labels = {\n",
        "    'no_pain': 0,\n",
        "    'low_pain': 0,\n",
        "    'high_pain': 0\n",
        "}\n",
        "\n",
        "# Count occurrences of each activity for unique IDs in the training set\n",
        "for id in df_train['sample_index'].unique():\n",
        "    label = df_train[df_train['sample_index'] == id]['label'].values[0]\n",
        "    training_labels[label] += 1\n",
        "\n",
        "\n",
        "#if 'joint_30' in df_train.columns:\n",
        "#    df_train = df_train.drop(columns=['joint_30']) # we deleted this joint since has no final effect during training\n",
        "\n",
        "# Print the distribution of training labels\n",
        "print('Training labels:', training_labels)\n",
        "\n",
        "# Initialise a dictionary to count occurrences of each activity in the training set\n",
        "val_labels = {\n",
        "    'no_pain': 0,\n",
        "    'low_pain': 0,\n",
        "    'high_pain': 0\n",
        "}\n",
        "\n",
        "# Count occurrences of each activity for unique IDs in the training set\n",
        "for id in df_val['sample_index'].unique():\n",
        "    label = df_val[df_val['sample_index'] == id]['label'].values[0]\n",
        "    val_labels[label] += 1\n",
        "\n",
        "\n",
        "#if 'joint_30' in df_val.columns:\n",
        "#    df_val = df_val.drop(columns=['joint_30']) # we deleted this joint since has no final effect during training\n",
        "\n",
        "# Print the distribution of validation labels\n",
        "print('Validation labels:', val_labels)\n",
        "\n",
        "# Initialise a dictionary to count occurrences of each activity in the test set\n",
        "test_labels = {\n",
        "    'no_pain': 0,\n",
        "    'low_pain': 0,\n",
        "    'high_pain': 0\n",
        "}\n",
        "\n",
        "# Count occurrences of each activity for unique IDs in the test set\n",
        "for id in df_test['sample_index'].unique():\n",
        "    label = df_test[df_test['sample_index'] == id]['label'].values[0]\n",
        "    test_labels[label] += 1\n",
        "#if 'joint_30' in df_test.columns:\n",
        "#    df_test = df_test.drop(columns=['joint_30']) # we deleted this joint since has no final effect during training\n",
        "\n",
        "# Print the distribution of test labels\n",
        "print('Test labels:', test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDuw27RUo8Rx"
      },
      "source": [
        "### 4.5 Label Distribution Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DT3wxqdLQDW7"
      },
      "outputs": [],
      "source": [
        "# Define a training mapping of label names to integer labels\n",
        "train_label_mapping = {\n",
        "    'no_pain': 0,\n",
        "    'low_pain': 1,\n",
        "    'high_pain': 2\n",
        "}\n",
        "\n",
        "# Map label names to integers in the training set\n",
        "df_train['label'] = df_train['label'].map(train_label_mapping)\n",
        "\n",
        "# Define a validation mapping of label names to integer labels\n",
        "val_label_mapping = {\n",
        "    'no_pain': 0,\n",
        "    'low_pain': 1,\n",
        "    'high_pain': 2\n",
        "}\n",
        "\n",
        "# Map label names to integers in the validation set\n",
        "df_val['label'] = df_val['label'].map(val_label_mapping)\n",
        "\n",
        "test_label_mapping = {\n",
        "    'no_pain': 0,\n",
        "    'low_pain': 1,\n",
        "    'high_pain': 2\n",
        "}\n",
        "\n",
        "# Map label names to integers in the test set\n",
        "df_test['label'] = df_test['label'].map(test_label_mapping)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOi0Yx5bo8Ry"
      },
      "source": [
        "<a id=\"sequence-building\"></a>\n",
        "## 5. Sequence Building\n",
        "\n",
        "Convert variable-length time-series into fixed-size windows for RNN input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3qv_eAbDQDW7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define window and stride boolean variable -> if True, during training we will visit more time the same pirate with overlapping windows\n",
        "# if False, each pirate will be visited only once during training\n",
        "one_pirate_window = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sbmKJyH-QDW7"
      },
      "outputs": [],
      "source": [
        "if one_pirate_window:\n",
        "    # Define the window size\n",
        "    WINDOW_SIZE = 30 # before: 80\n",
        "\n",
        "    # Stride size\n",
        "    STRIDE = 2\n",
        "else:\n",
        "    # Define the window size -> select an higher window size in order to get more pirates\n",
        "    WINDOW_SIZE = 160\n",
        "\n",
        "    # Stride size\n",
        "    STRIDE = 160"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut3JifRfo8Ry"
      },
      "source": [
        "### 5.1 Window & Stride Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dY-ksbv0QDW8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "  GENERAL COMMENTS:\n",
        "  in this function we are restricting for each user data the number of samples of recorded data to a constant\n",
        "  value (window size), since every user data could be composed by different numbers of timestep. Therefore we are\n",
        "  \"normalizing\" the timesteps of a constant window size. Additionally is also defined a stride variable, which if is equal to\n",
        "  the window size, then we are not taking overlapping timestamp samples, instead if stride < window, we are letting some samples\n",
        "  to overlap in such a way that the RNN or other kind of NN architecture will analyze better the context.\n",
        "\"\"\"\n",
        "\n",
        "# Define a function to build sequences from the dataset\n",
        "def build_sequences(df, window=200, stride=200):\n",
        "    # Sanity check to ensure the window is divisible by the stride\n",
        "    assert window % stride == 0 # checks if the window size is divisible by the stride\n",
        "\n",
        "    # Initialise lists to store sequences and their corresponding labels\n",
        "    dataset = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate over unique IDs in the DataFrame\n",
        "    for id in df['sample_index'].unique():\n",
        "\n",
        "        # Extract pirate sample index data for the current sample index\n",
        "        columns = [col for col in df.columns if col not in ['sample_index', 'label', 'time']]\n",
        "\n",
        "        temp = df[df['sample_index'] == id][columns].values\n",
        "\n",
        "        # Retrieve the label for the current pirate\n",
        "        label = df[df['sample_index'] == id]['label'].values[0]\n",
        "\n",
        "        # Calculate padding length to ensure full windows\n",
        "        padding_len = window - len(temp) % window\n",
        "\n",
        "        # Create zero padding and concatenate with the data\n",
        "        padding = np.zeros((padding_len, len(columns)), dtype='float32')\n",
        "        temp = np.concatenate((temp, padding))\n",
        "\n",
        "        # Build feature windows and associate them with labels\n",
        "        idx = 0\n",
        "        while idx + window <= len(temp):\n",
        "            dataset.append(temp[idx:idx + window])\n",
        "            labels.append(label)\n",
        "            idx += stride\n",
        "\n",
        "    # Convert lists to numpy arrays for further processing\n",
        "    dataset = np.array(dataset)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return dataset, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUdcu3oGo8Ry"
      },
      "source": [
        "### 5.2 Build Sequences Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPVEgwEmQDW8",
        "outputId": "e63c598c-debf-40d8-d7b7-c0e8266d82f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((37848, 30, 21), (37848,), (12160, 30, 21), (12160,), (228, 30, 21), (228,))"
            ]
          },
          "execution_count": 236,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate sequences and labels for the training set\n",
        "X_train, y_train = build_sequences(df_train, WINDOW_SIZE, STRIDE)\n",
        "\n",
        "# Generate sequences and labels for the validation set\n",
        "X_val, y_val = build_sequences(df_val, WINDOW_SIZE, STRIDE)\n",
        "\n",
        "# Generate sequences and labels for the test set\n",
        "X_test, y_test = build_sequences(df_test, WINDOW_SIZE, STRIDE)\n",
        "\n",
        "# Print the shapes of the generated datasets and their labels\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utsTrSH5o8Ry"
      },
      "source": [
        "### 5.3 Generate Sequences for Train/Val/Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1mmtqJwQDW8"
      },
      "outputs": [],
      "source": [
        "# Convert dataset into float32 for PyTorch compatibility\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# y_train = y_train.astype('int64')\n",
        "# y_val = y_val.astype('int64')\n",
        "# y_test = y_test.astype('int64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jLnJ0YMo8Rz"
      },
      "source": [
        "### 5.4 Data Type Conversion & Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxfz2MegQDW8"
      },
      "outputs": [],
      "source": [
        "# Define the input shape based on the training data\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "# Define the number of classes based on the categorical labels\n",
        "num_classes = len(np.unique(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcSpP3DBQDW8"
      },
      "outputs": [],
      "source": [
        "# Discard nan values from the dataset\n",
        "if np.isnan(X_train).any() or np.isnan(X_val).any() or np.isnan(X_test).any():\n",
        "    X_train = np.nan_to_num(X_train)\n",
        "    X_val = np.nan_to_num(X_val)\n",
        "    X_test = np.nan_to_num(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s45svGakQDW8"
      },
      "outputs": [],
      "source": [
        "# Convert numpy arrays to PyTorch datasets (pairs features with labels)\n",
        "train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b-SGD2to8Rz"
      },
      "source": [
        "<a id=\"dataloaders\"></a>\n",
        "## 6. DataLoaders\n",
        "\n",
        "Create PyTorch DataLoaders for efficient batching and parallel loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2dd26aqQDW8"
      },
      "outputs": [],
      "source": [
        "# Define the batch size, which is the number of samples in each batch\n",
        "BATCH_SIZE = 512 # we can change it depending on the GPU RAM available (by default 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CPWMPHOQDW9"
      },
      "outputs": [],
      "source": [
        "def make_loader(ds, batch_size, shuffle, drop_last):\n",
        "    # Determine optimal number of worker processes for data loading\n",
        "    cpu_cores = os.cpu_count() or 2\n",
        "    num_workers = max(2, min(4, cpu_cores))\n",
        "\n",
        "    # Create DataLoader with performance optimizations\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,  # Faster GPU transfer\n",
        "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
        "        prefetch_factor=4,  # Load 4 batches ahead\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPlQI3R8QDW9"
      },
      "outputs": [],
      "source": [
        "# Create data loaders with different settings for each phase\n",
        "train_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "val_loader   = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "test_loader  = make_loader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33LHsppfQDW-",
        "outputId": "42835e50-9878-498c-b9ae-8d07d89bd680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features batch shape: torch.Size([512, 30, 21])\n",
            "Labels batch shape: torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "# Get one batch from the training data loader\n",
        "for xb, yb in train_loader:\n",
        "    print(\"Features batch shape:\", xb.shape)\n",
        "    print(\"Labels batch shape:\", yb.shape)\n",
        "    break # Stop after getting one batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl4n83GrQDW-"
      },
      "outputs": [],
      "source": [
        "def recurrent_summary(model, input_size):\n",
        "    \"\"\"\n",
        "    Custom summary function that emulates torchinfo's output while correctly\n",
        "    counting parameters for RNN/GRU/LSTM layers.\n",
        "\n",
        "    This function is designed for models whose direct children are\n",
        "    nn.Linear, nn.RNN, nn.GRU, or nn.LSTM layers.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to analyze.\n",
        "        input_size (tuple): Shape of the input tensor (e.g., (seq_len, features)).\n",
        "    \"\"\"\n",
        "\n",
        "    # Dictionary to store output shapes captured by forward hooks\n",
        "    output_shapes = {}\n",
        "    # List to track hook handles for later removal\n",
        "    hooks = []\n",
        "\n",
        "    def get_hook(name):\n",
        "        \"\"\"Factory function to create a forward hook for a specific module.\"\"\"\n",
        "        def hook(module, input, output):\n",
        "            # Handle RNN layer outputs (returns a tuple)\n",
        "            if isinstance(output, tuple):\n",
        "                # output[0]: all hidden states with shape (batch, seq_len, hidden*directions)\n",
        "                shape1 = list(output[0].shape)\n",
        "                shape1[0] = -1  # Replace batch dimension with -1\n",
        "\n",
        "                # output[1]: final hidden state h_n (or tuple (h_n, c_n) for LSTM)\n",
        "                if isinstance(output[1], tuple):  # LSTM case: (h_n, c_n)\n",
        "                    shape2 = list(output[1][0].shape)  # Extract h_n only\n",
        "                else:  # RNN/GRU case: h_n only\n",
        "                    shape2 = list(output[1].shape)\n",
        "\n",
        "                # Replace batch dimension (middle position) with -1\n",
        "                shape2[1] = -1\n",
        "\n",
        "                output_shapes[name] = f\"[{shape1}, {shape2}]\"\n",
        "\n",
        "            # Handle standard layer outputs (e.g., Linear)\n",
        "            else:\n",
        "                shape = list(output.shape)\n",
        "                shape[0] = -1  # Replace batch dimension with -1\n",
        "                output_shapes[name] = f\"{shape}\"\n",
        "        return hook\n",
        "\n",
        "    # 1. Determine the device where model parameters reside\n",
        "    try:\n",
        "        device = next(model.parameters()).device\n",
        "    except StopIteration:\n",
        "        device = torch.device(\"cpu\")  # Fallback for models without parameters\n",
        "\n",
        "    # 2. Create a dummy input tensor with batch_size=1\n",
        "    dummy_input = torch.randn(1, *input_size).to(device)\n",
        "\n",
        "    # 3. Register forward hooks on target layers\n",
        "    # Iterate through direct children of the model (e.g., self.rnn, self.classifier)\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, (nn.Linear, nn.RNN, nn.GRU, nn.LSTM)):\n",
        "            # Register the hook and store its handle for cleanup\n",
        "            hook_handle = module.register_forward_hook(get_hook(name))\n",
        "            hooks.append(hook_handle)\n",
        "\n",
        "    # 4. Execute a dummy forward pass in evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            model(dummy_input)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during dummy forward pass: {e}\")\n",
        "            # Clean up hooks even if an error occurs\n",
        "            for h in hooks:\n",
        "                h.remove()\n",
        "            return\n",
        "\n",
        "    # 5. Remove all registered hooks\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    # --- 6. Print the summary table ---\n",
        "\n",
        "    print(\"-\" * 79)\n",
        "    # Column headers\n",
        "    print(f\"{'Layer (type)':<25} {'Output Shape':<28} {'Param #':<18}\")\n",
        "    print(\"=\" * 79)\n",
        "\n",
        "    total_params = 0\n",
        "    total_trainable_params = 0\n",
        "\n",
        "    # Iterate through modules again to collect and display parameter information\n",
        "    for name, module in model.named_children():\n",
        "        if name in output_shapes:\n",
        "            # Count total and trainable parameters for this module\n",
        "            module_params = sum(p.numel() for p in module.parameters())\n",
        "            trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "\n",
        "            total_params += module_params\n",
        "            total_trainable_params += trainable_params\n",
        "\n",
        "            # Format strings for display\n",
        "            layer_name = f\"{name} ({type(module).__name__})\"\n",
        "            output_shape_str = str(output_shapes[name])\n",
        "            params_str = f\"{trainable_params:,}\"\n",
        "\n",
        "            print(f\"{layer_name:<25} {output_shape_str:<28} {params_str:<15}\")\n",
        "\n",
        "    print(\"=\" * 79)\n",
        "    print(f\"Total params: {total_params:,}\")\n",
        "    print(f\"Trainable params: {total_trainable_params:,}\")\n",
        "    print(f\"Non-trainable params: {total_params - total_trainable_params:,}\")\n",
        "    print(\"-\" * 79)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5VULB4UQDW_"
      },
      "source": [
        "<a id=\"hyperparameters\"></a>\n",
        "## 7. Network Hyperparameters\n",
        "\n",
        "Configure training settings, architecture parameters, and regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a183G6zQDW_"
      },
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 500\n",
        "PATIENCE = 50\n",
        "\n",
        "# Architecture\n",
        "HIDDEN_LAYERS = 2        # Hidden layers\n",
        "HIDDEN_SIZE = 25        # Neurons per layer -> prev hidden size = 128\n",
        "\n",
        "# Regularisation\n",
        "DROPOUT_RATE = 0.3      # Dropout probability\n",
        "\n",
        "# For now disable weight decay\n",
        "L1_LAMBDA = 0.0        # L1 penalty\n",
        "L2_LAMBDA = 1e-2          # L2 penalty\n",
        "\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "\n",
        "# TO GIVE DIFFERENT WEIGHTS TO THE LOSS DEPENDING ON THE INVERSE OF EACH LABEL TOTAL NUMBER:\n",
        "# Set up loss function and optimizer\n",
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "# classes = np.unique(y_train)\n",
        "# class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "# class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "# criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# print(f\"Class weights (order = {classes}): {class_weights.cpu().numpy()}\")\n",
        "\n",
        "\n",
        "# TO GIVE FIXED WEIGHTS TO THE LOSS FUNCTION DEPENDING ON THE LABELS DISTRIBUTION:\n",
        "# weights = torch.tensor([1.0, 1.2, 1.4]).to(device)\n",
        "# criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "\n",
        "# TO NOT CHANGE THE WEIGHTS, BUT WITH LABEL SMOOTHING\n",
        "# criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "\n",
        "# TO WEIGHT MORE THE \"MORE DIFFICULT\" CASES AND THE LESS FREQUENT LABELS:\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.ce = nn.CrossEntropyLoss(weight=alpha, reduction='none')\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = self.ce(inputs, targets)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "        return focal_loss.mean()\n",
        "alpha = None\n",
        "# alpha = torch.tensor([0.7, 1.3, 1.7], dtype=torch.float32, device=device)  # None if we don't want to alterate the weights of each label losses (FocalLoss already do it)\n",
        "criterion = FocalLoss(alpha=alpha, gamma=1.0)  # gamma = 0 it's like Crossentropy(), gamma < 1 it's like in between Crossentropy and FocalLoss,\n",
        "                                               # gamma = 1 it's a good compromise, gamma = 1.5 or gamma = 2 to weight so much the less present labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-RAXl_BQDXA"
      },
      "outputs": [],
      "source": [
        "# Initialize best model tracking variables\n",
        "best_model = None\n",
        "best_performance = float('-inf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouaaN67Ho8R3"
      },
      "source": [
        "<a id=\"model-architecture\"></a>\n",
        "## 8. Model Architecture\n",
        "\n",
        "Custom RNN/LSTM/GRU classifier with configurable bidirectionality and dropout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4I8vKDBo8R4"
      },
      "source": [
        "### 8.1 Recurrent Classifier Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nyxSmz4QDW_"
      },
      "outputs": [],
      "source": [
        "class RecurrentClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Generic RNN classifier (RNN, LSTM, GRU).\n",
        "    Uses the last hidden state for classification.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size,\n",
        "            hidden_size,\n",
        "            num_layers,\n",
        "            num_classes,\n",
        "            rnn_type= RNN_TYPE,        # 'RNN', 'LSTM', or 'GRU'\n",
        "            bidirectional=BIDIRECTIONAL,\n",
        "            dropout_rate=0.2\n",
        "            ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        # Map string name to PyTorch RNN class\n",
        "        rnn_map = {\n",
        "            'RNN': nn.RNN,\n",
        "            'LSTM': nn.LSTM,\n",
        "            'GRU': nn.GRU\n",
        "        }\n",
        "\n",
        "        if rnn_type not in rnn_map:\n",
        "            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
        "\n",
        "        rnn_module = rnn_map[rnn_type]\n",
        "\n",
        "        # Dropout is only applied between layers (if num_layers > 1)\n",
        "        dropout_val = dropout_rate if num_layers > 1 else 0 # dropout between RNN layers, applied for regularization\n",
        "\n",
        "        # Create the recurrent layer\n",
        "        self.rnn = rnn_module(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,       # Input shape: (batch, seq_len, features)\n",
        "            bidirectional=bidirectional, # We are defining a bidirectional RNN since we want to extract also the future contextual information for making better predictions\n",
        "            dropout=dropout_val\n",
        "        )\n",
        "\n",
        "        # Calculate input size for the final classifier\n",
        "        if self.bidirectional:\n",
        "            classifier_input_size = hidden_size * 2 # Concat fwd + bwd\n",
        "        else:\n",
        "            classifier_input_size = hidden_size\n",
        "\n",
        "        # Final classification layer\n",
        "        self.classifier = nn.Linear(classifier_input_size, num_classes) # output layer for classifying\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x shape: (batch_size, seq_length, input_size)\n",
        "        \"\"\"\n",
        "\n",
        "        # rnn_out shape: (batch_size, seq_len, hidden_size * num_directions)\n",
        "        rnn_out, hidden = self.rnn(x) # feeds the input sequence into the RNN layer\n",
        "        # rnn_out -> contains the hidden state output for every timestep\n",
        "\n",
        "        # LSTM returns (h_n, c_n), we only need h_n\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            hidden = hidden[0]  # final hidden state of the last timestep\n",
        "\n",
        "        # hidden shape: (num_layers * num_directions, batch_size, hidden_size)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            # Reshape to (num_layers, 2, batch_size, hidden_size)\n",
        "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
        "\n",
        "            # Concat last fwd (hidden[-1, 0, ...]) and bwd (hidden[-1, 1, ...])\n",
        "            # Final shape: (batch_size, hidden_size * 2)\n",
        "            hidden_to_classify = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
        "        else:\n",
        "            # Take the last layer's hidden state\n",
        "            # Final shape: (batch_size, hidden_size)\n",
        "            hidden_to_classify = hidden[-1]\n",
        "\n",
        "        # Get logits\n",
        "        logits = self.classifier(hidden_to_classify)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLdCrp-qQDXA"
      },
      "source": [
        "<a id=\"training-functions\"></a>\n",
        "## 9. Training Functions\n",
        "\n",
        "Helper functions for training, validation, logging, and early stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QgHx0BHQDXA"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n",
        "    \"\"\"\n",
        "    Perform one complete training epoch through the entire training dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to train\n",
        "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
        "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
        "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
        "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "        l1_lambda (float): Lambda for L1 regularization\n",
        "        l2_lambda (float): Lambda for L2 regularization\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
        "    \"\"\"\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Iterate through training batches\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        # Move data to device (GPU/CPU)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Clear gradients from previous step\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Forward pass with mixed precision (if CUDA available)\n",
        "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "            logits = model(inputs)\n",
        "            loss = criterion(logits, targets)\n",
        "\n",
        "            # Add L1 and L2 regularization\n",
        "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
        "            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
        "            loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n",
        "\n",
        "\n",
        "        # Backward pass with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # Accumulate metrics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        predictions = logits.argmax(dim=1)\n",
        "        all_predictions.append(predictions.cpu().numpy())\n",
        "        all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_f1 = f1_score(\n",
        "        np.concatenate(all_targets),\n",
        "        np.concatenate(all_predictions),\n",
        "        average='weighted'\n",
        "    )\n",
        "\n",
        "    return epoch_loss, epoch_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKsdfMrSo8R4"
      },
      "source": [
        "### 9.1 Train One Epoch Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVlcqfzqQDXA"
      },
      "outputs": [],
      "source": [
        "def validate_one_epoch(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Perform one complete validation epoch through the entire validation dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
        "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
        "        criterion (nn.Module): Loss function used to calculate validation loss\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n",
        "\n",
        "    Note:\n",
        "        This function automatically sets the model to evaluation mode and disables\n",
        "        gradient computation for efficiency during validation.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Disable gradient computation for validation\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            # Move data to device\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass with mixed precision (if CUDA available)\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "                logits = model(inputs)\n",
        "                loss = criterion(logits, targets)\n",
        "\n",
        "            # Accumulate metrics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            predictions = logits.argmax(dim=1)\n",
        "            all_predictions.append(predictions.cpu().numpy())\n",
        "            all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = running_loss / len(val_loader.dataset)\n",
        "    epoch_accuracy = f1_score(\n",
        "        np.concatenate(all_targets),\n",
        "        np.concatenate(all_predictions),\n",
        "        average='weighted'\n",
        "    )\n",
        "\n",
        "    return epoch_loss, epoch_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAGFlt3Fo8R4"
      },
      "source": [
        "### 9.2 Validate One Epoch Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZwJNmCZQDXA"
      },
      "outputs": [],
      "source": [
        "def log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model):\n",
        "    \"\"\"\n",
        "    Log training metrics and model parameters to TensorBoard for visualization.\n",
        "\n",
        "    Args:\n",
        "        writer (SummaryWriter): TensorBoard SummaryWriter object for logging\n",
        "        epoch (int): Current epoch number (used as x-axis in TensorBoard plots)\n",
        "        train_loss (float): Training loss for this epoch\n",
        "        train_f1 (float): Training f1 score for this epoch\n",
        "        val_loss (float): Validation loss for this epoch\n",
        "        val_f1 (float): Validation f1 score for this epoch\n",
        "        model (nn.Module): The neural network model (for logging weights/gradients)\n",
        "\n",
        "    Note:\n",
        "        This function logs scalar metrics (loss/f1 score) and histograms of model\n",
        "        parameters and gradients, which helps monitor training progress and detect\n",
        "        issues like vanishing/exploding gradients.\n",
        "    \"\"\"\n",
        "    # Log scalar metrics\n",
        "    writer.add_scalar('Loss/Training', train_loss, epoch)\n",
        "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
        "    writer.add_scalar('F1/Training', train_f1, epoch)\n",
        "    writer.add_scalar('F1/Validation', val_f1, epoch)\n",
        "\n",
        "    # Log model parameters and gradients\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            # Check if the tensor is not empty before adding a histogram\n",
        "            if param.numel() > 0:\n",
        "                writer.add_histogram(f'{name}/weights', param.data, epoch)\n",
        "            if param.grad is not None:\n",
        "                # Check if the gradient tensor is not empty before adding a histogram\n",
        "                if param.grad.numel() > 0:\n",
        "                    if param.grad is not None and torch.isfinite(param.grad).all():\n",
        "                        writer.add_histogram(f'{name}/gradients', param.grad.data, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOa3T9Pho8R4"
      },
      "source": [
        "### 9.3 Fit  Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgpOY62qQDXB"
      },
      "outputs": [],
      "source": [
        "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
        "        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
        "        restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\"):\n",
        "    \"\"\"\n",
        "    Train the neural network model on the training data and validate on the validation data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to train\n",
        "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
        "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
        "        epochs (int): Number of training epochs\n",
        "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
        "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
        "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "        l1_lambda (float): L1 regularization coefficient (default: 0)\n",
        "        l2_lambda (float): L2 regularization coefficient (default: 0)\n",
        "        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n",
        "        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n",
        "        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n",
        "        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n",
        "        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n",
        "        verbose (int, optional): Frequency of printing training progress (default: 10)\n",
        "        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, training_history) - Trained model and metrics history\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize metrics tracking\n",
        "    training_history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_f1': [], 'val_f1': []\n",
        "    }\n",
        "\n",
        "    # Configure early stopping if patience is set\n",
        "    if patience > 0:\n",
        "        patience_counter = 0\n",
        "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
        "        best_epoch = 0\n",
        "\n",
        "    print(f\"Training {epochs} epochs...\")\n",
        "\n",
        "    # Main training loop: iterate through epochs\n",
        "    for epoch in range(1, epochs + 1):\n",
        "\n",
        "        # Forward pass through training data, compute gradients, update weights\n",
        "        train_loss, train_f1 = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n",
        "        )\n",
        "\n",
        "        # Evaluate model on validation data without updating weights\n",
        "        val_loss, val_f1 = validate_one_epoch(\n",
        "            model, val_loader, criterion, device\n",
        "        )\n",
        "\n",
        "        # Store metrics for plotting and analysis\n",
        "        training_history['train_loss'].append(train_loss)\n",
        "        training_history['val_loss'].append(val_loss)\n",
        "        training_history['train_f1'].append(train_f1)\n",
        "        training_history['val_f1'].append(val_f1)\n",
        "\n",
        "        # Write metrics to TensorBoard for visualization\n",
        "        if writer is not None:\n",
        "            log_metrics_to_tensorboard(\n",
        "                writer, epoch, train_loss, train_f1, val_loss, val_f1, model\n",
        "            )\n",
        "\n",
        "        # Print progress every N epochs or on first epoch\n",
        "        if verbose > 0:\n",
        "            if epoch % verbose == 0 or epoch == 1:\n",
        "                print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
        "                    f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n",
        "                    f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n",
        "\n",
        "        # Early stopping logic: monitor metric and save best model\n",
        "        if patience > 0:\n",
        "            current_metric = training_history[evaluation_metric][-1]\n",
        "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
        "\n",
        "            if is_improvement:\n",
        "                best_metric = current_metric\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), f\"{models_dir}/{experiment_name}_model.pt\")\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(f\"Early stopping triggered after {epoch} epochs.\")\n",
        "                    break\n",
        "\n",
        "    # Restore best model weights if early stopping was used\n",
        "    if restore_best_weights and patience > 0:\n",
        "        model.load_state_dict(torch.load(f\"{models_dir}/{experiment_name}_model.pt\"))\n",
        "        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
        "\n",
        "    # Save final model if no early stopping\n",
        "    if patience == 0:\n",
        "        torch.save(model.state_dict(), f\"{models_dir}/{experiment_name}_model.pt\")\n",
        "\n",
        "    # Close TensorBoard writer\n",
        "    if writer is not None:\n",
        "        writer.close()\n",
        "\n",
        "    return model, training_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8g2Pr_To8R5"
      },
      "source": [
        "### 9.4 Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00tkWSbCQDXB",
        "outputId": "6afcadfb-ccc9-4a88-999a-5bcf9f466a98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 30, 50], [4, -1, 25]]  25,000         \n",
            "classifier (Linear)       [-1, 3]                      153            \n",
            "===============================================================================\n",
            "Total params: 25,153\n",
            "Trainable params: 25,153\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.4664, F1 Score=0.6741 | Val: Loss=0.4201, F1 Score=0.6768\n",
            "Epoch   2/500 | Train: Loss=0.3643, F1 Score=0.7349 | Val: Loss=0.2966, F1 Score=0.7832\n",
            "Epoch   3/500 | Train: Loss=0.2629, F1 Score=0.8271 | Val: Loss=0.2364, F1 Score=0.8222\n",
            "Epoch   4/500 | Train: Loss=0.1974, F1 Score=0.8704 | Val: Loss=0.2106, F1 Score=0.8714\n",
            "Epoch   5/500 | Train: Loss=0.1616, F1 Score=0.8954 | Val: Loss=0.1945, F1 Score=0.8802\n",
            "Epoch   6/500 | Train: Loss=0.1365, F1 Score=0.9118 | Val: Loss=0.2133, F1 Score=0.8910\n",
            "Epoch   7/500 | Train: Loss=0.1160, F1 Score=0.9241 | Val: Loss=0.2048, F1 Score=0.8880\n",
            "Epoch   8/500 | Train: Loss=0.0938, F1 Score=0.9406 | Val: Loss=0.2234, F1 Score=0.8987\n",
            "Epoch   9/500 | Train: Loss=0.0794, F1 Score=0.9496 | Val: Loss=0.2431, F1 Score=0.9067\n",
            "Epoch  10/500 | Train: Loss=0.0724, F1 Score=0.9525 | Val: Loss=0.2467, F1 Score=0.9045\n",
            "Epoch  11/500 | Train: Loss=0.0678, F1 Score=0.9549 | Val: Loss=0.2862, F1 Score=0.9018\n",
            "Epoch  12/500 | Train: Loss=0.0575, F1 Score=0.9611 | Val: Loss=0.2860, F1 Score=0.9033\n",
            "Epoch  13/500 | Train: Loss=0.0557, F1 Score=0.9627 | Val: Loss=0.2728, F1 Score=0.9079\n",
            "Epoch  14/500 | Train: Loss=0.0552, F1 Score=0.9617 | Val: Loss=0.2779, F1 Score=0.9070\n",
            "Epoch  15/500 | Train: Loss=0.0459, F1 Score=0.9674 | Val: Loss=0.2764, F1 Score=0.9149\n",
            "Epoch  16/500 | Train: Loss=0.0402, F1 Score=0.9718 | Val: Loss=0.3139, F1 Score=0.9096\n",
            "Epoch  17/500 | Train: Loss=0.0373, F1 Score=0.9736 | Val: Loss=0.3254, F1 Score=0.9111\n",
            "Epoch  18/500 | Train: Loss=0.0343, F1 Score=0.9750 | Val: Loss=0.3177, F1 Score=0.9045\n",
            "Epoch  19/500 | Train: Loss=0.0329, F1 Score=0.9765 | Val: Loss=0.2968, F1 Score=0.9057\n",
            "Epoch  20/500 | Train: Loss=0.0354, F1 Score=0.9759 | Val: Loss=0.3144, F1 Score=0.9094\n",
            "Epoch  21/500 | Train: Loss=0.0302, F1 Score=0.9784 | Val: Loss=0.2897, F1 Score=0.9173\n",
            "Epoch  22/500 | Train: Loss=0.0282, F1 Score=0.9804 | Val: Loss=0.3291, F1 Score=0.9090\n",
            "Epoch  23/500 | Train: Loss=0.0255, F1 Score=0.9819 | Val: Loss=0.3390, F1 Score=0.9094\n",
            "Epoch  24/500 | Train: Loss=0.0325, F1 Score=0.9778 | Val: Loss=0.3116, F1 Score=0.8998\n",
            "Epoch  25/500 | Train: Loss=0.0203, F1 Score=0.9860 | Val: Loss=0.3775, F1 Score=0.8917\n",
            "Epoch  26/500 | Train: Loss=0.0236, F1 Score=0.9836 | Val: Loss=0.3341, F1 Score=0.9039\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Create model and display architecture with parameter count\n",
        "rnn_model = RecurrentClassifier(\n",
        "    input_size=input_shape[-1], # Pass the number of features\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    num_layers=HIDDEN_LAYERS,\n",
        "    num_classes=num_classes,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        "    bidirectional=BIDIRECTIONAL,\n",
        "    rnn_type=RNN_TYPE\n",
        "    ).to(device)\n",
        "recurrent_summary(rnn_model, input_size=input_shape)\n",
        "\n",
        "# Set up TensorBoard logging and save model architecture\n",
        "writer = SummaryWriter(f\"./{logs_dir}/{EXPERIMENT_NAME}\")\n",
        "x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n",
        "writer.add_graph(rnn_model, x)\n",
        "\n",
        "# Define optimizer with L2 regularization\n",
        "optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
        "\n",
        "# Enable mixed precision training for GPU acceleration\n",
        "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "# Train model and track training history\n",
        "rnn_model, training_history = fit(\n",
        "    model=rnn_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    l1_lambda=L1_LAMBDA,\n",
        "    epochs=EPOCHS,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scaler=scaler,\n",
        "    device=device,\n",
        "    writer=writer,\n",
        "    verbose=1,\n",
        "    experiment_name=EXPERIMENT_NAME,\n",
        "    patience=PATIENCE\n",
        "    )\n",
        "\n",
        "# Update best model if current performance is superior\n",
        "if training_history['val_f1'][-1] > best_performance:\n",
        "    best_model = rnn_model\n",
        "    best_performance = training_history['val_f1'][-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb45ROPxo8R5"
      },
      "source": [
        "<a id=\"evaluation\"></a>\n",
        "## 11. Evaluation & Metrics\n",
        "\n",
        "Visualize training history and compute validation metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA9iOhcdo8R5"
      },
      "source": [
        "### 11.1 Training History Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aK2k-TrcWKz7"
      },
      "outputs": [],
      "source": [
        "# @title Plot Hitory\n",
        "# Create a figure with two side-by-side subplots (two columns)\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n",
        "\n",
        "# Plot of training and validation loss on the first axis\n",
        "ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
        "ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n",
        "ax1.set_title('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Plot of training and validation accuracy on the second axis\n",
        "ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
        "ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n",
        "ax2.set_title('F1 Score')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# Adjust the layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(right=0.85)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BnkLnkjZYGq2"
      },
      "outputs": [],
      "source": [
        "# @title Plot Confusion Matrix\n",
        "# Collect predictions and ground truth labels\n",
        "val_preds, val_targets = [], []\n",
        "with torch.no_grad():  # Disable gradient computation for inference\n",
        "    for xb, yb in val_loader:\n",
        "        xb = xb.to(device)\n",
        "\n",
        "        # Forward pass: get model predictions\n",
        "        logits = rnn_model(xb)\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        # Store batch results\n",
        "        val_preds.append(preds)\n",
        "        val_targets.append(yb.numpy())\n",
        "\n",
        "# Combine all batches into single arrays\n",
        "val_preds = np.concatenate(val_preds)\n",
        "val_targets = np.concatenate(val_targets)\n",
        "\n",
        "# Calculate overall validation metrics\n",
        "val_acc = accuracy_score(val_targets, val_preds)\n",
        "val_prec = precision_score(val_targets, val_preds, average='weighted')\n",
        "val_rec = recall_score(val_targets, val_preds, average='weighted')\n",
        "val_f1 = f1_score(val_targets, val_preds, average='weighted')\n",
        "print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n",
        "print(f\"Precision over the validation set: {val_prec:.4f}\")\n",
        "print(f\"Recall over the validation set: {val_rec:.4f}\")\n",
        "print(f\"F1 score over the validation set: {val_f1:.4f}\")\n",
        "\n",
        "# Generate confusion matrix for detailed error analysis\n",
        "cm = confusion_matrix(val_targets, val_preds)\n",
        "\n",
        "# Create numeric labels for heatmap annotation\n",
        "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
        "\n",
        "# Visualise confusion matrix\n",
        "plt.figure(figsize=(8, 7))\n",
        "sns.heatmap(cm, annot=labels, fmt='',\n",
        "            cmap='Blues')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix ‚Äî Validation Set')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrmdKvTDmtvF"
      },
      "source": [
        "## K-fold Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEDRAxhUoiRL"
      },
      "outputs": [],
      "source": [
        "# Modified version of k_shuffle_split_cross_validation_round_rnn that returns models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "\n",
        "def k_shuffle_split_cross_validation_round_rnn_with_models(df, epochs, criterion, device,\n",
        "                            k, n_val_users, n_test_users, batch_size, hidden_layers, hidden_size, learning_rate, dropout_rate,\n",
        "                            window_size, stride, rnn_type, bidirectional,\n",
        "                            l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
        "                            restore_best_weights=True, writer=None, verbose=10, seed=42, experiment_name=\"\"):\n",
        "    \"\"\"\n",
        "    Perform K-fold shuffle split cross-validation with user-based splitting for time series data.\n",
        "    Modified to return trained models.\n",
        "\n",
        "    Returns:\n",
        "        fold_losses: Dict with validation losses for each split\n",
        "        fold_metrics: Dict with validation F1 scores for each split\n",
        "        best_scores: Dict with best F1 score for each split plus mean and std\n",
        "        trained_models: Dict with the best trained model from each split\n",
        "        model_performances: Dict with detailed performance metrics for each model\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialise containers for results across all splits\n",
        "    fold_losses = {}\n",
        "    fold_metrics = {}\n",
        "    best_scores = {}\n",
        "    trained_models = {}  # New: store trained models\n",
        "    model_performances = {}  # New: store model performance details\n",
        "\n",
        "    # Get the global num_classes\n",
        "    global_num_classes = 3 # Based on 'no_pain', 'low_pain', 'high_pain'\n",
        "\n",
        "    # Iterate through K random splits\n",
        "    for split_idx in range(k):\n",
        "\n",
        "        if verbose > 0:\n",
        "            print(f\"Split {split_idx+1}/{k}\")\n",
        "\n",
        "        # --- Step 1: Compute each user's dominant label\n",
        "        user_labels = (\n",
        "            df.groupby('sample_index')['label']\n",
        "            .agg(lambda x: x.value_counts().index[0])\n",
        "            .reset_index()\n",
        "        )\n",
        "\n",
        "        # Split users stratified by their dominant label\n",
        "        train_users, temp_users = train_test_split(\n",
        "            user_labels['sample_index'],\n",
        "            test_size=(n_val_users + n_test_users) / len(user_labels),\n",
        "            stratify=user_labels['label'],\n",
        "            random_state=seed + split_idx\n",
        "        )\n",
        "\n",
        "        temp_labels = user_labels[user_labels['sample_index'].isin(temp_users)]\n",
        "        val_users, test_users = train_test_split(\n",
        "            temp_labels['sample_index'],\n",
        "            test_size=n_test_users / (n_val_users + n_test_users),\n",
        "            stratify=temp_labels['label'],\n",
        "            random_state=seed + split_idx\n",
        "        )\n",
        "\n",
        "        # Filter dataframes\n",
        "        df_train = df[df['sample_index'].isin(train_users)]\n",
        "        df_val = df[df['sample_index'].isin(val_users)]\n",
        "        df_test = df[df['sample_index'].isin(test_users)]\n",
        "\n",
        "        # Map labels\n",
        "        label_mapping = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\n",
        "        df_train['label'] = df_train['label'].map(label_mapping)\n",
        "        df_val['label'] = df_val['label'].map(label_mapping)\n",
        "        df_test['label'] = df_test['label'].map(label_mapping)\n",
        "\n",
        "        if verbose > 0:\n",
        "            print(f\"  Training set shape: {df_train.shape}\")\n",
        "            print(f\"  Validation set shape: {df_val.shape}\")\n",
        "            print(f\"  Test set shape: {df_test.shape}\")\n",
        "\n",
        "        # Normalize features\n",
        "        scale_columns = [col for col in df.columns\n",
        "                 if (col.startswith('joint_') or col.startswith('pain_survey')) and not col.startswith('joint_30')]\n",
        "\n",
        "        mins_train = df_train[scale_columns].min()\n",
        "        maxs_train = df_train[scale_columns].max()\n",
        "\n",
        "        for column in scale_columns:\n",
        "            df_train[column] = (df_train[column] - mins_train[column]) / (maxs_train[column] - mins_train[column])\n",
        "            df_val[column] = (df_val[column] - mins_train[column]) / (maxs_train[column] - mins_train[column])\n",
        "            df_test[column] = (df_test[column] - mins_train[column]) / (maxs_train[column] - mins_train[column])\n",
        "\n",
        "        # --- Remove joint_30 from all splits ---\n",
        "        if 'joint_30' in df_train.columns:\n",
        "            df_train = df_train.drop(columns=['joint_30'])\n",
        "            df_val = df_val.drop(columns=['joint_30'])\n",
        "            df_test = df_test.drop(columns=['joint_30'])\n",
        "\n",
        "        # Build sequences\n",
        "        X_train_fold, y_train_fold = build_sequences(df_train, window=window_size, stride=stride)\n",
        "        X_val_fold, y_val_fold = build_sequences(df_val, window=window_size, stride=stride)\n",
        "        X_test_fold, y_test_fold = build_sequences(df_test, window=window_size, stride=stride)\n",
        "\n",
        "        # Convert and clean data\n",
        "        X_train_fold = np.nan_to_num(X_train_fold.astype('float32'))\n",
        "        X_val_fold = np.nan_to_num(X_val_fold.astype('float32'))\n",
        "        X_test_fold = np.nan_to_num(X_test_fold.astype('float32'))\n",
        "\n",
        "        if verbose > 0:\n",
        "            print(f\"  Training sequences shape: {X_train_fold.shape}\")\n",
        "            print(f\"  Validation sequences shape: {X_val_fold.shape}\")\n",
        "            print(f\"  Test sequences shape: {X_test_fold.shape}\")\n",
        "\n",
        "        # Initialize model\n",
        "        in_features_model = 37\n",
        "        model = RecurrentClassifier(\n",
        "            input_size=in_features_model,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=hidden_layers,\n",
        "            num_classes=global_num_classes,\n",
        "            dropout_rate=dropout_rate,\n",
        "            bidirectional=bidirectional,\n",
        "            rnn_type=rnn_type\n",
        "        ).to(device)\n",
        "\n",
        "        # Create data loaders\n",
        "        train_ds = TensorDataset(torch.from_numpy(X_train_fold), torch.from_numpy(y_train_fold))\n",
        "        val_ds = TensorDataset(torch.from_numpy(X_val_fold), torch.from_numpy(y_val_fold))\n",
        "        test_ds = TensorDataset(torch.from_numpy(X_test_fold), torch.from_numpy(y_test_fold))\n",
        "\n",
        "        train_loader = make_loader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "        val_loader = make_loader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "        test_loader = make_loader(test_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "        # Define optimizer\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=l2_lambda)\n",
        "        split_scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "        # Create directory for model checkpoints\n",
        "        os.makedirs(f\"models/{experiment_name}\", exist_ok=True)\n",
        "\n",
        "        # Train model\n",
        "        model, training_history = fit(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            epochs=epochs,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            scaler=split_scaler,\n",
        "            device=device,\n",
        "            writer=writer,\n",
        "            patience=patience,\n",
        "            verbose=verbose,\n",
        "            l1_lambda=l1_lambda,\n",
        "            evaluation_metric=evaluation_metric,\n",
        "            mode=mode,\n",
        "            restore_best_weights=restore_best_weights,\n",
        "            experiment_name=experiment_name+\"/split_\"+str(split_idx)\n",
        "        )\n",
        "\n",
        "        # Store the trained model\n",
        "        trained_models[f\"split_{split_idx}\"] = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        # Evaluate model on test set to get performance metrics\n",
        "        model.eval()\n",
        "        test_predictions = []\n",
        "        test_true_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_data, batch_labels in test_loader:\n",
        "                batch_data = batch_data.to(device)\n",
        "                batch_labels = batch_labels.to(device)\n",
        "\n",
        "                outputs = model(batch_data)\n",
        "                predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "                test_predictions.extend(predictions.cpu().numpy())\n",
        "                test_true_labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "        # Calculate performance metrics\n",
        "        test_f1 = f1_score(test_true_labels, test_predictions, average='weighted')\n",
        "        test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
        "\n",
        "        model_performances[f\"split_{split_idx}\"] = {\n",
        "            'test_f1': test_f1,\n",
        "            'test_accuracy': test_accuracy,\n",
        "            'best_val_f1': max(training_history['val_f1']),\n",
        "            'training_history': training_history\n",
        "        }\n",
        "\n",
        "        # Store results for this split\n",
        "        fold_losses[f\"split_{split_idx}\"] = training_history['val_loss']\n",
        "        fold_metrics[f\"split_{split_idx}\"] = training_history['val_f1']\n",
        "        best_scores[f\"split_{split_idx}\"] = max(training_history['val_f1'])\n",
        "\n",
        "        if verbose > 0:\n",
        "            print(f\"  Split {split_idx+1} - Best Val F1: {best_scores[f'split_{split_idx}']:.4f}, Test F1: {test_f1:.4f}\")\n",
        "\n",
        "    # Compute mean and standard deviation of best scores across splits\n",
        "    best_scores[\"mean\"] = np.mean([best_scores[k] for k in best_scores.keys() if k.startswith(\"split_\")])\n",
        "    best_scores[\"std\"] = np.std([best_scores[k] for k in best_scores.keys() if k.startswith(\"split_\")])\n",
        "\n",
        "    if verbose > 0:\n",
        "        print(f\"Overall Best Score: {best_scores['mean']:.4f}¬±{best_scores['std']:.4f}\")\n",
        "\n",
        "        # Print summary of all models\n",
        "        print(f\"\\nModel Performance Summary:\")\n",
        "        for split_name in sorted([k for k in model_performances.keys()]):\n",
        "            perf = model_performances[split_name]\n",
        "            print(f\"  {split_name}: Val F1={perf['best_val_f1']:.4f}, Test F1={perf['test_f1']:.4f}, Test Acc={perf['test_accuracy']:.4f}\")\n",
        "\n",
        "    return fold_losses, fold_metrics, best_scores, trained_models, model_performances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_x48QWUm-02"
      },
      "source": [
        "# Run the iterations for Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cn5PQgOm6I_",
        "outputId": "9bd55c62-809b-4312-911a-78aa470ab086"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running K-fold cross-validation with model extraction...\n",
            "Split 1/3\n",
            "  Training set shape: (81280, 40)\n",
            "  Validation set shape: (24000, 40)\n",
            "  Test set shape: (480, 40)\n",
            "  Training sequences shape: (4572, 64, 37)\n",
            "  Validation sequences shape: (1350, 64, 37)\n",
            "  Test sequences shape: (27, 64, 37)\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=1.8631, F1 Score=0.6643 | Val: Loss=0.4870, F1 Score=0.6745\n",
            "Epoch  10/500 | Train: Loss=0.7520, F1 Score=0.6749 | Val: Loss=0.4630, F1 Score=0.6745\n",
            "Epoch  20/500 | Train: Loss=0.4485, F1 Score=0.7862 | Val: Loss=0.3502, F1 Score=0.7887\n",
            "Epoch  30/500 | Train: Loss=0.4337, F1 Score=0.7728 | Val: Loss=0.3291, F1 Score=0.7755\n",
            "Epoch  40/500 | Train: Loss=0.3286, F1 Score=0.8197 | Val: Loss=0.2503, F1 Score=0.8365\n",
            "Epoch  50/500 | Train: Loss=0.3141, F1 Score=0.8241 | Val: Loss=0.2530, F1 Score=0.8355\n",
            "Epoch  60/500 | Train: Loss=0.2831, F1 Score=0.8364 | Val: Loss=0.2255, F1 Score=0.8452\n",
            "Epoch  70/500 | Train: Loss=0.2608, F1 Score=0.8564 | Val: Loss=0.2166, F1 Score=0.8579\n",
            "Epoch  80/500 | Train: Loss=0.2479, F1 Score=0.8669 | Val: Loss=0.2288, F1 Score=0.8553\n",
            "Epoch  90/500 | Train: Loss=0.2296, F1 Score=0.8785 | Val: Loss=0.2531, F1 Score=0.8491\n",
            "Epoch 100/500 | Train: Loss=0.2294, F1 Score=0.8848 | Val: Loss=0.2213, F1 Score=0.8687\n",
            "Epoch 110/500 | Train: Loss=0.2138, F1 Score=0.8888 | Val: Loss=0.2237, F1 Score=0.8768\n",
            "Epoch 120/500 | Train: Loss=0.2006, F1 Score=0.8947 | Val: Loss=0.2674, F1 Score=0.8615\n",
            "Epoch 130/500 | Train: Loss=0.1934, F1 Score=0.9017 | Val: Loss=0.2160, F1 Score=0.8875\n",
            "Epoch 140/500 | Train: Loss=0.1906, F1 Score=0.9086 | Val: Loss=0.2659, F1 Score=0.8686\n",
            "Epoch 150/500 | Train: Loss=0.1791, F1 Score=0.9158 | Val: Loss=0.2751, F1 Score=0.8788\n",
            "Epoch 160/500 | Train: Loss=0.1676, F1 Score=0.9272 | Val: Loss=0.2604, F1 Score=0.8809\n",
            "Epoch 170/500 | Train: Loss=0.1639, F1 Score=0.9274 | Val: Loss=0.3116, F1 Score=0.8653\n",
            "Epoch 180/500 | Train: Loss=0.1415, F1 Score=0.9449 | Val: Loss=0.2788, F1 Score=0.8796\n",
            "Epoch 190/500 | Train: Loss=0.2254, F1 Score=0.9000 | Val: Loss=0.2523, F1 Score=0.8787\n",
            "Epoch 200/500 | Train: Loss=0.1272, F1 Score=0.9564 | Val: Loss=0.2838, F1 Score=0.8694\n",
            "Epoch 210/500 | Train: Loss=0.1635, F1 Score=0.9324 | Val: Loss=0.3418, F1 Score=0.8621\n",
            "Epoch 220/500 | Train: Loss=0.1287, F1 Score=0.9572 | Val: Loss=0.2878, F1 Score=0.8857\n",
            "Epoch 230/500 | Train: Loss=0.1405, F1 Score=0.9479 | Val: Loss=0.2830, F1 Score=0.8868\n",
            "Epoch 240/500 | Train: Loss=0.1123, F1 Score=0.9652 | Val: Loss=0.2992, F1 Score=0.8895\n",
            "Early stopping triggered after 245 epochs.\n",
            "Best model restored from epoch 195 with val_f1 0.8958\n",
            "  Split 1 - Best Val F1: 0.8958, Test F1: 1.0000\n",
            "Split 2/3\n",
            "  Training set shape: (81280, 40)\n",
            "  Validation set shape: (24000, 40)\n",
            "  Test set shape: (480, 40)\n",
            "  Training sequences shape: (4572, 64, 37)\n",
            "  Validation sequences shape: (1350, 64, 37)\n",
            "  Test sequences shape: (27, 64, 37)\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=1.8636, F1 Score=0.6556 | Val: Loss=0.4889, F1 Score=0.6745\n",
            "Epoch  10/500 | Train: Loss=0.7500, F1 Score=0.6749 | Val: Loss=0.4505, F1 Score=0.6745\n",
            "Epoch  20/500 | Train: Loss=0.4790, F1 Score=0.7390 | Val: Loss=0.3872, F1 Score=0.7472\n",
            "Epoch  30/500 | Train: Loss=0.4393, F1 Score=0.7407 | Val: Loss=0.3800, F1 Score=0.7475\n",
            "Epoch  40/500 | Train: Loss=0.4163, F1 Score=0.7456 | Val: Loss=0.3833, F1 Score=0.7469\n",
            "Epoch  50/500 | Train: Loss=0.4030, F1 Score=0.7493 | Val: Loss=0.3825, F1 Score=0.7354\n",
            "Epoch  60/500 | Train: Loss=0.3908, F1 Score=0.7839 | Val: Loss=0.3845, F1 Score=0.7691\n",
            "Epoch  70/500 | Train: Loss=0.3946, F1 Score=0.7937 | Val: Loss=0.4014, F1 Score=0.7407\n",
            "Epoch  80/500 | Train: Loss=0.3425, F1 Score=0.8143 | Val: Loss=0.3525, F1 Score=0.7820\n",
            "Epoch  90/500 | Train: Loss=0.2757, F1 Score=0.8800 | Val: Loss=0.3103, F1 Score=0.8396\n",
            "Epoch 100/500 | Train: Loss=0.2481, F1 Score=0.8961 | Val: Loss=0.2970, F1 Score=0.8414\n",
            "Epoch 110/500 | Train: Loss=0.2281, F1 Score=0.9092 | Val: Loss=0.2752, F1 Score=0.8636\n",
            "Epoch 120/500 | Train: Loss=0.2068, F1 Score=0.9177 | Val: Loss=0.2636, F1 Score=0.8736\n",
            "Epoch 130/500 | Train: Loss=0.1962, F1 Score=0.9264 | Val: Loss=0.2915, F1 Score=0.8755\n",
            "Epoch 140/500 | Train: Loss=0.1811, F1 Score=0.9353 | Val: Loss=0.2629, F1 Score=0.8812\n",
            "Epoch 150/500 | Train: Loss=0.2254, F1 Score=0.9198 | Val: Loss=0.2927, F1 Score=0.8667\n",
            "Epoch 160/500 | Train: Loss=0.1622, F1 Score=0.9459 | Val: Loss=0.2905, F1 Score=0.8807\n",
            "Epoch 170/500 | Train: Loss=0.1612, F1 Score=0.9453 | Val: Loss=0.2729, F1 Score=0.8841\n",
            "Epoch 180/500 | Train: Loss=0.1496, F1 Score=0.9542 | Val: Loss=0.2732, F1 Score=0.8904\n",
            "Epoch 190/500 | Train: Loss=0.1785, F1 Score=0.9383 | Val: Loss=0.2931, F1 Score=0.8744\n",
            "Epoch 200/500 | Train: Loss=0.1408, F1 Score=0.9558 | Val: Loss=0.2592, F1 Score=0.8906\n",
            "Epoch 210/500 | Train: Loss=0.1347, F1 Score=0.9565 | Val: Loss=0.2482, F1 Score=0.8959\n",
            "Epoch 220/500 | Train: Loss=0.1282, F1 Score=0.9581 | Val: Loss=0.2691, F1 Score=0.8943\n",
            "Epoch 230/500 | Train: Loss=0.1213, F1 Score=0.9626 | Val: Loss=0.2807, F1 Score=0.8890\n",
            "Epoch 240/500 | Train: Loss=0.1785, F1 Score=0.9344 | Val: Loss=0.2853, F1 Score=0.8874\n",
            "Epoch 250/500 | Train: Loss=0.1111, F1 Score=0.9652 | Val: Loss=0.2678, F1 Score=0.8941\n",
            "Epoch 260/500 | Train: Loss=0.1498, F1 Score=0.9481 | Val: Loss=0.3825, F1 Score=0.8587\n",
            "Epoch 270/500 | Train: Loss=0.1144, F1 Score=0.9639 | Val: Loss=0.2597, F1 Score=0.8957\n",
            "Early stopping triggered after 275 epochs.\n",
            "Best model restored from epoch 225 with val_f1 0.8984\n",
            "  Split 2 - Best Val F1: 0.8984, Test F1: 0.8821\n",
            "Split 3/3\n",
            "  Training set shape: (81280, 40)\n",
            "  Validation set shape: (24000, 40)\n",
            "  Test set shape: (480, 40)\n",
            "  Training sequences shape: (4572, 64, 37)\n",
            "  Validation sequences shape: (1350, 64, 37)\n",
            "  Test sequences shape: (27, 64, 37)\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=1.8413, F1 Score=0.6753 | Val: Loss=0.4834, F1 Score=0.6745\n",
            "Epoch  10/500 | Train: Loss=0.7269, F1 Score=0.6749 | Val: Loss=0.4441, F1 Score=0.6745\n",
            "Epoch  20/500 | Train: Loss=0.4799, F1 Score=0.7490 | Val: Loss=0.4106, F1 Score=0.7375\n",
            "Epoch  30/500 | Train: Loss=0.4301, F1 Score=0.7549 | Val: Loss=0.4053, F1 Score=0.7384\n",
            "Epoch  40/500 | Train: Loss=0.4114, F1 Score=0.7600 | Val: Loss=0.4082, F1 Score=0.7414\n",
            "Epoch  50/500 | Train: Loss=0.3949, F1 Score=0.7682 | Val: Loss=0.3924, F1 Score=0.7417\n",
            "Epoch  60/500 | Train: Loss=0.3504, F1 Score=0.7944 | Val: Loss=0.3294, F1 Score=0.8027\n",
            "Epoch  70/500 | Train: Loss=0.2984, F1 Score=0.8356 | Val: Loss=0.2503, F1 Score=0.8291\n",
            "Epoch  80/500 | Train: Loss=0.2935, F1 Score=0.8334 | Val: Loss=0.2705, F1 Score=0.8168\n",
            "Epoch  90/500 | Train: Loss=0.2755, F1 Score=0.8401 | Val: Loss=0.2531, F1 Score=0.8233\n",
            "Epoch 100/500 | Train: Loss=0.2557, F1 Score=0.8571 | Val: Loss=0.2454, F1 Score=0.8356\n",
            "Epoch 110/500 | Train: Loss=0.2376, F1 Score=0.8749 | Val: Loss=0.2305, F1 Score=0.8609\n",
            "Epoch 120/500 | Train: Loss=0.2464, F1 Score=0.9014 | Val: Loss=0.2347, F1 Score=0.8730\n",
            "Epoch 130/500 | Train: Loss=0.2185, F1 Score=0.9167 | Val: Loss=0.2247, F1 Score=0.8872\n",
            "Epoch 140/500 | Train: Loss=0.2026, F1 Score=0.9203 | Val: Loss=0.2251, F1 Score=0.8929\n",
            "Epoch 150/500 | Train: Loss=0.2246, F1 Score=0.9056 | Val: Loss=0.2662, F1 Score=0.8601\n",
            "Epoch 160/500 | Train: Loss=0.1710, F1 Score=0.9313 | Val: Loss=0.1929, F1 Score=0.9045\n",
            "Epoch 170/500 | Train: Loss=0.1910, F1 Score=0.9147 | Val: Loss=0.2343, F1 Score=0.8683\n",
            "Epoch 180/500 | Train: Loss=0.1961, F1 Score=0.9260 | Val: Loss=0.2258, F1 Score=0.8863\n",
            "Epoch 190/500 | Train: Loss=0.1811, F1 Score=0.9291 | Val: Loss=0.1954, F1 Score=0.9000\n",
            "Epoch 200/500 | Train: Loss=0.1768, F1 Score=0.9340 | Val: Loss=0.2027, F1 Score=0.9074\n",
            "Epoch 210/500 | Train: Loss=0.1802, F1 Score=0.9245 | Val: Loss=0.2175, F1 Score=0.9012\n",
            "Epoch 220/500 | Train: Loss=0.1512, F1 Score=0.9419 | Val: Loss=0.2252, F1 Score=0.9027\n",
            "Epoch 230/500 | Train: Loss=0.1326, F1 Score=0.9490 | Val: Loss=0.2214, F1 Score=0.9127\n",
            "Epoch 240/500 | Train: Loss=0.1372, F1 Score=0.9515 | Val: Loss=0.1915, F1 Score=0.9189\n",
            "Epoch 250/500 | Train: Loss=0.1319, F1 Score=0.9537 | Val: Loss=0.2399, F1 Score=0.9086\n",
            "Early stopping triggered after 257 epochs.\n",
            "Best model restored from epoch 207 with val_f1 0.9243\n",
            "  Split 3 - Best Val F1: 0.9243, Test F1: 0.5333\n",
            "Overall Best Score: 0.9061¬±0.0129\n",
            "\n",
            "Model Performance Summary:\n",
            "  split_0: Val F1=0.8958, Test F1=1.0000, Test Acc=1.0000\n",
            "  split_1: Val F1=0.8984, Test F1=0.8821, Test Acc=0.8889\n",
            "  split_2: Val F1=0.9243, Test F1=0.5333, Test Acc=0.6667\n"
          ]
        }
      ],
      "source": [
        "# Example: How to use the modified function to extract models\n",
        "print(\"Running K-fold cross-validation with model extraction...\")\n",
        "N_VAL_USERS = 150\n",
        "N_TEST_USERS = 3\n",
        "K = 3\n",
        "VERBOSE = 10\n",
        "PATIENCE_KFOLD = 50\n",
        "\n",
        "# Execute K-fold cross-validation that returns models\n",
        "losses, metrics, best_scores, trained_models, model_performances = k_shuffle_split_cross_validation_round_rnn_with_models(\n",
        "    df=data,\n",
        "    epochs=EPOCHS,\n",
        "    criterion=criterion,\n",
        "    device=device,\n",
        "    k=K,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    hidden_layers=HIDDEN_LAYERS,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        "    l1_lambda=L1_LAMBDA,\n",
        "    l2_lambda=L2_LAMBDA,\n",
        "    verbose=VERBOSE,\n",
        "    patience=PATIENCE_KFOLD,\n",
        "    seed=SEED,\n",
        "    experiment_name=\"LSTM_with_models\",\n",
        "    n_val_users=N_VAL_USERS,\n",
        "    n_test_users=N_TEST_USERS,\n",
        "    window_size=WINDOW_SIZE,\n",
        "    stride=STRIDE,\n",
        "    rnn_type=RNN_TYPE,\n",
        "    bidirectional=BIDIRECTIONAL\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbaDexCwnJLG"
      },
      "source": [
        "# Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "qerAnh47nLLx",
        "outputId": "a8838f80-11fd-426a-a0e9-f0befe65d44c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title Plot Hitory\n",
        "# Create figure with two subplots sharing x axis\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 5), sharex=True)\n",
        "\n",
        "# Color palette for K splits\n",
        "colors = plt.cm.get_cmap('tab10', K)\n",
        "\n",
        "# Plot validation loss for each split\n",
        "for split in range(K):\n",
        "    axes[0].plot(losses[f'split_{split}'][:-PATIENCE_KFOLD], label=f'Split {split+1}',\n",
        "                 color=colors(split), alpha=0.6)\n",
        "axes[0].set_title('Validation Loss per Split')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Plot validation F1 score for each split\n",
        "for split in range(K):\n",
        "    axes[1].plot(metrics[f'split_{split}'][:-PATIENCE_KFOLD], label=f'Split {split+1}',\n",
        "                 color=colors(split), alpha=0.6)\n",
        "axes[1].set_title('Validation F1 Score per Split')\n",
        "axes[1].set_ylabel('F1 Score')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "# Add shared legend on the right\n",
        "handles, labels = axes[0].get_legend_handles_labels()\n",
        "fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5), fontsize='small')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(right=0.975)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3IOvsXcnM2i"
      },
      "source": [
        "# Confusion matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "B1n22xTFpPqL",
        "outputId": "061bd749-87ef-4b9b-b275-a814479bf6f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Elaborazione split 1/3...\n",
            "\n",
            "Elaborazione split 2/3...\n",
            "\n",
            "Elaborazione split 3/3...\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Layout dei subplot: 3 per riga\n",
        "ncols = min(3, K)\n",
        "nrows = int(np.ceil(K / ncols))\n",
        "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5*ncols, 5*nrows))\n",
        "axes = axes.flatten() if K > 1 else [axes]\n",
        "\n",
        "class_names = ['no_pain', 'low_pain', 'high_pain']\n",
        "\n",
        "for split_idx in range(K):\n",
        "    print(f\"\\nElaborazione split {split_idx+1}/{K}...\")\n",
        "\n",
        "    # Ricostruisci split utenti\n",
        "    user_labels = (\n",
        "        data.groupby('sample_index')['label']\n",
        "        .agg(lambda x: x.value_counts().index[0])\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    train_users, temp_users = train_test_split(\n",
        "        user_labels['sample_index'],\n",
        "        test_size=(N_VAL_USERS + N_TEST_USERS) / len(user_labels),\n",
        "        stratify=user_labels['label'],\n",
        "        random_state=SEED + split_idx\n",
        "    )\n",
        "\n",
        "    temp_labels = user_labels[user_labels['sample_index'].isin(temp_users)]\n",
        "    val_users, test_users = train_test_split(\n",
        "        temp_labels['sample_index'],\n",
        "        test_size=N_TEST_USERS / (N_VAL_USERS + N_TEST_USERS),\n",
        "        stratify=temp_labels['label'],\n",
        "        random_state=SEED + split_idx\n",
        "    )\n",
        "\n",
        "    # Validation set\n",
        "    df_val = data[data['sample_index'].isin(val_users)].copy()\n",
        "    df_train = data[data['sample_index'].isin(train_users)].copy()\n",
        "\n",
        "    # Map labels\n",
        "    label_mapping = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\n",
        "    df_val['label'] = df_val['label'].map(label_mapping)\n",
        "    df_train['label'] = df_train['label'].map(label_mapping)\n",
        "\n",
        "    # Normalizzazione\n",
        "    scale_columns = [col for col in df_train.columns\n",
        "                     if (col.startswith('joint_') or col.startswith('pain_survey')) and not col.startswith('joint_30')]\n",
        "    mins_train = df_train[scale_columns].min()\n",
        "    maxs_train = df_train[scale_columns].max()\n",
        "    for col in scale_columns:\n",
        "        df_val[col] = (df_val[col] - mins_train[col]) / (maxs_train[col] - mins_train[col])\n",
        "\n",
        "    # Rimuovi joint_30\n",
        "    if 'joint_30' in df_val.columns:\n",
        "        df_val = df_val.drop(columns=['joint_30'])\n",
        "\n",
        "    # Sequenze validation\n",
        "    X_val, y_val = build_sequences(df_val, window=WINDOW_SIZE, stride=STRIDE)\n",
        "    X_val = np.nan_to_num(X_val.astype('float32'))\n",
        "    y_val = np.nan_to_num(y_val.astype('int64'))\n",
        "\n",
        "    val_ds = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "    val_loader = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "    # Carica modello\n",
        "    model = RecurrentClassifier(\n",
        "        input_size=in_features_model,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        num_layers=HIDDEN_LAYERS,\n",
        "        num_classes=global_num_classes,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        bidirectional=BIDIRECTIONAL,\n",
        "        rnn_type=RNN_TYPE\n",
        "    ).to(device)\n",
        "    model.load_state_dict(trained_models[f\"split_{split_idx}\"])\n",
        "    model.eval()\n",
        "\n",
        "    # Predizioni\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(device)\n",
        "            preds = model(xb).argmax(dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(yb.numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Confusion matrix (forza 3x3)\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=[0,1,2])\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    # Plot\n",
        "    ax = axes[split_idx]\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "                xticklabels=class_names, yticklabels=class_names, cbar=False)\n",
        "    ax.set_title(f\"Split {split_idx+1}\\nAcc: {acc:.3f} | F1: {f1:.3f}\")\n",
        "    ax.set_xlabel(\"Predicted\")\n",
        "    ax.set_ylabel(\"True\")\n",
        "\n",
        "# Rimuovi eventuali subplot vuoti\n",
        "for j in range(split_idx + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynpL75GJteQW"
      },
      "source": [
        "## GRID SEARCH: HYPERPARAMETERS TUNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXbnyYeMtQI8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "GRID_EPOCHS = 500\n",
        "GRID_PATIENCE = 40\n",
        "param_grid = {\n",
        "    'RNN_TYPE': ['LSTM'],\n",
        "    'BIDIRECTIONAL': [True],\n",
        "    'HIDDEN_SIZE': [5, 10, 15, 20, 25, 30, 105, 110, 115, 120, 125, 130],\n",
        "    'HIDDEN_LAYERS': [2],\n",
        "    'LEARNING_RATE': [1e-3],\n",
        "    'DROPOUT_RATE': [0.3],\n",
        "    'BATCH_SIZE': [512],\n",
        "    'L1_LAMBDA': [0.00001],\n",
        "    'L2_LAMBDA': [0.001],\n",
        "    'WINDOW': [64],\n",
        "    'STRIDE': [16],\n",
        "    'CRITERION': ['FOCAL'], #CROSS or FOCAL\n",
        "    'WEIGHTS': [[1.0, 1.0, 1.0]], # Only if CrossEntropy\n",
        "    'GAMMA': [1.0], #Only if FocalLoss\n",
        "}\n",
        "\n",
        "results = []\n",
        "grid = list(ParameterGrid(param_grid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2UjyaAqtvI1"
      },
      "source": [
        "## Loop the grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUJ67yMdtpqi",
        "outputId": "05e5a495-a12b-4d59-fda3-e0aa39edc637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running 12 configurations...\n",
            "\n",
            "Configuration 1/12: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 5, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "Training set size: 4482\n",
            "Validation set size: 1440\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 64, 10], [4, -1, 5]]   2,440          \n",
            "classifier (Linear)       [-1, 3]                      33             \n",
            "===============================================================================\n",
            "Total params: 2,473\n",
            "Trainable params: 2,473\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.7553, F1 Score=0.0465 | Val: Loss=0.7117, F1 Score=0.1902\n",
            "Epoch  10/500 | Train: Loss=0.4520, F1 Score=0.6742 | Val: Loss=0.4413, F1 Score=0.6768\n",
            "Epoch  20/500 | Train: Loss=0.4385, F1 Score=0.6742 | Val: Loss=0.4335, F1 Score=0.6768\n",
            "Epoch  30/500 | Train: Loss=0.4344, F1 Score=0.6742 | Val: Loss=0.4276, F1 Score=0.6768\n",
            "Epoch  40/500 | Train: Loss=0.3835, F1 Score=0.7294 | Val: Loss=0.4019, F1 Score=0.7654\n",
            "Epoch  50/500 | Train: Loss=0.3761, F1 Score=0.7548 | Val: Loss=0.3375, F1 Score=0.7830\n",
            "Epoch  60/500 | Train: Loss=0.3565, F1 Score=0.7699 | Val: Loss=0.3662, F1 Score=0.7784\n",
            "Epoch  70/500 | Train: Loss=0.3495, F1 Score=0.7726 | Val: Loss=0.3541, F1 Score=0.7858\n",
            "Epoch  80/500 | Train: Loss=0.3568, F1 Score=0.7553 | Val: Loss=0.3692, F1 Score=0.7684\n",
            "Epoch  90/500 | Train: Loss=0.3267, F1 Score=0.7755 | Val: Loss=0.3469, F1 Score=0.7957\n",
            "Epoch 100/500 | Train: Loss=0.3223, F1 Score=0.7681 | Val: Loss=0.3423, F1 Score=0.7678\n",
            "Epoch 110/500 | Train: Loss=0.2798, F1 Score=0.7878 | Val: Loss=0.3309, F1 Score=0.7915\n",
            "Epoch 120/500 | Train: Loss=0.2487, F1 Score=0.8296 | Val: Loss=0.2906, F1 Score=0.8216\n",
            "Epoch 130/500 | Train: Loss=0.2364, F1 Score=0.8483 | Val: Loss=0.3032, F1 Score=0.8068\n",
            "Epoch 140/500 | Train: Loss=0.2592, F1 Score=0.8287 | Val: Loss=0.3346, F1 Score=0.8052\n",
            "Epoch 150/500 | Train: Loss=0.2136, F1 Score=0.8775 | Val: Loss=0.2785, F1 Score=0.8303\n",
            "Epoch 160/500 | Train: Loss=0.2053, F1 Score=0.8824 | Val: Loss=0.2722, F1 Score=0.8395\n",
            "Epoch 170/500 | Train: Loss=0.1999, F1 Score=0.8870 | Val: Loss=0.2827, F1 Score=0.8063\n",
            "Epoch 180/500 | Train: Loss=0.1961, F1 Score=0.8886 | Val: Loss=0.2916, F1 Score=0.8045\n",
            "Epoch 190/500 | Train: Loss=0.2080, F1 Score=0.8898 | Val: Loss=0.2788, F1 Score=0.8238\n",
            "Epoch 200/500 | Train: Loss=0.1940, F1 Score=0.8986 | Val: Loss=0.2930, F1 Score=0.8026\n",
            "Epoch 210/500 | Train: Loss=0.1821, F1 Score=0.9023 | Val: Loss=0.2857, F1 Score=0.8229\n",
            "Early stopping triggered after 219 epochs.\n",
            "Best model restored from epoch 179 with val_f1 0.8446\n",
            "[Run 1] Best val_f1 = 0.8446 (epoch 179)\n",
            "Configuration 1 completed in 106.0s\n",
            "\n",
            "Configuration 2/12: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 10, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "Training set size: 4482\n",
            "Validation set size: 1440\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 64, 20], [4, -1, 10]]  6,480          \n",
            "classifier (Linear)       [-1, 3]                      63             \n",
            "===============================================================================\n",
            "Total params: 6,543\n",
            "Trainable params: 6,543\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.7595, F1 Score=0.2037 | Val: Loss=0.7028, F1 Score=0.6617\n",
            "Epoch  10/500 | Train: Loss=0.4461, F1 Score=0.6742 | Val: Loss=0.4356, F1 Score=0.6768\n",
            "Epoch  20/500 | Train: Loss=0.4385, F1 Score=0.6742 | Val: Loss=0.4308, F1 Score=0.6768\n",
            "Epoch  30/500 | Train: Loss=0.3814, F1 Score=0.7107 | Val: Loss=0.3970, F1 Score=0.7311\n",
            "Epoch  40/500 | Train: Loss=0.3500, F1 Score=0.7586 | Val: Loss=0.5264, F1 Score=0.6667\n",
            "Epoch  50/500 | Train: Loss=0.3076, F1 Score=0.7750 | Val: Loss=0.3630, F1 Score=0.7528\n",
            "Epoch  60/500 | Train: Loss=0.2724, F1 Score=0.8183 | Val: Loss=0.3201, F1 Score=0.8005\n",
            "Epoch  70/500 | Train: Loss=0.2480, F1 Score=0.8267 | Val: Loss=0.3072, F1 Score=0.8002\n",
            "Epoch  80/500 | Train: Loss=0.2233, F1 Score=0.8563 | Val: Loss=0.2388, F1 Score=0.8471\n",
            "Epoch  90/500 | Train: Loss=0.2033, F1 Score=0.8759 | Val: Loss=0.2091, F1 Score=0.8653\n",
            "Epoch 100/500 | Train: Loss=0.1835, F1 Score=0.8871 | Val: Loss=0.2181, F1 Score=0.8527\n",
            "Epoch 110/500 | Train: Loss=0.1708, F1 Score=0.8973 | Val: Loss=0.2606, F1 Score=0.8370\n",
            "Epoch 120/500 | Train: Loss=0.1414, F1 Score=0.9233 | Val: Loss=0.2431, F1 Score=0.8518\n",
            "Epoch 130/500 | Train: Loss=0.1422, F1 Score=0.9211 | Val: Loss=0.2225, F1 Score=0.8643\n",
            "Epoch 140/500 | Train: Loss=0.1372, F1 Score=0.9204 | Val: Loss=0.2580, F1 Score=0.8537\n",
            "Epoch 150/500 | Train: Loss=0.1273, F1 Score=0.9281 | Val: Loss=0.2526, F1 Score=0.8534\n",
            "Epoch 160/500 | Train: Loss=0.1308, F1 Score=0.9306 | Val: Loss=0.2407, F1 Score=0.8602\n",
            "Epoch 170/500 | Train: Loss=0.1142, F1 Score=0.9420 | Val: Loss=0.2286, F1 Score=0.8776\n",
            "Epoch 180/500 | Train: Loss=0.1330, F1 Score=0.9276 | Val: Loss=0.2198, F1 Score=0.8796\n",
            "Epoch 190/500 | Train: Loss=0.0967, F1 Score=0.9475 | Val: Loss=0.2723, F1 Score=0.8637\n",
            "Epoch 200/500 | Train: Loss=0.1078, F1 Score=0.9380 | Val: Loss=0.2582, F1 Score=0.8711\n",
            "Epoch 210/500 | Train: Loss=0.1014, F1 Score=0.9427 | Val: Loss=0.2820, F1 Score=0.8694\n",
            "Epoch 220/500 | Train: Loss=0.0870, F1 Score=0.9544 | Val: Loss=0.2723, F1 Score=0.8684\n",
            "Epoch 230/500 | Train: Loss=0.0962, F1 Score=0.9470 | Val: Loss=0.2502, F1 Score=0.8740\n",
            "Epoch 240/500 | Train: Loss=0.0813, F1 Score=0.9571 | Val: Loss=0.2833, F1 Score=0.8815\n",
            "Epoch 250/500 | Train: Loss=0.0853, F1 Score=0.9542 | Val: Loss=0.2597, F1 Score=0.8823\n",
            "Epoch 260/500 | Train: Loss=0.0783, F1 Score=0.9563 | Val: Loss=0.2554, F1 Score=0.8904\n",
            "Epoch 270/500 | Train: Loss=0.0634, F1 Score=0.9654 | Val: Loss=0.2701, F1 Score=0.8901\n",
            "Epoch 280/500 | Train: Loss=0.0733, F1 Score=0.9643 | Val: Loss=0.2491, F1 Score=0.8961\n",
            "Epoch 290/500 | Train: Loss=0.0669, F1 Score=0.9629 | Val: Loss=0.2671, F1 Score=0.8863\n",
            "Epoch 300/500 | Train: Loss=0.0529, F1 Score=0.9742 | Val: Loss=0.2880, F1 Score=0.8769\n",
            "Epoch 310/500 | Train: Loss=0.0553, F1 Score=0.9738 | Val: Loss=0.2728, F1 Score=0.8869\n",
            "Epoch 320/500 | Train: Loss=0.0484, F1 Score=0.9735 | Val: Loss=0.2978, F1 Score=0.8668\n",
            "Early stopping triggered after 322 epochs.\n",
            "Best model restored from epoch 282 with val_f1 0.9023\n",
            "[Run 2] Best val_f1 = 0.9023 (epoch 282)\n",
            "Configuration 2 completed in 148.7s\n",
            "\n",
            "Configuration 3/12: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 15, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "Training set size: 4482\n",
            "Validation set size: 1440\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 64, 30], [4, -1, 15]]  12,120         \n",
            "classifier (Linear)       [-1, 3]                      93             \n",
            "===============================================================================\n",
            "Total params: 12,213\n",
            "Trainable params: 12,213\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.6509, F1 Score=0.6532 | Val: Loss=0.5540, F1 Score=0.6768\n",
            "Epoch  10/500 | Train: Loss=0.4435, F1 Score=0.6742 | Val: Loss=0.4286, F1 Score=0.6768\n",
            "Epoch  20/500 | Train: Loss=0.3637, F1 Score=0.7275 | Val: Loss=0.3855, F1 Score=0.7357\n",
            "Epoch  30/500 | Train: Loss=0.2779, F1 Score=0.8409 | Val: Loss=0.2929, F1 Score=0.8255\n",
            "Epoch  40/500 | Train: Loss=0.2540, F1 Score=0.8616 | Val: Loss=0.3056, F1 Score=0.8206\n",
            "Epoch  50/500 | Train: Loss=0.2204, F1 Score=0.8834 | Val: Loss=0.2909, F1 Score=0.8114\n",
            "Epoch  60/500 | Train: Loss=0.1955, F1 Score=0.8967 | Val: Loss=0.2702, F1 Score=0.8235\n",
            "Epoch  70/500 | Train: Loss=0.1717, F1 Score=0.9093 | Val: Loss=0.2834, F1 Score=0.8373\n",
            "Epoch  80/500 | Train: Loss=0.1546, F1 Score=0.9166 | Val: Loss=0.2350, F1 Score=0.8676\n",
            "Epoch  90/500 | Train: Loss=0.1326, F1 Score=0.9314 | Val: Loss=0.2590, F1 Score=0.8727\n",
            "Epoch 100/500 | Train: Loss=0.1271, F1 Score=0.9374 | Val: Loss=0.3417, F1 Score=0.8399\n",
            "Epoch 110/500 | Train: Loss=0.1138, F1 Score=0.9471 | Val: Loss=0.2745, F1 Score=0.8758\n",
            "Epoch 120/500 | Train: Loss=0.1087, F1 Score=0.9510 | Val: Loss=0.2992, F1 Score=0.8665\n",
            "Epoch 130/500 | Train: Loss=0.1030, F1 Score=0.9503 | Val: Loss=0.3005, F1 Score=0.8735\n",
            "Epoch 140/500 | Train: Loss=0.1173, F1 Score=0.9413 | Val: Loss=0.2455, F1 Score=0.8792\n",
            "Epoch 150/500 | Train: Loss=0.0842, F1 Score=0.9586 | Val: Loss=0.2800, F1 Score=0.8829\n",
            "Epoch 160/500 | Train: Loss=0.0747, F1 Score=0.9631 | Val: Loss=0.3056, F1 Score=0.8869\n",
            "Epoch 170/500 | Train: Loss=0.0638, F1 Score=0.9687 | Val: Loss=0.3244, F1 Score=0.8852\n",
            "Epoch 180/500 | Train: Loss=0.0730, F1 Score=0.9630 | Val: Loss=0.3223, F1 Score=0.8831\n",
            "Epoch 190/500 | Train: Loss=0.0556, F1 Score=0.9744 | Val: Loss=0.3367, F1 Score=0.8863\n",
            "Epoch 200/500 | Train: Loss=0.0677, F1 Score=0.9678 | Val: Loss=0.2501, F1 Score=0.8926\n",
            "Epoch 210/500 | Train: Loss=0.0568, F1 Score=0.9757 | Val: Loss=0.2936, F1 Score=0.8907\n",
            "Epoch 220/500 | Train: Loss=0.0515, F1 Score=0.9781 | Val: Loss=0.2836, F1 Score=0.8861\n",
            "Early stopping triggered after 222 epochs.\n",
            "Best model restored from epoch 182 with val_f1 0.8965\n",
            "[Run 3] Best val_f1 = 0.8965 (epoch 182)\n",
            "Configuration 3 completed in 104.4s\n",
            "\n",
            "Configuration 4/12: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 20, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "Training set size: 4482\n",
            "Validation set size: 1440\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 64, 40], [4, -1, 20]]  19,360         \n",
            "classifier (Linear)       [-1, 3]                      123            \n",
            "===============================================================================\n",
            "Total params: 19,483\n",
            "Trainable params: 19,483\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.7615, F1 Score=0.2878 | Val: Loss=0.6183, F1 Score=0.6694\n",
            "Epoch  10/500 | Train: Loss=0.4493, F1 Score=0.6742 | Val: Loss=0.4281, F1 Score=0.6768\n",
            "Epoch  20/500 | Train: Loss=0.3522, F1 Score=0.7674 | Val: Loss=0.3483, F1 Score=0.7643\n",
            "Epoch  30/500 | Train: Loss=0.3207, F1 Score=0.7924 | Val: Loss=0.3350, F1 Score=0.7663\n",
            "Epoch  40/500 | Train: Loss=0.2710, F1 Score=0.8342 | Val: Loss=0.2762, F1 Score=0.7884\n",
            "Epoch  50/500 | Train: Loss=0.2786, F1 Score=0.8297 | Val: Loss=0.2865, F1 Score=0.8167\n",
            "Epoch  60/500 | Train: Loss=0.2246, F1 Score=0.8777 | Val: Loss=0.2653, F1 Score=0.8130\n",
            "Epoch  70/500 | Train: Loss=0.1685, F1 Score=0.9120 | Val: Loss=0.2234, F1 Score=0.8472\n",
            "Epoch  80/500 | Train: Loss=0.1808, F1 Score=0.8964 | Val: Loss=0.2386, F1 Score=0.8427\n",
            "Epoch  90/500 | Train: Loss=0.1227, F1 Score=0.9416 | Val: Loss=0.2240, F1 Score=0.8682\n",
            "Epoch 100/500 | Train: Loss=0.1022, F1 Score=0.9542 | Val: Loss=0.2009, F1 Score=0.8825\n",
            "Epoch 110/500 | Train: Loss=0.0952, F1 Score=0.9551 | Val: Loss=0.1967, F1 Score=0.8938\n",
            "Epoch 120/500 | Train: Loss=0.0852, F1 Score=0.9605 | Val: Loss=0.2290, F1 Score=0.8879\n",
            "Epoch 130/500 | Train: Loss=0.0740, F1 Score=0.9653 | Val: Loss=0.1986, F1 Score=0.8999\n",
            "Epoch 140/500 | Train: Loss=0.0688, F1 Score=0.9717 | Val: Loss=0.2361, F1 Score=0.8959\n",
            "Epoch 150/500 | Train: Loss=0.0853, F1 Score=0.9637 | Val: Loss=0.2019, F1 Score=0.9043\n",
            "Epoch 160/500 | Train: Loss=0.0677, F1 Score=0.9738 | Val: Loss=0.2746, F1 Score=0.8942\n",
            "Epoch 170/500 | Train: Loss=0.0531, F1 Score=0.9808 | Val: Loss=0.2349, F1 Score=0.9050\n",
            "Epoch 180/500 | Train: Loss=0.0510, F1 Score=0.9826 | Val: Loss=0.2627, F1 Score=0.9142\n",
            "Epoch 190/500 | Train: Loss=0.0747, F1 Score=0.9658 | Val: Loss=0.1909, F1 Score=0.9106\n",
            "Epoch 200/500 | Train: Loss=0.0494, F1 Score=0.9821 | Val: Loss=0.2565, F1 Score=0.9095\n",
            "Epoch 210/500 | Train: Loss=0.0424, F1 Score=0.9833 | Val: Loss=0.2542, F1 Score=0.9073\n",
            "Early stopping triggered after 219 epochs.\n",
            "Best model restored from epoch 179 with val_f1 0.9164\n",
            "[Run 4] Best val_f1 = 0.9164 (epoch 179)\n",
            "Configuration 4 completed in 101.8s\n",
            "\n",
            "Configuration 5/12: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 25, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "Training set size: 4482\n",
            "Validation set size: 1440\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 64, 50], [4, -1, 25]]  28,200         \n",
            "classifier (Linear)       [-1, 3]                      153            \n",
            "===============================================================================\n",
            "Total params: 28,353\n",
            "Trainable params: 28,353\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.6743, F1 Score=0.6597 | Val: Loss=0.5456, F1 Score=0.6768\n",
            "Epoch  10/500 | Train: Loss=0.4543, F1 Score=0.6742 | Val: Loss=0.4301, F1 Score=0.6768\n",
            "Epoch  20/500 | Train: Loss=0.3212, F1 Score=0.7940 | Val: Loss=0.3387, F1 Score=0.7741\n",
            "Epoch  30/500 | Train: Loss=0.2355, F1 Score=0.8711 | Val: Loss=0.2237, F1 Score=0.8597\n",
            "Epoch  40/500 | Train: Loss=0.1944, F1 Score=0.8982 | Val: Loss=0.2045, F1 Score=0.8693\n",
            "Epoch  50/500 | Train: Loss=0.1790, F1 Score=0.9159 | Val: Loss=0.1816, F1 Score=0.8983\n",
            "Epoch  60/500 | Train: Loss=0.2219, F1 Score=0.8832 | Val: Loss=0.1993, F1 Score=0.8775\n",
            "Epoch  70/500 | Train: Loss=0.1655, F1 Score=0.9200 | Val: Loss=0.1898, F1 Score=0.8829\n",
            "Epoch  80/500 | Train: Loss=0.1321, F1 Score=0.9378 | Val: Loss=0.1976, F1 Score=0.8936\n",
            "Epoch  90/500 | Train: Loss=0.1211, F1 Score=0.9434 | Val: Loss=0.2318, F1 Score=0.8817\n",
            "Epoch 100/500 | Train: Loss=0.1354, F1 Score=0.9340 | Val: Loss=0.2615, F1 Score=0.8637\n",
            "Epoch 110/500 | Train: Loss=0.0959, F1 Score=0.9561 | Val: Loss=0.2158, F1 Score=0.8898\n",
            "Epoch 120/500 | Train: Loss=0.1170, F1 Score=0.9487 | Val: Loss=0.2095, F1 Score=0.8891\n",
            "Epoch 130/500 | Train: Loss=0.0973, F1 Score=0.9531 | Val: Loss=0.2401, F1 Score=0.8813\n",
            "Early stopping triggered after 135 epochs.\n",
            "Best model restored from epoch 95 with val_f1 0.9026\n",
            "[Run 5] Best val_f1 = 0.9026 (epoch 95)\n",
            "Configuration 5 completed in 64.0s\n",
            "\n",
            "Configuration 6/12: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 30, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "Training set size: 4482\n",
            "Validation set size: 1440\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 64, 60], [4, -1, 30]]  38,640         \n",
            "classifier (Linear)       [-1, 3]                      183            \n",
            "===============================================================================\n",
            "Total params: 38,823\n",
            "Trainable params: 38,823\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.6356, F1 Score=0.6742 | Val: Loss=0.4959, F1 Score=0.6768\n",
            "Epoch  10/500 | Train: Loss=0.4496, F1 Score=0.6742 | Val: Loss=0.4175, F1 Score=0.6768\n",
            "Epoch  20/500 | Train: Loss=0.3547, F1 Score=0.7851 | Val: Loss=0.3603, F1 Score=0.7671\n",
            "Epoch  30/500 | Train: Loss=0.3087, F1 Score=0.8281 | Val: Loss=0.3554, F1 Score=0.7789\n",
            "Epoch  40/500 | Train: Loss=0.2574, F1 Score=0.8674 | Val: Loss=0.2838, F1 Score=0.8462\n",
            "Epoch  50/500 | Train: Loss=0.2117, F1 Score=0.8949 | Val: Loss=0.2704, F1 Score=0.8397\n",
            "Epoch  60/500 | Train: Loss=0.2663, F1 Score=0.8415 | Val: Loss=0.2495, F1 Score=0.8356\n",
            "Epoch  70/500 | Train: Loss=0.2126, F1 Score=0.8854 | Val: Loss=0.2417, F1 Score=0.8346\n",
            "Epoch  80/500 | Train: Loss=0.1850, F1 Score=0.9015 | Val: Loss=0.2429, F1 Score=0.8409\n",
            "Epoch  90/500 | Train: Loss=0.1385, F1 Score=0.9309 | Val: Loss=0.2292, F1 Score=0.8613\n",
            "Epoch 100/500 | Train: Loss=0.1097, F1 Score=0.9492 | Val: Loss=0.2423, F1 Score=0.8768\n",
            "Epoch 110/500 | Train: Loss=0.1011, F1 Score=0.9554 | Val: Loss=0.2724, F1 Score=0.8601\n",
            "Epoch 120/500 | Train: Loss=0.0963, F1 Score=0.9561 | Val: Loss=0.2682, F1 Score=0.8574\n",
            "Epoch 130/500 | Train: Loss=0.1353, F1 Score=0.9364 | Val: Loss=0.2519, F1 Score=0.8736\n",
            "Epoch 140/500 | Train: Loss=0.0961, F1 Score=0.9555 | Val: Loss=0.2843, F1 Score=0.8735\n",
            "Epoch 150/500 | Train: Loss=0.0791, F1 Score=0.9638 | Val: Loss=0.2504, F1 Score=0.8890\n",
            "Epoch 160/500 | Train: Loss=0.0761, F1 Score=0.9647 | Val: Loss=0.2824, F1 Score=0.8895\n",
            "Epoch 170/500 | Train: Loss=0.0688, F1 Score=0.9717 | Val: Loss=0.3192, F1 Score=0.8782\n",
            "Epoch 180/500 | Train: Loss=0.0836, F1 Score=0.9598 | Val: Loss=0.3179, F1 Score=0.8783\n",
            "Epoch 190/500 | Train: Loss=0.0625, F1 Score=0.9767 | Val: Loss=0.2994, F1 Score=0.8604\n",
            "Early stopping triggered after 194 epochs.\n",
            "Best model restored from epoch 154 with val_f1 0.8934\n",
            "[Run 6] Best val_f1 = 0.8934 (epoch 154)\n",
            "Configuration 6 completed in 91.1s\n",
            "\n",
            "Configuration 7/12: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 105, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "Training set size: 4482\n",
            "Validation set size: 1440\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 64, 210], [4, -1, 105]] 387,240        \n",
            "classifier (Linear)       [-1, 3]                      633            \n",
            "===============================================================================\n",
            "Total params: 387,873\n",
            "Trainable params: 387,873\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.7277, F1 Score=0.6492 | Val: Loss=0.4665, F1 Score=0.6768\n",
            "Epoch  10/500 | Train: Loss=0.4495, F1 Score=0.7462 | Val: Loss=0.3879, F1 Score=0.7317\n",
            "Epoch  20/500 | Train: Loss=0.3361, F1 Score=0.8401 | Val: Loss=0.3412, F1 Score=0.7773\n",
            "Epoch  30/500 | Train: Loss=0.2826, F1 Score=0.8692 | Val: Loss=0.2879, F1 Score=0.8119\n",
            "Epoch  40/500 | Train: Loss=0.2587, F1 Score=0.8781 | Val: Loss=0.2748, F1 Score=0.8377\n",
            "Epoch  50/500 | Train: Loss=0.1676, F1 Score=0.9374 | Val: Loss=0.2586, F1 Score=0.8654\n",
            "Epoch  60/500 | Train: Loss=0.1519, F1 Score=0.9454 | Val: Loss=0.2638, F1 Score=0.8679\n",
            "Epoch  70/500 | Train: Loss=0.1657, F1 Score=0.9362 | Val: Loss=0.2855, F1 Score=0.8457\n",
            "Epoch  80/500 | Train: Loss=0.1968, F1 Score=0.9162 | Val: Loss=0.2946, F1 Score=0.8522\n",
            "Epoch  90/500 | Train: Loss=0.1641, F1 Score=0.9284 | Val: Loss=0.2877, F1 Score=0.8430\n",
            "Epoch 100/500 | Train: Loss=0.1092, F1 Score=0.9596 | Val: Loss=0.3461, F1 Score=0.8649\n",
            "Epoch 110/500 | Train: Loss=0.0820, F1 Score=0.9751 | Val: Loss=0.2718, F1 Score=0.8935\n",
            "Epoch 120/500 | Train: Loss=0.0787, F1 Score=0.9772 | Val: Loss=0.2771, F1 Score=0.8912\n",
            "Epoch 130/500 | Train: Loss=0.0756, F1 Score=0.9771 | Val: Loss=0.3197, F1 Score=0.8853\n",
            "Epoch 140/500 | Train: Loss=0.0745, F1 Score=0.9749 | Val: Loss=0.3263, F1 Score=0.8829\n",
            "Epoch 150/500 | Train: Loss=0.1015, F1 Score=0.9659 | Val: Loss=0.3102, F1 Score=0.8536\n",
            "Epoch 160/500 | Train: Loss=0.0890, F1 Score=0.9718 | Val: Loss=0.3159, F1 Score=0.8783\n",
            "Early stopping triggered after 162 epochs.\n",
            "Best model restored from epoch 122 with val_f1 0.9083\n",
            "[Run 7] Best val_f1 = 0.9083 (epoch 122)\n",
            "Configuration 7 completed in 111.9s\n",
            "\n",
            "Configuration 8/12: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 110, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "Training set size: 4482\n",
            "Validation set size: 1440\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 64, 220], [4, -1, 110]] 423,280        \n",
            "classifier (Linear)       [-1, 3]                      663            \n",
            "===============================================================================\n",
            "Total params: 423,943\n",
            "Trainable params: 423,943\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.7329, F1 Score=0.6602 | Val: Loss=0.4603, F1 Score=0.6768\n",
            "Epoch  10/500 | Train: Loss=0.4409, F1 Score=0.7504 | Val: Loss=0.3878, F1 Score=0.7325\n",
            "Epoch  20/500 | Train: Loss=0.3514, F1 Score=0.8417 | Val: Loss=0.5161, F1 Score=0.6639\n",
            "Epoch  30/500 | Train: Loss=0.2896, F1 Score=0.8745 | Val: Loss=0.2701, F1 Score=0.8449\n",
            "Epoch  40/500 | Train: Loss=0.2496, F1 Score=0.8897 | Val: Loss=0.2707, F1 Score=0.8392\n",
            "Epoch  50/500 | Train: Loss=0.1883, F1 Score=0.9248 | Val: Loss=0.2700, F1 Score=0.8457\n",
            "Epoch  60/500 | Train: Loss=0.1548, F1 Score=0.9435 | Val: Loss=0.2660, F1 Score=0.8692\n",
            "Epoch  70/500 | Train: Loss=0.2375, F1 Score=0.8857 | Val: Loss=0.2254, F1 Score=0.8603\n",
            "Epoch  80/500 | Train: Loss=0.1603, F1 Score=0.9366 | Val: Loss=0.2569, F1 Score=0.8551\n",
            "Epoch  90/500 | Train: Loss=0.1162, F1 Score=0.9604 | Val: Loss=0.3229, F1 Score=0.8729\n",
            "Epoch 100/500 | Train: Loss=0.1105, F1 Score=0.9634 | Val: Loss=0.2988, F1 Score=0.8784\n",
            "Epoch 110/500 | Train: Loss=0.0928, F1 Score=0.9712 | Val: Loss=0.3102, F1 Score=0.8829\n",
            "Epoch 120/500 | Train: Loss=0.0898, F1 Score=0.9740 | Val: Loss=0.3046, F1 Score=0.8878\n",
            "Epoch 130/500 | Train: Loss=0.1088, F1 Score=0.9615 | Val: Loss=0.2725, F1 Score=0.8893\n",
            "Epoch 140/500 | Train: Loss=0.0891, F1 Score=0.9717 | Val: Loss=0.3042, F1 Score=0.8936\n",
            "Early stopping triggered after 146 epochs.\n",
            "Best model restored from epoch 106 with val_f1 0.9111\n",
            "[Run 8] Best val_f1 = 0.9111 (epoch 106)\n",
            "Configuration 8 completed in 103.1s\n",
            "\n",
            "Configuration 9/12: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 115, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "Training set size: 4482\n",
            "Validation set size: 1440\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 64, 230], [4, -1, 115]] 460,920        \n",
            "classifier (Linear)       [-1, 3]                      693            \n",
            "===============================================================================\n",
            "Total params: 461,613\n",
            "Trainable params: 461,613\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.7620, F1 Score=0.6463 | Val: Loss=0.4611, F1 Score=0.6768\n",
            "Epoch  10/500 | Train: Loss=0.4683, F1 Score=0.7521 | Val: Loss=0.4332, F1 Score=0.7543\n",
            "Epoch  20/500 | Train: Loss=0.3827, F1 Score=0.8138 | Val: Loss=0.3550, F1 Score=0.7710\n",
            "Epoch  30/500 | Train: Loss=0.3108, F1 Score=0.8383 | Val: Loss=0.2763, F1 Score=0.8015\n",
            "Epoch  40/500 | Train: Loss=0.2239, F1 Score=0.8917 | Val: Loss=0.2272, F1 Score=0.8567\n",
            "Epoch  50/500 | Train: Loss=0.1944, F1 Score=0.9133 | Val: Loss=0.2146, F1 Score=0.8728\n",
            "Epoch  60/500 | Train: Loss=0.2042, F1 Score=0.9229 | Val: Loss=0.2381, F1 Score=0.8826\n",
            "Epoch  70/500 | Train: Loss=0.1325, F1 Score=0.9466 | Val: Loss=0.2167, F1 Score=0.8760\n",
            "Epoch  80/500 | Train: Loss=0.1290, F1 Score=0.9498 | Val: Loss=0.2448, F1 Score=0.8600\n",
            "Epoch  90/500 | Train: Loss=0.1160, F1 Score=0.9586 | Val: Loss=0.2381, F1 Score=0.8823\n",
            "Epoch 100/500 | Train: Loss=0.0934, F1 Score=0.9691 | Val: Loss=0.2299, F1 Score=0.8764\n",
            "Epoch 110/500 | Train: Loss=0.0926, F1 Score=0.9663 | Val: Loss=0.2208, F1 Score=0.8953\n",
            "Epoch 120/500 | Train: Loss=0.0804, F1 Score=0.9708 | Val: Loss=0.2311, F1 Score=0.8947\n",
            "Epoch 130/500 | Train: Loss=0.0678, F1 Score=0.9771 | Val: Loss=0.2694, F1 Score=0.8973\n",
            "Epoch 140/500 | Train: Loss=0.0787, F1 Score=0.9722 | Val: Loss=0.2476, F1 Score=0.8933\n",
            "Epoch 150/500 | Train: Loss=0.1249, F1 Score=0.9460 | Val: Loss=0.2330, F1 Score=0.8913\n",
            "Epoch 160/500 | Train: Loss=0.0602, F1 Score=0.9817 | Val: Loss=0.2541, F1 Score=0.8956\n",
            "Epoch 170/500 | Train: Loss=0.0452, F1 Score=0.9898 | Val: Loss=0.3089, F1 Score=0.8975\n",
            "Epoch 180/500 | Train: Loss=0.0621, F1 Score=0.9788 | Val: Loss=0.2840, F1 Score=0.9003\n",
            "Epoch 190/500 | Train: Loss=0.0501, F1 Score=0.9877 | Val: Loss=0.3006, F1 Score=0.8960\n",
            "Epoch 200/500 | Train: Loss=0.1170, F1 Score=0.9527 | Val: Loss=0.4112, F1 Score=0.8321\n",
            "Epoch 210/500 | Train: Loss=0.0479, F1 Score=0.9888 | Val: Loss=0.3378, F1 Score=0.8943\n",
            "Epoch 220/500 | Train: Loss=0.0481, F1 Score=0.9902 | Val: Loss=0.3421, F1 Score=0.8951\n",
            "Early stopping triggered after 221 epochs.\n",
            "Best model restored from epoch 181 with val_f1 0.9184\n",
            "[Run 9] Best val_f1 = 0.9184 (epoch 181)\n",
            "Configuration 9 completed in 157.2s\n",
            "\n",
            "Configuration 10/12: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 120, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "Training set size: 4482\n",
            "Validation set size: 1440\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 64, 240], [4, -1, 120]] 500,160        \n",
            "classifier (Linear)       [-1, 3]                      723            \n",
            "===============================================================================\n",
            "Total params: 500,883\n",
            "Trainable params: 500,883\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.7744, F1 Score=0.6502 | Val: Loss=0.4602, F1 Score=0.6768\n",
            "Epoch  10/500 | Train: Loss=0.4642, F1 Score=0.7564 | Val: Loss=0.3838, F1 Score=0.7600\n",
            "Epoch  20/500 | Train: Loss=0.3613, F1 Score=0.8339 | Val: Loss=0.3445, F1 Score=0.7801\n",
            "Epoch  30/500 | Train: Loss=0.2823, F1 Score=0.8736 | Val: Loss=0.2907, F1 Score=0.8296\n",
            "Epoch  40/500 | Train: Loss=0.2465, F1 Score=0.8931 | Val: Loss=0.2558, F1 Score=0.8477\n",
            "Epoch  50/500 | Train: Loss=0.2015, F1 Score=0.9095 | Val: Loss=0.2193, F1 Score=0.8605\n",
            "Epoch  60/500 | Train: Loss=0.2368, F1 Score=0.8839 | Val: Loss=0.2495, F1 Score=0.8480\n",
            "Epoch  70/500 | Train: Loss=0.1791, F1 Score=0.9207 | Val: Loss=0.2653, F1 Score=0.8745\n",
            "Epoch  80/500 | Train: Loss=0.2454, F1 Score=0.8919 | Val: Loss=0.3015, F1 Score=0.8305\n",
            "Epoch  90/500 | Train: Loss=0.1741, F1 Score=0.9222 | Val: Loss=0.2525, F1 Score=0.8532\n",
            "Epoch 100/500 | Train: Loss=0.2280, F1 Score=0.8906 | Val: Loss=0.2602, F1 Score=0.8555\n",
            "Epoch 110/500 | Train: Loss=0.1228, F1 Score=0.9534 | Val: Loss=0.2509, F1 Score=0.8839\n",
            "Epoch 120/500 | Train: Loss=0.1082, F1 Score=0.9604 | Val: Loss=0.2775, F1 Score=0.8717\n",
            "Epoch 130/500 | Train: Loss=0.1377, F1 Score=0.9444 | Val: Loss=0.2181, F1 Score=0.8931\n",
            "Epoch 140/500 | Train: Loss=0.1264, F1 Score=0.9502 | Val: Loss=0.2663, F1 Score=0.8687\n",
            "Epoch 150/500 | Train: Loss=0.0908, F1 Score=0.9695 | Val: Loss=0.2713, F1 Score=0.8902\n",
            "Epoch 160/500 | Train: Loss=0.0782, F1 Score=0.9755 | Val: Loss=0.2551, F1 Score=0.8954\n",
            "Epoch 170/500 | Train: Loss=0.0816, F1 Score=0.9709 | Val: Loss=0.2647, F1 Score=0.8967\n",
            "Epoch 180/500 | Train: Loss=0.0783, F1 Score=0.9719 | Val: Loss=0.2501, F1 Score=0.9063\n",
            "Epoch 190/500 | Train: Loss=0.1154, F1 Score=0.9532 | Val: Loss=0.2799, F1 Score=0.8887\n",
            "Epoch 200/500 | Train: Loss=0.0751, F1 Score=0.9746 | Val: Loss=0.2534, F1 Score=0.9007\n",
            "Epoch 210/500 | Train: Loss=0.0859, F1 Score=0.9712 | Val: Loss=0.2469, F1 Score=0.8886\n",
            "Epoch 220/500 | Train: Loss=0.1097, F1 Score=0.9501 | Val: Loss=0.2560, F1 Score=0.8819\n",
            "Early stopping triggered after 220 epochs.\n",
            "Best model restored from epoch 180 with val_f1 0.9063\n",
            "[Run 10] Best val_f1 = 0.9063 (epoch 180)\n",
            "Configuration 10 completed in 133.1s\n",
            "\n",
            "Configuration 11/12: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 125, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "Training set size: 4482\n",
            "Validation set size: 1440\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 64, 250], [4, -1, 125]] 541,000        \n",
            "classifier (Linear)       [-1, 3]                      753            \n",
            "===============================================================================\n",
            "Total params: 541,753\n",
            "Trainable params: 541,753\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.7776, F1 Score=0.6503 | Val: Loss=0.4592, F1 Score=0.6768\n",
            "Epoch  10/500 | Train: Loss=0.4763, F1 Score=0.7493 | Val: Loss=0.3801, F1 Score=0.7536\n",
            "Epoch  20/500 | Train: Loss=0.3755, F1 Score=0.8194 | Val: Loss=0.3895, F1 Score=0.7665\n",
            "Epoch  30/500 | Train: Loss=0.3842, F1 Score=0.7944 | Val: Loss=0.3833, F1 Score=0.7412\n",
            "Epoch  40/500 | Train: Loss=0.2532, F1 Score=0.9012 | Val: Loss=0.2778, F1 Score=0.8539\n",
            "Epoch  50/500 | Train: Loss=0.2579, F1 Score=0.8931 | Val: Loss=0.2953, F1 Score=0.8307\n",
            "Epoch  60/500 | Train: Loss=0.2194, F1 Score=0.9162 | Val: Loss=0.4271, F1 Score=0.7377\n",
            "Epoch  70/500 | Train: Loss=0.2267, F1 Score=0.9051 | Val: Loss=0.2352, F1 Score=0.8700\n",
            "Epoch  80/500 | Train: Loss=0.1683, F1 Score=0.9334 | Val: Loss=0.2252, F1 Score=0.8757\n",
            "Epoch  90/500 | Train: Loss=0.1620, F1 Score=0.9291 | Val: Loss=0.2474, F1 Score=0.8515\n",
            "Epoch 100/500 | Train: Loss=0.1148, F1 Score=0.9572 | Val: Loss=0.2410, F1 Score=0.8825\n",
            "Epoch 110/500 | Train: Loss=0.1949, F1 Score=0.9210 | Val: Loss=0.2615, F1 Score=0.8507\n",
            "Epoch 120/500 | Train: Loss=0.1428, F1 Score=0.9403 | Val: Loss=0.2188, F1 Score=0.8846\n",
            "Epoch 130/500 | Train: Loss=0.0928, F1 Score=0.9697 | Val: Loss=0.2638, F1 Score=0.9051\n",
            "Epoch 140/500 | Train: Loss=0.0817, F1 Score=0.9742 | Val: Loss=0.2238, F1 Score=0.9096\n",
            "Epoch 150/500 | Train: Loss=0.0784, F1 Score=0.9708 | Val: Loss=0.2541, F1 Score=0.9068\n",
            "Epoch 160/500 | Train: Loss=0.1544, F1 Score=0.9313 | Val: Loss=0.2179, F1 Score=0.8808\n",
            "Epoch 170/500 | Train: Loss=0.0763, F1 Score=0.9764 | Val: Loss=0.2613, F1 Score=0.9027\n",
            "Epoch 180/500 | Train: Loss=0.0851, F1 Score=0.9750 | Val: Loss=0.3555, F1 Score=0.8802\n",
            "Epoch 190/500 | Train: Loss=0.0703, F1 Score=0.9819 | Val: Loss=0.2760, F1 Score=0.8727\n",
            "Epoch 200/500 | Train: Loss=0.0801, F1 Score=0.9782 | Val: Loss=0.2424, F1 Score=0.9018\n",
            "Epoch 210/500 | Train: Loss=0.0749, F1 Score=0.9802 | Val: Loss=0.2882, F1 Score=0.9063\n",
            "Early stopping triggered after 219 epochs.\n",
            "Best model restored from epoch 179 with val_f1 0.9124\n",
            "[Run 11] Best val_f1 = 0.9124 (epoch 179)\n",
            "Configuration 11 completed in 160.9s\n",
            "\n",
            "Configuration 12/12: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 130, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "Training set size: 4482\n",
            "Validation set size: 1440\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 64, 260], [4, -1, 130]] 583,440        \n",
            "classifier (Linear)       [-1, 3]                      783            \n",
            "===============================================================================\n",
            "Total params: 584,223\n",
            "Trainable params: 584,223\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 500 epochs...\n",
            "Epoch   1/500 | Train: Loss=0.7922, F1 Score=0.6530 | Val: Loss=0.4511, F1 Score=0.6768\n",
            "Epoch  10/500 | Train: Loss=0.4830, F1 Score=0.7248 | Val: Loss=0.4033, F1 Score=0.7492\n",
            "Epoch  20/500 | Train: Loss=0.3603, F1 Score=0.8449 | Val: Loss=0.3778, F1 Score=0.7808\n",
            "Epoch  30/500 | Train: Loss=0.3106, F1 Score=0.8581 | Val: Loss=0.2845, F1 Score=0.8233\n",
            "Epoch  40/500 | Train: Loss=0.2358, F1 Score=0.9056 | Val: Loss=0.2439, F1 Score=0.8581\n",
            "Epoch  50/500 | Train: Loss=0.2087, F1 Score=0.9081 | Val: Loss=0.2368, F1 Score=0.8585\n",
            "Epoch  60/500 | Train: Loss=0.1648, F1 Score=0.9300 | Val: Loss=0.2168, F1 Score=0.8722\n",
            "Epoch  70/500 | Train: Loss=0.2112, F1 Score=0.8995 | Val: Loss=0.2617, F1 Score=0.8465\n",
            "Epoch  80/500 | Train: Loss=0.1721, F1 Score=0.9318 | Val: Loss=0.3119, F1 Score=0.8494\n",
            "Epoch  90/500 | Train: Loss=0.1357, F1 Score=0.9480 | Val: Loss=0.2846, F1 Score=0.8708\n",
            "Early stopping triggered after 96 epochs.\n",
            "Best model restored from epoch 56 with val_f1 0.8848\n",
            "[Run 12] Best val_f1 = 0.8848 (epoch 56)\n",
            "Configuration 12 completed in 192.6s\n",
            "\n",
            "==================================================\n",
            "                GRID SEARCH COMPLETE\n",
            "==================================================\n",
            "Best run: #9 (epoch 181)\n",
            "Best Validation F1 Score: 0.9184\n",
            "Best Parameters: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.3, 'GAMMA': 1.0, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': 115, 'L1_LAMBDA': 1e-05, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 16, 'WEIGHTS': [1.0, 1.0, 1.0], 'WINDOW': 64}\n",
            "==================================================\n",
            "\n",
            "Grid Search Results Summary:\n",
            " Run  Best_Epoch  Best_Val_F1  Best_Val_Loss  Elapsed_s  BATCH_SIZE  BIDIRECTIONAL CRITERION  DROPOUT_RATE  GAMMA  HIDDEN_LAYERS  HIDDEN_SIZE  L1_LAMBDA  L2_LAMBDA  LEARNING_RATE RNN_TYPE  STRIDE         WEIGHTS  WINDOW\n",
            "   9         181     0.918370       0.240402 157.212220         512           True     FOCAL           0.3    1.0              2          115    0.00001      0.001          0.001     LSTM      16 [1.0, 1.0, 1.0]      64\n",
            "   4         179     0.916428       0.218850 101.818785         512           True     FOCAL           0.3    1.0              2           20    0.00001      0.001          0.001     LSTM      16 [1.0, 1.0, 1.0]      64\n",
            "  11         179     0.912442       0.260294 160.845180         512           True     FOCAL           0.3    1.0              2          125    0.00001      0.001          0.001     LSTM      16 [1.0, 1.0, 1.0]      64\n",
            "   8         106     0.911149       0.254225 103.137581         512           True     FOCAL           0.3    1.0              2          110    0.00001      0.001          0.001     LSTM      16 [1.0, 1.0, 1.0]      64\n",
            "   7         122     0.908333       0.264387 111.903084         512           True     FOCAL           0.3    1.0              2          105    0.00001      0.001          0.001     LSTM      16 [1.0, 1.0, 1.0]      64\n",
            "  10         180     0.906347       0.250130 133.063436         512           True     FOCAL           0.3    1.0              2          120    0.00001      0.001          0.001     LSTM      16 [1.0, 1.0, 1.0]      64\n",
            "   5          95     0.902606       0.199928  63.983780         512           True     FOCAL           0.3    1.0              2           25    0.00001      0.001          0.001     LSTM      16 [1.0, 1.0, 1.0]      64\n",
            "   2         282     0.902295       0.256272 148.652659         512           True     FOCAL           0.3    1.0              2           10    0.00001      0.001          0.001     LSTM      16 [1.0, 1.0, 1.0]      64\n",
            "   3         182     0.896510       0.302297 104.447303         512           True     FOCAL           0.3    1.0              2           15    0.00001      0.001          0.001     LSTM      16 [1.0, 1.0, 1.0]      64\n",
            "   6         154     0.893446       0.233340  91.130058         512           True     FOCAL           0.3    1.0              2           30    0.00001      0.001          0.001     LSTM      16 [1.0, 1.0, 1.0]      64\n",
            "  12          56     0.884785       0.198367 192.592222         512           True     FOCAL           0.3    1.0              2          130    0.00001      0.001          0.001     LSTM      16 [1.0, 1.0, 1.0]      64\n",
            "   1         179     0.844574       0.264170 106.005154         512           True     FOCAL           0.3    1.0              2            5    0.00001      0.001          0.001     LSTM      16 [1.0, 1.0, 1.0]      64\n",
            "\n",
            "Results saved to: ./tensorboard/LSTM_bi_11-11-21-15_grid_results.csv\n",
            "CPU times: user 12min 46s, sys: 4min 48s, total: 17min 34s\n",
            "Wall time: 24min 34s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(f'Running {len(grid)} configurations...')\n",
        "\n",
        "import os, math, copy, time\n",
        "\n",
        "# --- ensure output directories exist ---\n",
        "os.makedirs(str(logs_dir), exist_ok=True)\n",
        "\n",
        "best_val_f1 = float('-inf')\n",
        "best_params = None\n",
        "best_training_history = None\n",
        "best_state_dict = None\n",
        "best_model_path = None\n",
        "best_run_idx = None\n",
        "best_epoch_in_run = None\n",
        "results = []\n",
        "\n",
        "# Re-define FocalLoss class here to ensure it's available\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.ce = nn.CrossEntropyLoss(weight=alpha, reduction='none')\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = self.ce(inputs, targets)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "# Re-define RecurrentClassifier class here to ensure it's available\n",
        "class RecurrentClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Generic RNN classifier (RNN, LSTM, GRU).\n",
        "    Uses the last hidden state for classification.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size,\n",
        "            hidden_size,\n",
        "            num_layers,\n",
        "            num_classes,\n",
        "            rnn_type,        # 'RNN', 'LSTM', or 'GRU'\n",
        "            bidirectional,\n",
        "            dropout_rate=0.2\n",
        "            ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        # Map string name to PyTorch RNN class\n",
        "        rnn_map = {\n",
        "            'RNN': nn.RNN,\n",
        "            'LSTM': nn.LSTM,\n",
        "            'GRU': nn.GRU\n",
        "        }\n",
        "\n",
        "        if rnn_type not in rnn_map:\n",
        "            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
        "\n",
        "        rnn_module = rnn_map[rnn_type]\n",
        "\n",
        "        # Dropout is only applied between layers (if num_layers > 1)\n",
        "        dropout_val = dropout_rate if num_layers > 1 else 0 # dropout between RNN layers, applied for regularization\n",
        "\n",
        "        # Create the recurrent layer\n",
        "        self.rnn = rnn_module(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,       # Input shape: (batch, seq_len, features)\n",
        "            bidirectional=bidirectional, # We are defining a bidirectional RNN since we want to extract also the future contextual information for making better predictions\n",
        "            dropout=dropout_val\n",
        "        )\n",
        "\n",
        "        # Calculate input size for the final classifier\n",
        "        if self.bidirectional:\n",
        "            classifier_input_size = hidden_size * 2 # Concat fwd + bwd\n",
        "        else:\n",
        "            classifier_input_size = hidden_size\n",
        "\n",
        "        # Final classification layer\n",
        "        self.classifier = nn.Linear(classifier_input_size, num_classes) # output layer for classifying\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x shape: (batch_size, seq_length, input_size)\n",
        "        \"\"\"\n",
        "\n",
        "        # rnn_out shape: (batch_size, seq_len, hidden_size * num_directions)\n",
        "        rnn_out, hidden = self.rnn(x) # feeds the input sequence into the RNN layer\n",
        "        # rnn_out -> contains the hidden state output for every timestep\n",
        "\n",
        "        # LSTM returns (h_n, c_n), we only need h_n\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            hidden = hidden[0]  # final hidden state of the last timestep\n",
        "\n",
        "        # hidden shape: (num_layers * num_directions, batch_size, hidden_size)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            # Reshape to (num_layers, 2, batch_size, hidden_size)\n",
        "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
        "\n",
        "            # Concat last fwd (hidden[-1, 0, ...]) and bwd (hidden[-1, 1, ...])\n",
        "            # Final shape: (batch_size, hidden_size * 2)\n",
        "            hidden_to_classify = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
        "        else:\n",
        "            # Take the last layer's hidden state\n",
        "            # Final shape: (batch_size, hidden_size)\n",
        "            hidden_to_classify = hidden[-1]\n",
        "\n",
        "        # Get logits\n",
        "        logits = self.classifier(hidden_to_classify)\n",
        "        return logits\n",
        "\n",
        "\n",
        "for idx, params in enumerate(grid, 1):\n",
        "    start_time = time.perf_counter()\n",
        "    print(f\"\\nConfiguration {idx}/{len(grid)}: {params}\")\n",
        "    #Set up Criterion\n",
        "    weights = torch.tensor(params['WEIGHTS']).to(device)\n",
        "\n",
        "    if params['CRITERION'] == 'CROSS':\n",
        "      criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "    else:\n",
        "      criterion = FocalLoss(alpha=None, gamma=params['GAMMA'])\n",
        "    #Build Sequence for the grid step\n",
        "    WINDOW_GRID = params['WINDOW']\n",
        "    STRIDE_GRID = params['STRIDE']\n",
        "    # Generate sequences and labels for the training set\n",
        "    X_train, y_train = build_sequences(df_train, WINDOW_GRID, STRIDE_GRID)\n",
        "    # Generate sequences and labels for the validation set\n",
        "    X_val, y_val = build_sequences(df_val, WINDOW_GRID, STRIDE_GRID)\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_val = X_val.astype('float32')\n",
        "    # Define the input shape based on the training data\n",
        "    input_shape = X_train.shape[1:]\n",
        "    # Define the number of classes based on the categorical labels\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    # Discard nan values from the dataset\n",
        "    if np.isnan(X_train).any() or np.isnan(X_val).any() or np.isnan(X_test).any():\n",
        "        X_train = np.nan_to_num(X_train)\n",
        "        X_val = np.nan_to_num(X_val)\n",
        "    train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "    val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "    train_loader = make_loader(train_ds, batch_size=params['BATCH_SIZE'], shuffle=True, drop_last=False)\n",
        "    val_loader   = make_loader(val_ds, batch_size=params['BATCH_SIZE'], shuffle=False, drop_last=False)\n",
        "    print(f\"Training set size: {len(train_ds)}\")\n",
        "    print(f\"Validation set size: {len(val_ds)}\")\n",
        "\n",
        "\n",
        "    # Build model\n",
        "    rnn_model = RecurrentClassifier(\n",
        "        input_size=input_shape[-1],\n",
        "        hidden_size=params['HIDDEN_SIZE'],\n",
        "        num_layers=params['HIDDEN_LAYERS'],\n",
        "        num_classes=num_classes,\n",
        "        dropout_rate=params['DROPOUT_RATE'],\n",
        "        bidirectional=BIDIRECTIONAL,\n",
        "        rnn_type=RNN_TYPE\n",
        "    ).to(device)\n",
        "\n",
        "    # Display architecture summary\n",
        "    try:\n",
        "        recurrent_summary(rnn_model, input_size=input_shape)\n",
        "    except Exception as e:\n",
        "        print(f\"[warn] recurrent_summary failed: {e}\")\n",
        "\n",
        "    # Set up TensorBoard writer\n",
        "    experiment_id = f\"{EXPERIMENT_NAME}_{idx}\"\n",
        "    writer = SummaryWriter(f\"./{logs_dir}/{experiment_id}\")\n",
        "\n",
        "    # Add model graph only once to save time/disk\n",
        "    if idx == 1:\n",
        "        try:\n",
        "            x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n",
        "            x_for_graph = x if getattr(rnn_model, \"batch_first\", True) else x.permute(1, 0, 2)\n",
        "            writer.add_graph(rnn_model, x_for_graph)\n",
        "        except Exception as e:\n",
        "            print(f\"[warn] Skipping add_graph: {e}\")\n",
        "\n",
        "    # Optimizer and AMP scaler\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        rnn_model.parameters(),\n",
        "        lr=params['LEARNING_RATE'],\n",
        "        weight_decay=params['L2_LAMBDA']\n",
        "    )\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "    # --- train model ---\n",
        "    try:\n",
        "        rnn_model, training_history = fit(\n",
        "            model=rnn_model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            l1_lambda=params['L1_LAMBDA'],\n",
        "            l2_lambda=0.0, # Always set to zero because we are applying L2 Regularization in Optimizer\n",
        "            epochs=GRID_EPOCHS,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            scaler=scaler,\n",
        "            device=device,\n",
        "            writer=None, # No Tensorboard saving\n",
        "            verbose=10,\n",
        "            experiment_name=experiment_id,\n",
        "            patience=GRID_PATIENCE\n",
        "        )\n",
        "\n",
        "        # Extract metrics\n",
        "        val_f1_series = [float(v) for v in training_history.get('val_f1', [])\n",
        "                         if isinstance(v, (int, float)) and math.isfinite(v)]\n",
        "        val_loss_series = [float(v) for v in training_history.get('val_loss', [])\n",
        "                           if isinstance(v, (int, float)) and math.isfinite(v)]\n",
        "\n",
        "        if val_f1_series and val_loss_series:\n",
        "            run_best_f1 = max(val_f1_series)\n",
        "            run_best_epoch = val_f1_series.index(run_best_f1) + 1\n",
        "            run_best_val_loss = val_loss_series[run_best_epoch - 1]\n",
        "            elapsed = time.perf_counter() - start_time\n",
        "\n",
        "            print(f\"[Run {idx}] Best val_f1 = {run_best_f1:.4f} (epoch {run_best_epoch})\")\n",
        "\n",
        "            # Save metrics for summary table\n",
        "            results.append({\n",
        "                'Run': idx,\n",
        "                'Best_Epoch': run_best_epoch,\n",
        "                'Best_Val_F1': run_best_f1,\n",
        "                'Best_Val_Loss': run_best_val_loss,\n",
        "                'Elapsed_s': elapsed,\n",
        "                **params\n",
        "            })\n",
        "\n",
        "            # Track best model\n",
        "            if run_best_f1 > best_val_f1:\n",
        "                best_val_f1 = run_best_f1\n",
        "                best_params = params\n",
        "                best_training_history = training_history\n",
        "                best_state_dict = copy.deepcopy(rnn_model.state_dict())\n",
        "                best_run_idx = idx\n",
        "                best_epoch_in_run = run_best_epoch\n",
        "                #best_model_path = f\"./{logs_dir}/{EXPERIMENT_NAME}_best.pt\"\n",
        "                #torch.save(best_state_dict, best_model_path)\n",
        "\n",
        "        else:\n",
        "            print(\"[warn] No valid val_f1 or val_loss values recorded for this run.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[error] Training failed for configuration {idx}: {e}\")\n",
        "\n",
        "    finally:\n",
        "        try:\n",
        "            writer.close()\n",
        "        except Exception:\n",
        "            pass\n",
        "        del optimizer, scaler, rnn_model\n",
        "        if device.type == 'cuda':\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"Configuration {idx} completed in {time.perf_counter() - start_time:.1f}s\")\n",
        "\n",
        "# --- summary ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"                GRID SEARCH COMPLETE\")\n",
        "print(\"=\"*50)\n",
        "if best_params is not None:\n",
        "    print(f\"Best run: #{best_run_idx} (epoch {best_epoch_in_run})\")\n",
        "    print(f\"Best Validation F1 Score: {best_val_f1:.4f}\")\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "    if best_model_path:\n",
        "        print(f\"Best model saved to: {best_model_path}\")\n",
        "else:\n",
        "    print(\"No successful runs (val_f1 was empty or invalid).\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# --- results table ---\n",
        "if results:\n",
        "    df_results = pd.DataFrame(results)\n",
        "    df_results = df_results.sort_values(by='Best_Val_F1', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\nGrid Search Results Summary:\")\n",
        "    print(df_results.to_string(index=False))\n",
        "\n",
        "    # Optionally save results to CSV\n",
        "    results_path = f\"./{logs_dir}/{EXPERIMENT_NAME}_grid_results.csv\"\n",
        "    df_results.to_csv(results_path, index=False)\n",
        "    print(f\"\\nResults saved to: {results_path}\")\n",
        "else:\n",
        "    print(\"No results to display.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FripW_txty5d"
      },
      "source": [
        "## Recap of results and Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_N8-sBKt2DE"
      },
      "outputs": [],
      "source": [
        "results = pd.read_csv(results_path)\n",
        "print(results.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8Q0USqquFWB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set plot style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Plot 1: Best_Val_F1 vs. L1_LAMBDA\n",
        "plt.subplot(4, 2, 1)\n",
        "sns.lineplot(data=results, x='L1_LAMBDA', y='Best_Val_F1', marker='o')\n",
        "plt.title('Best Val F1 vs. L1 Lambda')\n",
        "plt.xlabel('L1 Lambda')\n",
        "plt.ylabel('F1')\n",
        "\n",
        "# Plot 2: Best_Val_F1 vs. L2_LAMBDA\n",
        "plt.subplot(4, 2, 2)\n",
        "sns.lineplot(data=results, x='L2_LAMBDA', y='Best_Val_F1', marker='o')\n",
        "plt.title('Best Val F1 vs. L2 Lambda')\n",
        "plt.xlabel('L2 Lambda')\n",
        "plt.ylabel('F1')\n",
        "\n",
        "# Plot 3: Best_Val_F1 vs. STRIDE\n",
        "plt.subplot(4, 2, 3)\n",
        "sns.lineplot(data=results, x='STRIDE', y='Best_Val_F1', marker='o')\n",
        "plt.title('Best Val F1 vs. Stride')\n",
        "plt.xlabel('Stride')\n",
        "plt.ylabel('F1')\n",
        "\n",
        "# Plot 4: Best_Val_F1 vs. WINDOW\n",
        "plt.subplot(4, 2, 4)\n",
        "sns.lineplot(data=results, x='WINDOW', y='Best_Val_F1', marker='o')\n",
        "plt.title('Best Val F1 vs. Window')\n",
        "plt.xlabel('Window')\n",
        "plt.ylabel('F1')\n",
        "\n",
        "# Plot 5: Best_Val_F1 vs. Hidden Size\n",
        "plt.subplot(4, 2, 5)\n",
        "sns.lineplot(data=results, x='HIDDEN_SIZE', y='Best_Val_F1', marker='o')\n",
        "plt.title('Best Val F1 vs. HIDDEN_SIZE')\n",
        "plt.xlabel('HIDDEN_SIZE')\n",
        "plt.ylabel('F1')\n",
        "\n",
        "# Plot 6: Best_Val_F1 vs. L1_LAMBDA\n",
        "plt.subplot(4, 2, 6)\n",
        "sns.lineplot(data=results, x='HIDDEN_LAYERS', y='Best_Val_F1', marker='o')\n",
        "plt.title('Best Val F1 vs. HIDDEN_LAYERS')\n",
        "plt.xlabel('HIDDEN_LAYERS')\n",
        "plt.ylabel('F1')\n",
        "\n",
        "# Plot 7: Best_Val_F1 vs. L1_LAMBDA\n",
        "plt.subplot(4, 2, 7)\n",
        "sns.lineplot(data=results, x='DROPOUT_RATE', y='Best_Val_F1', marker='o')\n",
        "plt.title('Best Val F1 vs. DROPOUT_RATE')\n",
        "plt.xlabel('DROPOUT_RATE')\n",
        "plt.ylabel('F1')\n",
        "\n",
        "# Plot 8: Best_Val_F1 vs. L1_LAMBDA\n",
        "plt.subplot(4, 2, 8)\n",
        "sns.lineplot(data=results, x='GAMMA', y='Best_Val_F1', marker='o')\n",
        "plt.title('Best Val F1 vs. gamma')\n",
        "plt.xlabel('gamma')\n",
        "plt.ylabel('F1')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn0xjziNo8R5"
      },
      "source": [
        "## 14 Competition Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wi1u77Gtxfe",
        "outputId": "6f98baa9-95a5-4123-bf5a-cd1907b32df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building sequences for actual test dataset with WINDOW_SIZE=64, STRIDE=16\n",
            "Actual test sequences shape: (1324, 200, 37)\n",
            "Number of batches in final test loader: 3\n",
            "Model input size derived from test sequences: 37\n"
          ]
        }
      ],
      "source": [
        "# Build sequences from the actual test data\n",
        "print(f\"Building sequences for actual test dataset with WINDOW_SIZE={WINDOW_SIZE}, STRIDE={STRIDE}\")\n",
        "\n",
        "X_test_sequences = build_sequences_test(X_test_final_df)\n",
        "\n",
        "# Discard nan values from the dataset\n",
        "if np.isnan(X_test_sequences).any():\n",
        "    X_test_sequences = np.nan_to_num(X_test_sequences)\n",
        "    print(\"NaN values found and replaced with 0 in test sequences.\")\n",
        "\n",
        "\n",
        "# Create a TensorDataset from the test sequences (no labels needed for prediction)\n",
        "test_ds_final = TensorDataset(torch.from_numpy(X_test_sequences))\n",
        "\n",
        "# Create a DataLoader for the final test set\n",
        "test_loader_final = make_loader(test_ds_final, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "print(f\"Actual test sequences shape: {X_test_sequences.shape}\")\n",
        "print(f\"Number of batches in final test loader: {len(test_loader_final)}\")\n",
        "\n",
        "\n",
        "# Create model with the correct input size (based on the feature columns used in sequences)\n",
        "actual_input_size = X_test_sequences.shape[-1]\n",
        "print(f\"Model input size derived from test sequences: {actual_input_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "Zhd7Pt3JwILk",
        "outputId": "c8495a5d-62a3-46cc-c3f2-1cd229bc19b4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test_final_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-976236f9-bb0e-485c-95af-a7387af53103\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_20</th>\n",
              "      <th>joint_21</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.561563</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>2.885370e-06</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>2.729749e-05</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>0.014909</td>\n",
              "      <td>0.045098</td>\n",
              "      <td>0.012882</td>\n",
              "      <td>0.010178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.599088</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>2.879201e-06</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>2.123247e-05</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.053679</td>\n",
              "      <td>0.055375</td>\n",
              "      <td>0.013892</td>\n",
              "      <td>0.029085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.638365</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>9.057689e-06</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>3.119309e-05</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.042305</td>\n",
              "      <td>0.039620</td>\n",
              "      <td>0.016286</td>\n",
              "      <td>0.040638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.554938</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>6.191420e-06</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>3.196222e-05</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.037477</td>\n",
              "      <td>0.031101</td>\n",
              "      <td>0.008568</td>\n",
              "      <td>0.018730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.537192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>8.306708e-06</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>2.074579e-05</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.015210</td>\n",
              "      <td>0.019426</td>\n",
              "      <td>0.008189</td>\n",
              "      <td>0.013444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211835</th>\n",
              "      <td>1323.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.746791</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>9.231271e-07</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>2.260549e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009774</td>\n",
              "      <td>0.031095</td>\n",
              "      <td>0.006292</td>\n",
              "      <td>0.070267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211836</th>\n",
              "      <td>1323.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.712191</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>8.987565e-07</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027009</td>\n",
              "      <td>0.049113</td>\n",
              "      <td>0.029173</td>\n",
              "      <td>0.068884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211837</th>\n",
              "      <td>1323.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.778327</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>8.742629e-07</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025910</td>\n",
              "      <td>0.042127</td>\n",
              "      <td>0.011971</td>\n",
              "      <td>0.079291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211838</th>\n",
              "      <td>1323.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.740327</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>8.496463e-07</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.019468</td>\n",
              "      <td>0.015994</td>\n",
              "      <td>0.106760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211839</th>\n",
              "      <td>1323.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.708521</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>8.249084e-07</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033291</td>\n",
              "      <td>0.024055</td>\n",
              "      <td>0.047641</td>\n",
              "      <td>0.099013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>211840 rows √ó 39 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-976236f9-bb0e-485c-95af-a7387af53103')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-976236f9-bb0e-485c-95af-a7387af53103 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-976236f9-bb0e-485c-95af-a7387af53103');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e06d6a2f-90bd-4122-a8ff-8c3ff9bfae1c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e06d6a2f-90bd-4122-a8ff-8c3ff9bfae1c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e06d6a2f-90bd-4122-a8ff-8c3ff9bfae1c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_2877b46d-c35e-4ab4-aedd-7a59c75b00f8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_test_final_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2877b46d-c35e-4ab4-aedd-7a59c75b00f8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_test_final_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        sample_index   time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
              "0                0.0    0.0            1.0            1.0            1.0   \n",
              "1                0.0    1.0            1.0            1.0            1.0   \n",
              "2                0.0    2.0            1.0            1.0            1.0   \n",
              "3                0.0    3.0            0.5            1.0            1.0   \n",
              "4                0.0    4.0            1.0            1.0            1.0   \n",
              "...              ...    ...            ...            ...            ...   \n",
              "211835        1323.0  155.0            1.0            1.0            0.5   \n",
              "211836        1323.0  156.0            0.5            1.0            1.0   \n",
              "211837        1323.0  157.0            0.5            1.0            1.0   \n",
              "211838        1323.0  158.0            1.0            1.0            0.5   \n",
              "211839        1323.0  159.0            0.5            0.0            1.0   \n",
              "\n",
              "        pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...  joint_20  \\\n",
              "0                 1.0     1.0      1.0     1.0  0.561563  ...  0.000015   \n",
              "1                 1.0     1.0      1.0     1.0  0.599088  ...  0.000015   \n",
              "2                 1.0     1.0      1.0     1.0  0.638365  ...  0.000027   \n",
              "3                 1.0     1.0      1.0     1.0  0.554938  ...  0.000015   \n",
              "4                 0.0     1.0      1.0     1.0  0.537192  ...  0.000025   \n",
              "...               ...     ...      ...     ...       ...  ...       ...   \n",
              "211835            1.0     1.0      1.0     1.0  0.746791  ...  0.000025   \n",
              "211836            1.0     1.0      1.0     1.0  0.712191  ...  0.000005   \n",
              "211837            1.0     1.0      1.0     1.0  0.778327  ...  0.000004   \n",
              "211838            1.0     1.0      1.0     1.0  0.740327  ...  0.000004   \n",
              "211839            0.0     1.0      1.0     1.0  0.708521  ...  0.000004   \n",
              "\n",
              "            joint_21  joint_22  joint_23      joint_24  joint_25  joint_26  \\\n",
              "0       2.885370e-06  0.000033  0.000048  2.729749e-05  0.000406  0.014909   \n",
              "1       2.879201e-06  0.000033  0.000060  2.123247e-05  0.000176  0.053679   \n",
              "2       9.057689e-06  0.000033  0.000146  3.119309e-05  0.000049  0.042305   \n",
              "3       6.191420e-06  0.000033  0.000047  3.196222e-05  0.000088  0.037477   \n",
              "4       8.306708e-06  0.000045  0.000047  2.074579e-05  0.000048  0.015210   \n",
              "...              ...       ...       ...           ...       ...       ...   \n",
              "211835  9.231271e-07  0.000010  0.000007  2.260549e-07  0.000000  0.009774   \n",
              "211836  8.987565e-07  0.000010  0.000000  0.000000e+00  0.000000  0.027009   \n",
              "211837  8.742629e-07  0.000030  0.000018  0.000000e+00  0.000000  0.025910   \n",
              "211838  8.496463e-07  0.000041  0.000000  0.000000e+00  0.000000  0.052790   \n",
              "211839  8.249084e-07  0.000010  0.000000  0.000000e+00  0.000000  0.033291   \n",
              "\n",
              "        joint_27  joint_28  joint_29  \n",
              "0       0.045098  0.012882  0.010178  \n",
              "1       0.055375  0.013892  0.029085  \n",
              "2       0.039620  0.016286  0.040638  \n",
              "3       0.031101  0.008568  0.018730  \n",
              "4       0.019426  0.008189  0.013444  \n",
              "...          ...       ...       ...  \n",
              "211835  0.031095  0.006292  0.070267  \n",
              "211836  0.049113  0.029173  0.068884  \n",
              "211837  0.042127  0.011971  0.079291  \n",
              "211838  0.019468  0.015994  0.106760  \n",
              "211839  0.024055  0.047641  0.099013  \n",
              "\n",
              "[211840 rows x 39 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show test_final\n",
        "X_test_final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlqtdvWL5MD6",
        "outputId": "7926f420-e26e-4217-c381-1178bd713e0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model input size derived from test sequences: 37\n",
            "Model created with input_size=37, hidden_size=64\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "rnn (LSTM)                [[-1, 200, 128], [4, -1, 64]] 152,064        \n",
            "classifier (Linear)       [-1, 3]                      387            \n",
            "===============================================================================\n",
            "Total params: 152,451\n",
            "Trainable params: 152,451\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "‚úì Model successfully loaded from models/LSTM_bi_11-11-15-55_model.pt\n",
            "‚úì Model loaded with 152,451 parameters\n",
            "Starting inference on actual test set...\n",
            "Running inference on 3 batches...\n",
            "Batch input shape: torch.Size([512, 200, 37])\n",
            "Expected: (batch_size, 64, 37)\n",
            "Processed batch 3/3\n",
            "\n",
            "Inference on actual test set completed successfully!\n",
            "Total predictions: 1324\n",
            "Predictions shape: (1324,)\n",
            "Probabilities shape: (1324, 3)\n",
            "   sample_index prediction\n",
            "0           0.0    no_pain\n",
            "1           1.0    no_pain\n",
            "2           2.0    no_pain\n",
            "3           3.0    no_pain\n",
            "4           4.0    no_pain\n",
            "‚úÖ Saved submission with 1324 rows should be 1324\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model input size derived from test sequences: {actual_input_size}\")\n",
        "\n",
        "rnn_model = RecurrentClassifier(\n",
        "    input_size=actual_input_size,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    num_layers=HIDDEN_LAYERS,\n",
        "    num_classes=num_classes,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        "    bidirectional=BIDIRECTIONAL,\n",
        "    rnn_type=RNN_TYPE\n",
        "    ).to(device)\n",
        "\n",
        "print(f\"Model created with input_size={actual_input_size}, hidden_size={HIDDEN_SIZE}\")\n",
        "# It's good practice to summarize the model with the actual input shape it will receive\n",
        "recurrent_summary(rnn_model, input_size=X_test_sequences.shape[1:])\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "model_path = MODEL_LOAD_PATH\n",
        "# model_path =\"/gdrive/MyDrive/pirate_dataset/models/LSTM_bi_10-11-22-23.pt\"  # Example hardcoded path\n",
        "\n",
        "\n",
        "try:\n",
        "    # Load the state dict\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    rnn_model.load_state_dict(checkpoint)\n",
        "    print(f\"‚úì Model successfully loaded from {model_path}\")\n",
        "\n",
        "    # Verify model architecture matches\n",
        "    total_params = sum(p.numel() for p in rnn_model.parameters())\n",
        "    print(f\"‚úì Model loaded with {total_params:,} parameters\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚úó ERROR: Model file not found at {model_path}\")\n",
        "    print(\"Please ensure the model was trained and saved properly.\")\n",
        "    print(\"You may need to retrain the model or check the file path.\")\n",
        "    # Exit or handle the error appropriately if the model cannot be loaded\n",
        "\n",
        "except RuntimeError as e:\n",
        "    print(f\"‚úó ERROR: Model architecture mismatch!\")\n",
        "    print(f\"Error details: {str(e)}\")\n",
        "    print(\"\\nThis usually happens when the saved model has a different architecture\")\n",
        "    print(\"than the current model definition (input_size, hidden_size, num_layers, bidirectional).\")\n",
        "    print(\"Please ensure the current model definition matches the saved model.\")\n",
        "    # Re-raise the exception after providing diagnostic information\n",
        "    raise e\n",
        "\n",
        "\n",
        "rnn_model.eval()  # Set model to evaluation mode\n",
        "\n",
        "print(\"Starting inference on actual test set...\")\n",
        "\n",
        "# --- Inference Pipeline ---\n",
        "final_test_preds = []\n",
        "final_test_probabilities = []\n",
        "sample_indices = []\n",
        "\n",
        "print(f\"Running inference on {len(test_loader_final)} batches...\")\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation for inference\n",
        "    for batch_idx, inputs in enumerate(test_loader_final):\n",
        "        # DataLoaders for prediction might return a tuple even with one tensor\n",
        "        xb = inputs[0].to(device)\n",
        "\n",
        "        # Verify batch dimensions\n",
        "        if batch_idx == 0:\n",
        "            print(f\"Batch input shape: {xb.shape}\")\n",
        "            print(f\"Expected: (batch_size, {WINDOW_SIZE}, {actual_input_size})\")\n",
        "\n",
        "        # Get model predictions\n",
        "        logits = rnn_model(xb)\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        # Get probabilities for confidence analysis\n",
        "        probabilities = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "        # Store batch results\n",
        "        final_test_preds.append(preds)\n",
        "        final_test_probabilities.append(probabilities)\n",
        "\n",
        "        # Since test_loader_final is built from sequences, we need to map predictions back to original sample indices\n",
        "        # The indices for this batch correspond to the sequences generated.\n",
        "        # We'll need to figure out the mapping from sequence index to original sample_index later for the submission file.\n",
        "        # For now, just store the predictions.\n",
        "\n",
        "        # Progress indicator\n",
        "        if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(test_loader_final):\n",
        "            print(f\"Processed batch {batch_idx + 1}/{len(test_loader_final)}\")\n",
        "\n",
        "\n",
        "# Combine all batches into single arrays\n",
        "final_test_preds = np.concatenate(final_test_preds)\n",
        "final_test_probabilities = np.concatenate(final_test_probabilities)\n",
        "\n",
        "print(f\"\\nInference on actual test set completed successfully!\")\n",
        "print(f\"Total predictions: {len(final_test_preds)}\")\n",
        "print(f\"Predictions shape: {final_test_preds.shape}\")\n",
        "print(f\"Probabilities shape: {final_test_probabilities.shape}\")\n",
        "\n",
        "\n",
        "# --- Create Submission File ---\n",
        "# Map numerical predictions back to original labels\n",
        "label_map = {0: \"no_pain\", 1: \"low_pain\", 2: \"high_pain\"}\n",
        "pred_labels = [label_map[p] for p in final_test_preds]\n",
        "\n",
        "# The sample_index for the submission file should correspond to the original sample_index from X_test_final_df\n",
        "# Since build_sequences creates multiple sequences per sample_index (if stride < window),\n",
        "# we need to associate each prediction with its original sample_index.\n",
        "# A simple way is to assume each sequence corresponds to the sample_index it came from.\n",
        "# This might not be perfectly accurate if predictions should be per-sample instead of per-sequence.\n",
        "# For this submission, we'll create a submission row for each sequence prediction.\n",
        "\n",
        "# Generate sample indices for the sequences\n",
        "# The number of sequences is len(final_test_preds)\n",
        "# We need to replicate the original sample_indices based on how many sequences were generated per sample.\n",
        "# This requires re-running or adapting the logic from build_sequences to track original indices.\n",
        "\n",
        "# A simpler approach for submission, if predictions are expected per original sample_index,\n",
        "# is to average predictions per sample_index or take the majority vote.\n",
        "# However, the competition usually expects one prediction per sequence/window if the model outputs per sequence.\n",
        "# Let's assume the submission requires one prediction per sequence generated.\n",
        "\n",
        "final_results = [] # Initialize final_results list\n",
        "\n",
        "for sample_id in X_test_final_df['sample_index'].unique():\n",
        "\n",
        "    # extract rows for this sample\n",
        "    temp = X_test_final_df[X_test_final_df['sample_index'] == sample_id]\n",
        "\n",
        "    # If the sample has fewer rows than WINDOW_SIZE, pad it with zeros\n",
        "    if len(temp) < WINDOW_SIZE:\n",
        "        padding = pd.DataFrame(0, index=np.arange(WINDOW_SIZE - len(temp)), columns=temp.columns)\n",
        "        temp = pd.concat([temp, padding], ignore_index=True)\n",
        "\n",
        "    # build sequences for this sample\n",
        "    seqs = build_sequences_test(temp, window=WINDOW_SIZE, stride=STRIDE)  # shape: [num_windows, window, features]\n",
        "\n",
        "    # sometimes build_sequences_test might still return zero sequences if len(temp) < stride\n",
        "    if len(seqs) == 0:\n",
        "        # fallback: take the last WINDOW_SIZE rows\n",
        "        seqs = temp.iloc[-WINDOW_SIZE:].values[np.newaxis, :, :]\n",
        "\n",
        "    seqs = torch.tensor(seqs, dtype=torch.float32).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = rnn_model(seqs)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "\n",
        "    # Final decision for this sample_index\n",
        "    final_class = np.bincount(preds).argmax()  # majority vote\n",
        "    final_results.append({\n",
        "        \"sample_index\": sample_id,\n",
        "        \"prediction\": label_map[final_class]\n",
        "    })\n",
        "\n",
        "submission = pd.DataFrame(final_results)\n",
        "submission.to_csv(SUBMISSION_FILENAME, index=False)\n",
        "\n",
        "print(submission.head())\n",
        "print(f\"‚úÖ Saved submission with {len(submission)} rows should be 1324\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc966286"
      },
      "source": [
        "### 15. Save Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5578b7fe",
        "outputId": "c0271a2e-a7d3-4d87-aadf-936d15bf6b6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model configuration saved to 'models/LSTM_bi_11-11-15-55_config.json'\n",
            "\n",
            "--- Saved Model Configuration ---\n",
            "{\n",
            "    \"EXPERIMENT_NAME\": \"LSTM_bi_11-11-15-55\",\n",
            "    \"RNN_TYPE\": \"LSTM\",\n",
            "    \"BIDIRECTIONAL\": true,\n",
            "    \"input_size\": 37,\n",
            "    \"num_classes\": 3,\n",
            "    \"HIDDEN_SIZE\": 64,\n",
            "    \"HIDDEN_LAYERS\": 2,\n",
            "    \"DROPOUT_RATE\": 0.22,\n",
            "    \"LEARNING_RATE\": 0.001,\n",
            "    \"EPOCHS\": 500,\n",
            "    \"PATIENCE\": 50,\n",
            "    \"L1_LAMBDA\": 1e-06,\n",
            "    \"L2_LAMBDA\": 1e-05,\n",
            "    \"BATCH_SIZE\": 512,\n",
            "    \"WINDOW_SIZE\": 64,\n",
            "    \"STRIDE\": 16,\n",
            "    \"SEED\": 42,\n",
            "    \"one_pirate_window\": true\n",
            "}\n",
            "-----------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Gather all relevant model and training parameters\n",
        "model_config = {\n",
        "    'EXPERIMENT_NAME': EXPERIMENT_NAME,\n",
        "    'RNN_TYPE': RNN_TYPE,\n",
        "    'BIDIRECTIONAL': BIDIRECTIONAL,\n",
        "    'input_size': input_shape[-1],\n",
        "    'num_classes': num_classes,\n",
        "    'HIDDEN_SIZE': HIDDEN_SIZE,\n",
        "    'HIDDEN_LAYERS': HIDDEN_LAYERS,\n",
        "    'DROPOUT_RATE': DROPOUT_RATE,\n",
        "    'LEARNING_RATE': LEARNING_RATE,\n",
        "    'EPOCHS': EPOCHS,\n",
        "    'PATIENCE': PATIENCE,\n",
        "    'L1_LAMBDA': L1_LAMBDA,\n",
        "    'L2_LAMBDA': L2_LAMBDA,\n",
        "    'BATCH_SIZE': BATCH_SIZE,\n",
        "    'WINDOW_SIZE': WINDOW_SIZE,\n",
        "    'STRIDE': STRIDE,\n",
        "    'SEED': SEED,\n",
        "    'one_pirate_window': one_pirate_window,\n",
        "    # 'TEST_F1': f'{test_f1:.4f}'\n",
        "}\n",
        "\n",
        "# Define the path to save the config file\n",
        "config_filepath = os.path.join(models_dir, f\"{EXPERIMENT_NAME}_config.json\")\n",
        "\n",
        "# Save the dictionary as a JSON file\n",
        "with open(config_filepath, 'w') as f:\n",
        "    json.dump(model_config, f, indent=4)\n",
        "\n",
        "print(f\"‚úÖ Model configuration saved to '{config_filepath}'\")\n",
        "\n",
        "# Display the saved configuration\n",
        "print(\"\\n--- Saved Model Configuration ---\")\n",
        "print(json.dumps(model_config, indent=4))\n",
        "print(\"-----------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "m2xyVfs7YAYH",
        "outputId": "9e171b71-278f-4722-d534-10ef8d59a1a8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0dadeffe-44b3-44d3-ac16-b4d1558e734a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_21</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.777046</td>\n",
              "      <td>...</td>\n",
              "      <td>2.426544e-06</td>\n",
              "      <td>1.503263e-06</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.014214</td>\n",
              "      <td>0.011376</td>\n",
              "      <td>0.018978</td>\n",
              "      <td>0.020291</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.805855</td>\n",
              "      <td>...</td>\n",
              "      <td>2.757563e-07</td>\n",
              "      <td>4.403064e-07</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009473</td>\n",
              "      <td>0.010006</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.767110</td>\n",
              "      <td>...</td>\n",
              "      <td>1.063529e-07</td>\n",
              "      <td>1.575589e-08</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.013097</td>\n",
              "      <td>0.006830</td>\n",
              "      <td>0.017065</td>\n",
              "      <td>0.016856</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.665528</td>\n",
              "      <td>...</td>\n",
              "      <td>6.981461e-06</td>\n",
              "      <td>3.352260e-07</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009505</td>\n",
              "      <td>0.006274</td>\n",
              "      <td>0.020264</td>\n",
              "      <td>0.017981</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.773829</td>\n",
              "      <td>...</td>\n",
              "      <td>3.076737e-06</td>\n",
              "      <td>1.885071e-08</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.004216</td>\n",
              "      <td>0.002132</td>\n",
              "      <td>0.023389</td>\n",
              "      <td>0.018477</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.813575</td>\n",
              "      <td>...</td>\n",
              "      <td>7.441192e-07</td>\n",
              "      <td>2.039074e-08</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.004861</td>\n",
              "      <td>0.005427</td>\n",
              "      <td>0.023442</td>\n",
              "      <td>0.017338</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.728054</td>\n",
              "      <td>...</td>\n",
              "      <td>7.452509e-07</td>\n",
              "      <td>2.192577e-08</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.005143</td>\n",
              "      <td>0.005407</td>\n",
              "      <td>0.022523</td>\n",
              "      <td>0.013901</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.737113</td>\n",
              "      <td>...</td>\n",
              "      <td>6.121956e-07</td>\n",
              "      <td>2.345575e-08</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012911</td>\n",
              "      <td>0.004546</td>\n",
              "      <td>0.025178</td>\n",
              "      <td>0.011477</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.698434</td>\n",
              "      <td>...</td>\n",
              "      <td>1.124017e-06</td>\n",
              "      <td>8.497671e-07</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016622</td>\n",
              "      <td>0.007172</td>\n",
              "      <td>0.006115</td>\n",
              "      <td>0.011130</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9 rows √ó 40 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0dadeffe-44b3-44d3-ac16-b4d1558e734a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0dadeffe-44b3-44d3-ac16-b4d1558e734a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0dadeffe-44b3-44d3-ac16-b4d1558e734a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bd3fa5f4-fdca-4ab1-a074-27fa103d6422\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd3fa5f4-fdca-4ab1-a074-27fa103d6422')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bd3fa5f4-fdca-4ab1-a074-27fa103d6422 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
              "0             0     0            1.0            0.0            1.0   \n",
              "1             0     1            1.0            1.0            1.0   \n",
              "2             0     2            1.0            0.0            1.0   \n",
              "3             0     3            1.0            1.0            1.0   \n",
              "4             0     4            1.0            1.0            1.0   \n",
              "5             0     5            1.0            0.0            1.0   \n",
              "6             0     6            1.0            0.5            1.0   \n",
              "7             0     7            1.0            1.0            1.0   \n",
              "8             0     8            1.0            1.0            0.0   \n",
              "\n",
              "   pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...      joint_21  \\\n",
              "0            0.5       2        2       2  0.777046  ...  2.426544e-06   \n",
              "1            1.0       2        2       2  0.805855  ...  2.757563e-07   \n",
              "2            1.0       2        2       2  0.767110  ...  1.063529e-07   \n",
              "3            1.0       2        2       2  0.665528  ...  6.981461e-06   \n",
              "4            1.0       2        2       2  0.773829  ...  3.076737e-06   \n",
              "5            0.5       2        2       2  0.813575  ...  7.441192e-07   \n",
              "6            0.5       2        2       2  0.728054  ...  7.452509e-07   \n",
              "7            1.0       2        2       2  0.737113  ...  6.121956e-07   \n",
              "8            0.5       2        2       2  0.698434  ...  1.124017e-06   \n",
              "\n",
              "       joint_22  joint_23  joint_24  joint_25  joint_26  joint_27  joint_28  \\\n",
              "0  1.503263e-06  0.000105  0.000405  0.000004  0.014214  0.011376  0.018978   \n",
              "1  4.403064e-07  0.000158  0.000001  0.000000  0.010748  0.000000  0.009473   \n",
              "2  1.575589e-08  0.000038  0.000085  0.000003  0.013097  0.006830  0.017065   \n",
              "3  3.352260e-07  0.000049  0.000002  0.000000  0.009505  0.006274  0.020264   \n",
              "4  1.885071e-08  0.000041  0.000002  0.000007  0.004216  0.002132  0.023389   \n",
              "5  2.039074e-08  0.000008  0.000002  0.000008  0.004861  0.005427  0.023442   \n",
              "6  2.192577e-08  0.000052  0.000055  0.000005  0.005143  0.005407  0.022523   \n",
              "7  2.345575e-08  0.000058  0.000052  0.000000  0.012911  0.004546  0.025178   \n",
              "8  8.497671e-07  0.000008  0.000019  0.000000  0.016622  0.007172  0.006115   \n",
              "\n",
              "   joint_29  label  \n",
              "0  0.020291      0  \n",
              "1  0.010006      0  \n",
              "2  0.016856      0  \n",
              "3  0.017981      0  \n",
              "4  0.018477      0  \n",
              "5  0.017338      0  \n",
              "6  0.013901      0  \n",
              "7  0.011477      0  \n",
              "8  0.011130      0  \n",
              "\n",
              "[9 rows x 40 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head(9)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
