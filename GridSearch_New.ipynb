{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy5OeJu9o8Rt"
      },
      "source": [
        "# üè¥‚Äç‚ò†Ô∏è Pirate Pain Classification Challenge\n",
        "\n",
        "> ‚öì *\"Even pirates feel pain ‚Äî let's teach the model to feel it too.\"*\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Table of Contents\n",
        "0. [README](#readme)  \n",
        "1. [Setup & Configuration](#setup)  \n",
        "2. [Data Loading](#data-loading)  \n",
        "3. [Import Libraries](#import-libraries)  \n",
        "4. [Data Preprocessing](#data-preprocessing)  \n",
        "5. [Sequence Building](#sequence-building)  \n",
        "6. [DataLoaders](#dataloaders)  \n",
        "7. [Network Hyperparameters](#hyperparameters)\n",
        "8. [Model Architecture](#model-architecture)  \n",
        "9. [Training Functions](#training-functions)  \n",
        "10. [Model Training](#model-training)  \n",
        "11. [Evaluation & Metrics](#evaluation)  \n",
        "12. [Model Loading & Final Testing](#model-loading)  \n",
        "13. [Competition Submission](#submission)\n",
        "\n",
        "---\n",
        "\n",
        "### ‚öôÔ∏è Quick Configuration Map\n",
        "\n",
        "> üß≠ *\"If ye seek to tweak the code, here be where to look!\"*\n",
        "\n",
        "- üß∫ **Batch Size:** ‚Üí [DataLoaders](#dataloaders)  \n",
        "- ‚öóÔ∏è **Hyperparameters:** ‚Üí [Network Hyperparameters](#hyperparameters)  \n",
        "- ü™û **Window Size & Stride:** ‚Üí [Sequence Building](#sequence-building)  \n",
        "- ‚öôÔ∏è **Model Type:** ‚Üí [Setup & Configuration](#setup)  \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### üí∞ Treasure Storage ‚Äî Models & Submissions\n",
        "> üè¥‚Äç‚ò†Ô∏è *\"A wise pirate always knows where his treasure be buried ‚Äî guard yer models and submissions well!\"*\n",
        "\n",
        "- üíæ **Model & Submission Save/Load Path:** ‚Üí [Setup & Configuration](#setup)  \n",
        "  - üóÇÔ∏è Models be saved in a **`models/`** folder with the name:\n",
        "    **`experiment_name_dd-mm-HH-MM.pt`** (day-month-hour-minute).\n",
        "  - üìú Submissions be saved in a **`submissions/`** folder with the filename format:  \n",
        "    **`experiment_name_dd-mm-HH-MM.csv`** .\n",
        "  - üî° All related model parameters are saved in **`models/`** folder with the  name **`experiment_name_dd-mm-HH-MM_config.json`** .\n",
        "\n",
        "  \n",
        "  *‚ùóThe experiment name is set as **`RnnType_Bi_dd-mm-HH-MM`** or **`RnnType_dd-mm-HH-MM`** depending on if it is bidirectional or not*\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oU_xMZwJUrZ"
      },
      "source": [
        "<a id=\"readme\"></a>\n",
        "## 0. Info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjy_NO-5HPw3"
      },
      "source": [
        "\n",
        "\n",
        "This section lists all the main parameters that can be modified to control data loading, model behavior, and training.\n",
        "\n",
        "---\n",
        "\n",
        "### üìÅ File Paths\n",
        "| Variable | Description | Default Value |\n",
        "|-----------|--------------|----------------|\n",
        "| `TRAIN_DATA_PATH` | Training features | `'pirate_pain_train.csv'` |\n",
        "| `TRAIN_LABELS_PATH` | Training labels | `'pirate_pain_train_labels.csv'` |\n",
        "| `TEST_DATA_PATH` | Test set for inference | `'pirate_pain_test.csv'` *(optional)* |\n",
        "| `MODEL_SAVE_PATH` | Output model file | `'pirate_model.pt'` |\n",
        "| `RESULTS_FILE` | CSV for predictions | `'results_<date-time>.csv'` |\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Model & Architecture\n",
        "| Parameter | Description | Typical Values |\n",
        "|------------|--------------|----------------|\n",
        "| `model_type` | Choose model class | `'RNN'`, `'LSTM'`, `'GRU'`, `'ANN'` |\n",
        "| `input_size` | Number of features per time step | *auto-detected from data* |\n",
        "| `hidden_size` | Hidden layer size | `64`, `128`, `256` |\n",
        "| `num_layers` | Number of RNN layers | `1-4` |\n",
        "| `dropout` | Dropout probability | `0.2‚Äì0.5` |\n",
        "| `num_classes` | Output classes (pain levels) | *from label set* |\n",
        "\n",
        "---\n",
        "\n",
        "### üèãÔ∏è Training Hyperparameters\n",
        "| Parameter | Description | Default / Range |\n",
        "|------------|--------------|-----------------|\n",
        "| `batch_size` | Samples per batch | `512/2^n` |\n",
        "| `learning_rate` | Optimizer learning rate | `1e-3` |\n",
        "| `num_epochs` | Training iterations | `500` |\n",
        "| `optimizer` | Optimization algorithm | `'AdamW'` |\n",
        "| `criterion` | Loss function | `CrossEntropyLoss()` |\n",
        "| `seed` | Random seed for reproducibility | `42` |\n",
        "\n",
        "---\n",
        "\n",
        "### üì§ Inference\n",
        "| Parameter | Description |\n",
        "|------------|--------------|\n",
        "| `LOAD_MODEL_PATH` | Path to pretrained `.pt` model (optional) |\n",
        "| `save_results` | Whether to write output CSV | `True` |\n",
        "\n",
        "---\n",
        "\n",
        "> üí° *Tip:* Adjust hyperparameters in the ‚ÄúConfiguration‚Äù or ‚ÄúTraining Setup‚Äù cell before running the notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZLBQ6tJrcBB"
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "## 1. Setup & Configuration\n",
        "\n",
        "*Optional: Connect to Google Drive (for Colab users)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nig16xZNnmnz",
        "outputId": "db9b87b6-8e0d-45c2-d84c-b051b1ed75de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/MyDrive/pirate_dataset\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")\n",
        "current_dir = \"/gdrive/MyDrive/pirate_dataset\"\n",
        "%cd $current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL1iYHipaeMD"
      },
      "source": [
        "*Set Model Type*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "uWaTlLkTKgk5"
      },
      "outputs": [],
      "source": [
        "RNN_TYPE = 'LSTM'            # 'RNN', 'LSTM', or 'GRU'\n",
        "BIDIRECTIONAL = True        # True / False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up7Qo6v-o8Ru"
      },
      "source": [
        "*Set Model Save Name*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkBnTJHuo8Rv",
        "outputId": "787964b9-1c61-4a57-deb4-6e264644933c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment name: LSTM_bi_12-11-14-45\n",
            "Submission filename: LSTM_bi_12-11-14-45.csv\n",
            "Model save path: models/LSTM_bi_12-11-14-45_model.pt\n",
            "Model load path: models/LSTM_bi_12-11-14-45_model.pt\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get current date and time for submission filename\n",
        "current_datetime = datetime.now().strftime(\"%d-%m-%H-%M\")\n",
        "\n",
        "if BIDIRECTIONAL:\n",
        "    EXPERIMENT_NAME = f\"{RNN_TYPE}_bi_{current_datetime}\"\n",
        "else:\n",
        "    EXPERIMENT_NAME = f\"{RNN_TYPE}_{current_datetime}\"\n",
        "\n",
        "SUBMISSION_FILENAME = f\"{EXPERIMENT_NAME}.csv\"\n",
        "\n",
        "\n",
        "# Directory configuration\n",
        "logs_dir = \"tensorboard\"\n",
        "models_dir = \"models\"\n",
        "\n",
        "# Model save/load paths\n",
        "MODEL_SAVE_PATH = f\"{models_dir}/{EXPERIMENT_NAME}_model.pt\"\n",
        "MODEL_LOAD_PATH = f\"{models_dir}/{EXPERIMENT_NAME}_model.pt\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Experiment name: {EXPERIMENT_NAME}\")\n",
        "print(f\"Submission filename: {SUBMISSION_FILENAME}\")\n",
        "print(f\"Model save path: {MODEL_SAVE_PATH}\")\n",
        "print(f\"Model load path: {MODEL_LOAD_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdaKCgHVvvHX"
      },
      "source": [
        "<a id=\"data-loading\"></a>\n",
        "## 2. Data Loading\n",
        "\n",
        "Load training and test datasets from CSV files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "oLyI938Jvn-J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "X_train = pd.read_csv('pirate_pain_train.csv')\n",
        "y_train = pd.read_csv('pirate_pain_train_labels.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3Lre5NWwCyk"
      },
      "source": [
        "<a id=\"import-libraries\"></a>\n",
        "## 3. Import Libraries\n",
        "\n",
        "Set random seeds for reproducibility and import all necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt3AnE8SwJg1",
        "outputId": "192b8425-7961-428d-9551-3faeda6ebca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "PyTorch version: 2.8.0+cu126\n",
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Set seed for reproducibility\n",
        "SEED = 1122\n",
        "# Import necessary libraries\n",
        "import os\n",
        "\n",
        "# Set environment variables before importing modules\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Import PyTorch\n",
        "import torch\n",
        "torch.manual_seed(SEED)\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!pkill -f tensorboard\n",
        "%load_ext tensorboard\n",
        "!mkdir -p {models_dir}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Import other libraries\n",
        "import copy\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from itertools import product\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix,classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "from itertools import product\n",
        "\n",
        "# Configure plot display settings\n",
        "sns.set(font_scale=1.4)\n",
        "sns.set_style('white')\n",
        "plt.rc('font', size=14)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWnQz-p-xyhD"
      },
      "source": [
        "<a id=\"data-preprocessing\"></a>\n",
        "## 4. Data Preprocessing\n",
        "\n",
        "Explore data, split into train/val/test sets, normalize features, and encode labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPMtvy5Fo8Rw"
      },
      "source": [
        "### 4.1 Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "hHK2Aw7Ix4S8",
        "outputId": "a7604ba4-c509-4a18-b74c-ed6355237ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (105760, 40)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
              "0             0     0              2              0              2   \n",
              "1             0     1              2              2              2   \n",
              "2             0     2              2              0              2   \n",
              "3             0     3              2              2              2   \n",
              "4             0     4              2              2              2   \n",
              "5             0     5              2              0              2   \n",
              "6             0     6              2              1              2   \n",
              "7             0     7              2              2              2   \n",
              "8             0     8              2              2              0   \n",
              "9             0     9              0              2              2   \n",
              "\n",
              "   pain_survey_4 n_legs n_hands n_eyes  joint_00  ...      joint_21  \\\n",
              "0              1    two     two    two  1.094705  ...  3.499558e-06   \n",
              "1              2    two     two    two  1.135183  ...  3.976952e-07   \n",
              "2              2    two     two    two  1.080745  ...  1.533820e-07   \n",
              "3              2    two     two    two  0.938017  ...  1.006865e-05   \n",
              "4              2    two     two    two  1.090185  ...  4.437266e-06   \n",
              "5              1    two     two    two  1.146031  ...  1.073167e-06   \n",
              "6              1    two     two    two  1.025870  ...  1.074800e-06   \n",
              "7              2    two     two    two  1.038597  ...  8.829074e-07   \n",
              "8              1    two     two    two  0.984251  ...  1.621055e-06   \n",
              "9              2    two     two    two  1.054999  ...  1.609114e-06   \n",
              "\n",
              "       joint_22      joint_23      joint_24  joint_25  joint_26  joint_27  \\\n",
              "0  1.945042e-06  3.999558e-06  1.153299e-05  0.000004  0.017592  0.013508   \n",
              "1  6.765107e-07  6.019627e-06  4.643774e-08  0.000000  0.013352  0.000000   \n",
              "2  1.698525e-07  1.446051e-06  2.424536e-06  0.000003  0.016225  0.008110   \n",
              "3  5.511079e-07  1.847597e-06  5.432416e-08  0.000000  0.011832  0.007450   \n",
              "4  1.735459e-07  1.552722e-06  5.825366e-08  0.000007  0.005360  0.002532   \n",
              "5  1.753837e-07  2.957340e-07  6.217311e-08  0.000007  0.006150  0.006444   \n",
              "6  1.772156e-07  1.976558e-06  1.576086e-06  0.000005  0.006495  0.006421   \n",
              "7  1.790415e-07  2.210562e-06  1.485741e-06  0.000000  0.015998  0.005397   \n",
              "8  1.165161e-06  3.030164e-07  5.416678e-07  0.000000  0.020539  0.008517   \n",
              "9  3.959558e-06  2.017157e-06  1.154349e-06  0.000007  0.007682  0.021383   \n",
              "\n",
              "   joint_28  joint_29  joint_30  \n",
              "0  0.026798  0.027815       0.5  \n",
              "1  0.013377  0.013716       0.5  \n",
              "2  0.024097  0.023105       0.5  \n",
              "3  0.028613  0.024648       0.5  \n",
              "4  0.033026  0.025328       0.5  \n",
              "5  0.033101  0.023767       0.5  \n",
              "6  0.031804  0.019056       0.5  \n",
              "7  0.035552  0.015732       0.5  \n",
              "8  0.008635  0.015257       0.5  \n",
              "9  0.034006  0.028966       0.5  \n",
              "\n",
              "[10 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a87c2855-f7a1-4123-a89c-2d684e48ca34\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_21</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "      <th>joint_30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.094705</td>\n",
              "      <td>...</td>\n",
              "      <td>3.499558e-06</td>\n",
              "      <td>1.945042e-06</td>\n",
              "      <td>3.999558e-06</td>\n",
              "      <td>1.153299e-05</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.017592</td>\n",
              "      <td>0.013508</td>\n",
              "      <td>0.026798</td>\n",
              "      <td>0.027815</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.135183</td>\n",
              "      <td>...</td>\n",
              "      <td>3.976952e-07</td>\n",
              "      <td>6.765107e-07</td>\n",
              "      <td>6.019627e-06</td>\n",
              "      <td>4.643774e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013377</td>\n",
              "      <td>0.013716</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.080745</td>\n",
              "      <td>...</td>\n",
              "      <td>1.533820e-07</td>\n",
              "      <td>1.698525e-07</td>\n",
              "      <td>1.446051e-06</td>\n",
              "      <td>2.424536e-06</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.016225</td>\n",
              "      <td>0.008110</td>\n",
              "      <td>0.024097</td>\n",
              "      <td>0.023105</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>0.938017</td>\n",
              "      <td>...</td>\n",
              "      <td>1.006865e-05</td>\n",
              "      <td>5.511079e-07</td>\n",
              "      <td>1.847597e-06</td>\n",
              "      <td>5.432416e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011832</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.028613</td>\n",
              "      <td>0.024648</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.090185</td>\n",
              "      <td>...</td>\n",
              "      <td>4.437266e-06</td>\n",
              "      <td>1.735459e-07</td>\n",
              "      <td>1.552722e-06</td>\n",
              "      <td>5.825366e-08</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.005360</td>\n",
              "      <td>0.002532</td>\n",
              "      <td>0.033026</td>\n",
              "      <td>0.025328</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.146031</td>\n",
              "      <td>...</td>\n",
              "      <td>1.073167e-06</td>\n",
              "      <td>1.753837e-07</td>\n",
              "      <td>2.957340e-07</td>\n",
              "      <td>6.217311e-08</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.006444</td>\n",
              "      <td>0.033101</td>\n",
              "      <td>0.023767</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.025870</td>\n",
              "      <td>...</td>\n",
              "      <td>1.074800e-06</td>\n",
              "      <td>1.772156e-07</td>\n",
              "      <td>1.976558e-06</td>\n",
              "      <td>1.576086e-06</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.006495</td>\n",
              "      <td>0.006421</td>\n",
              "      <td>0.031804</td>\n",
              "      <td>0.019056</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.038597</td>\n",
              "      <td>...</td>\n",
              "      <td>8.829074e-07</td>\n",
              "      <td>1.790415e-07</td>\n",
              "      <td>2.210562e-06</td>\n",
              "      <td>1.485741e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015998</td>\n",
              "      <td>0.005397</td>\n",
              "      <td>0.035552</td>\n",
              "      <td>0.015732</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>0.984251</td>\n",
              "      <td>...</td>\n",
              "      <td>1.621055e-06</td>\n",
              "      <td>1.165161e-06</td>\n",
              "      <td>3.030164e-07</td>\n",
              "      <td>5.416678e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020539</td>\n",
              "      <td>0.008517</td>\n",
              "      <td>0.008635</td>\n",
              "      <td>0.015257</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>1.054999</td>\n",
              "      <td>...</td>\n",
              "      <td>1.609114e-06</td>\n",
              "      <td>3.959558e-06</td>\n",
              "      <td>2.017157e-06</td>\n",
              "      <td>1.154349e-06</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.007682</td>\n",
              "      <td>0.021383</td>\n",
              "      <td>0.034006</td>\n",
              "      <td>0.028966</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows √ó 40 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a87c2855-f7a1-4123-a89c-2d684e48ca34')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a87c2855-f7a1-4123-a89c-2d684e48ca34 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a87c2855-f7a1-4123-a89c-2d684e48ca34');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-25eab21e-62db-4d73-9e8a-4853a3904ec1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25eab21e-62db-4d73-9e8a-4853a3904ec1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-25eab21e-62db-4d73-9e8a-4853a3904ec1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train"
            }
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "# Print the shape of the dataset\n",
        "print(f\"Dataset shape: {X_train.shape}\")\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlDwxJ38o8Rw"
      },
      "source": [
        "### 4.2 Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "LfBKIdsrQDW3"
      },
      "outputs": [],
      "source": [
        "# Merge features and labels\n",
        "data = X_train.merge(y_train, on='sample_index')\n",
        "\n",
        "# Create a mapping dictionary to convert categorical labels to numerical values\n",
        "map_dict_legs = { 'two': 2, 'one+peg_leg': 1}\n",
        "map_dict_hands = { 'two': 2, 'one+hook_hand': 1}\n",
        "map_dict_eyes = { 'two': 2, 'one+eye_patch': 1}\n",
        "data['n_legs'] = data['n_legs'].map(map_dict_legs)\n",
        "data['n_hands'] = data['n_hands'].map(map_dict_hands)\n",
        "data['n_eyes'] = data['n_eyes'].map(map_dict_eyes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUwlOzWBo8Rx"
      },
      "source": [
        "### 4.3 Stratified Train/Val/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqptiNjNQDW3",
        "outputId": "23236987-07db-41b2-a129-602ec9b5df43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label proportions:\n",
            "Train:\n",
            " label\n",
            "no_pain      0.771971\n",
            "low_pain     0.142518\n",
            "high_pain    0.085511\n",
            "Name: proportion, dtype: float64\n",
            "Val:\n",
            " label\n",
            "no_pain      0.775000\n",
            "low_pain     0.141667\n",
            "high_pain    0.083333\n",
            "Name: proportion, dtype: float64\n",
            "Test:\n",
            " label\n",
            "no_pain      0.775000\n",
            "low_pain     0.141667\n",
            "high_pain    0.083333\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# df has columns: ['sample_index', 'label']\n",
        "N_VAL_USERS = 120\n",
        "N_TEST_USERS = 120\n",
        "\n",
        "# --- Step 1: Compute each user's dominant label (or label distribution)\n",
        "user_labels = (\n",
        "    data.groupby('sample_index')['label']\n",
        "    .agg(lambda x: x.value_counts().index[0])  # dominant label per user\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "train_users, temp_users = train_test_split(\n",
        "    user_labels['sample_index'],\n",
        "    test_size=(N_VAL_USERS + N_TEST_USERS) / len(user_labels),\n",
        "    stratify=user_labels['label'],\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "# Split temp into val/test (also stratified)\n",
        "temp_labels = user_labels[user_labels['sample_index'].isin(temp_users)]\n",
        "if N_TEST_USERS != 0:\n",
        "  val_users, test_users = train_test_split(\n",
        "      temp_labels['sample_index'],\n",
        "      test_size=N_TEST_USERS / (N_VAL_USERS + N_TEST_USERS),\n",
        "      stratify=temp_labels['label'],\n",
        "      random_state=SEED\n",
        "  )\n",
        "else:\n",
        "  val_users = temp_users\n",
        "  test_users = []\n",
        "\n",
        "# --- Step 3: Filter your main df\n",
        "df_train = data[data['sample_index'].isin(train_users)]\n",
        "df_val = data[data['sample_index'].isin(val_users)]\n",
        "df_test = data[data['sample_index'].isin(test_users)]\n",
        "\n",
        "# --- Step 4: Check label proportions\n",
        "print(\"Label proportions:\")\n",
        "print(\"Train:\\n\", df_train['label'].value_counts(normalize=True))\n",
        "print(\"Val:\\n\", df_val['label'].value_counts(normalize=True))\n",
        "print(\"Test:\\n\", df_test['label'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI13WygTQDW4",
        "outputId": "9f82f965-41fd-4f95-b5cb-a5bcdad63a18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((67360, 41), (19200, 41), (19200, 41))"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsE1KsTTQDW4",
        "outputId": "c56d6794-8834-4d33-a04b-8e54b72cb503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pirates in training set: 421\n",
            "Total pirates in validation set: 120\n",
            "Total pirates in test set: 120\n"
          ]
        }
      ],
      "source": [
        "# Print the total number of pirates for each dataset\n",
        "print(f\"Total pirates in training set: {df_train['sample_index'].nunique()}\")\n",
        "print(f\"Total pirates in validation set: {df_val['sample_index'].nunique()}\")\n",
        "print(f\"Total pirates in test set: {df_test['sample_index'].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9Pp8l1bo8Rx"
      },
      "source": [
        "### 4.4 Feature Normalization (min-max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "YkF51CmhQDW5"
      },
      "outputs": [],
      "source": [
        "# Define the columns to be normalised\n",
        "\n",
        "scale_columns = [\n",
        "    col for col in data.columns\n",
        "    if (col.startswith('joint_') or col.startswith('pain_survey')) and not col.startswith('joint_30')\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the minimum and maximum values from the training data only\n",
        "mins_train = df_train[scale_columns].min()\n",
        "maxs_train = df_train[scale_columns].max()\n",
        "\n",
        "#mins_val = df_val[scale_columns].min()\n",
        "#maxs_val = df_val[scale_columns].max()\n",
        "#\n",
        "#mins_test = df_test[scale_columns].min()\n",
        "#maxs_test = df_test[scale_columns].max()\n",
        "\n",
        "####\n",
        "#CHANGED ALL THE REGULARIZATION TO USE MIN AND MAX VALUES FROM THE TRAINING DATA FOR GENERALIZATION\n",
        "###\n",
        "\n",
        "# Apply normalisation to the specified columns in all datasets\n",
        "for column in scale_columns:\n",
        "    denom = maxs_train[column] - mins_train[column]\n",
        "    if np.isclose(denom, 0.0):\n",
        "        df_train[column] = 0.0\n",
        "        df_val[column] = 0.0\n",
        "        df_test[column] = 0.0\n",
        "        continue\n",
        "\n",
        "    # Normalise the training set\n",
        "    df_train[column] = (df_train[column] - mins_train[column]) / denom\n",
        "\n",
        "    # Normalise the validation set\n",
        "    df_val[column] = (df_val[column] - mins_train[column]) / denom\n",
        "\n",
        "    # Normalise the test set\n",
        "    df_test[column] = (df_test[column] - mins_train[column]) / denom\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "4gQk4AVMBVuD",
        "outputId": "95fd07f4-d6eb-4e3d-f0ac-45bc15393b0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
              "0             0     0            1.0            0.0            1.0   \n",
              "1             0     1            1.0            1.0            1.0   \n",
              "2             0     2            1.0            0.0            1.0   \n",
              "3             0     3            1.0            1.0            1.0   \n",
              "4             0     4            1.0            1.0            1.0   \n",
              "5             0     5            1.0            0.0            1.0   \n",
              "6             0     6            1.0            0.5            1.0   \n",
              "7             0     7            1.0            1.0            1.0   \n",
              "8             0     8            1.0            1.0            0.0   \n",
              "\n",
              "   pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...      joint_22  \\\n",
              "0            0.5       2        2       2  0.777507  ...  1.374706e-06   \n",
              "1            1.0       2        2       2  0.806256  ...  4.026521e-07   \n",
              "2            1.0       2        2       2  0.767592  ...  1.440847e-08   \n",
              "3            1.0       2        2       2  0.666220  ...  3.065580e-07   \n",
              "4            1.0       2        2       2  0.774297  ...  1.723863e-08   \n",
              "5            0.5       2        2       2  0.813961  ...  1.864695e-08   \n",
              "6            0.5       2        2       2  0.728617  ...  2.005071e-08   \n",
              "7            1.0       2        2       2  0.737657  ...  2.144985e-08   \n",
              "8            0.5       2        2       2  0.699058  ...  7.770963e-07   \n",
              "\n",
              "   joint_23      joint_24  joint_25  joint_26  joint_27  joint_28  joint_29  \\\n",
              "0  0.000015  3.162813e-04  0.000004  0.014214  0.011376  0.018978  0.024117   \n",
              "1  0.000022  9.828599e-07  0.000000  0.010748  0.000000  0.009473  0.011892   \n",
              "2  0.000005  6.626013e-05  0.000003  0.013097  0.006830  0.017065  0.020033   \n",
              "3  0.000007  1.199337e-06  0.000000  0.009505  0.006274  0.020264  0.021371   \n",
              "4  0.000006  1.307199e-06  0.000007  0.004216  0.002132  0.023389  0.021961   \n",
              "5  0.000001  1.414785e-06  0.000008  0.004861  0.005427  0.023442  0.020607   \n",
              "6  0.000007  4.297072e-05  0.000005  0.005143  0.005407  0.022523  0.016522   \n",
              "7  0.000008  4.049080e-05  0.000000  0.012911  0.004546  0.025178  0.013640   \n",
              "8  0.000001  1.457661e-05  0.000000  0.016622  0.007172  0.006115  0.013229   \n",
              "\n",
              "   joint_30    label  \n",
              "0       0.5  no_pain  \n",
              "1       0.5  no_pain  \n",
              "2       0.5  no_pain  \n",
              "3       0.5  no_pain  \n",
              "4       0.5  no_pain  \n",
              "5       0.5  no_pain  \n",
              "6       0.5  no_pain  \n",
              "7       0.5  no_pain  \n",
              "8       0.5  no_pain  \n",
              "\n",
              "[9 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-811be6a3-522b-47ed-9c8d-2bfa18b00d17\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "      <th>joint_30</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.777507</td>\n",
              "      <td>...</td>\n",
              "      <td>1.374706e-06</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>3.162813e-04</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.014214</td>\n",
              "      <td>0.011376</td>\n",
              "      <td>0.018978</td>\n",
              "      <td>0.024117</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.806256</td>\n",
              "      <td>...</td>\n",
              "      <td>4.026521e-07</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>9.828599e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009473</td>\n",
              "      <td>0.011892</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.767592</td>\n",
              "      <td>...</td>\n",
              "      <td>1.440847e-08</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>6.626013e-05</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.013097</td>\n",
              "      <td>0.006830</td>\n",
              "      <td>0.017065</td>\n",
              "      <td>0.020033</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666220</td>\n",
              "      <td>...</td>\n",
              "      <td>3.065580e-07</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>1.199337e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009505</td>\n",
              "      <td>0.006274</td>\n",
              "      <td>0.020264</td>\n",
              "      <td>0.021371</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.774297</td>\n",
              "      <td>...</td>\n",
              "      <td>1.723863e-08</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>1.307199e-06</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.004216</td>\n",
              "      <td>0.002132</td>\n",
              "      <td>0.023389</td>\n",
              "      <td>0.021961</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.813961</td>\n",
              "      <td>...</td>\n",
              "      <td>1.864695e-08</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>1.414785e-06</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.004861</td>\n",
              "      <td>0.005427</td>\n",
              "      <td>0.023442</td>\n",
              "      <td>0.020607</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.728617</td>\n",
              "      <td>...</td>\n",
              "      <td>2.005071e-08</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>4.297072e-05</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.005143</td>\n",
              "      <td>0.005407</td>\n",
              "      <td>0.022523</td>\n",
              "      <td>0.016522</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.737657</td>\n",
              "      <td>...</td>\n",
              "      <td>2.144985e-08</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>4.049080e-05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012911</td>\n",
              "      <td>0.004546</td>\n",
              "      <td>0.025178</td>\n",
              "      <td>0.013640</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.699058</td>\n",
              "      <td>...</td>\n",
              "      <td>7.770963e-07</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>1.457661e-05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016622</td>\n",
              "      <td>0.007172</td>\n",
              "      <td>0.006115</td>\n",
              "      <td>0.013229</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9 rows √ó 41 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-811be6a3-522b-47ed-9c8d-2bfa18b00d17')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-811be6a3-522b-47ed-9c8d-2bfa18b00d17 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-811be6a3-522b-47ed-9c8d-2bfa18b00d17');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d9991973-015d-4fc1-9f26-3428ebb711a5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9991973-015d-4fc1-9f26-3428ebb711a5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d9991973-015d-4fc1-9f26-3428ebb711a5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "df_train.head(9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "V_1543vlBEqf"
      },
      "outputs": [],
      "source": [
        "# @title  Delete Some Columns Experimental\n",
        "\n",
        "#del_columns = [\n",
        "#    col for col in data.columns\n",
        "#    if not (col.startswith('pain_survey') or col.startswith('sample_index') or col.startswith('label') or col.startswith('time') or\n",
        "#            col.endswith('00') or col.endswith('01') or col.endswith('02') or col.endswith('03') or col.endswith('04') or col.endswith('05')\n",
        "#            or col.endswith('06') or col.endswith('07') or col.endswith('08') or col.endswith('09') or col.endswith('10') or col.endswith('11')\n",
        "#            or col.endswith('12') or col.endswith('25') or col.endswith('26') or col.endswith('27') or col.endswith('28') or col.endswith('29'))\n",
        "#]\n",
        "#\n",
        "#for column in del_columns:\n",
        "#\n",
        "#    # Normalise the training set\n",
        "#    df_train[column] =  0.0\n",
        "#    df_val[column] =  0.0\n",
        "#    df_test[column] =  0.0\n",
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "R-cyjeAuYt4D",
        "outputId": "f9ed6683-e42c-4230-d5ec-fe8c8058bcf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
              "0             0     0            1.0            0.0            1.0   \n",
              "1             0     1            1.0            1.0            1.0   \n",
              "2             0     2            1.0            0.0            1.0   \n",
              "3             0     3            1.0            1.0            1.0   \n",
              "4             0     4            1.0            1.0            1.0   \n",
              "\n",
              "   pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...      joint_22  \\\n",
              "0            0.5       2        2       2  0.777507  ...  1.374706e-06   \n",
              "1            1.0       2        2       2  0.806256  ...  4.026521e-07   \n",
              "2            1.0       2        2       2  0.767592  ...  1.440847e-08   \n",
              "3            1.0       2        2       2  0.666220  ...  3.065580e-07   \n",
              "4            1.0       2        2       2  0.774297  ...  1.723863e-08   \n",
              "\n",
              "   joint_23      joint_24  joint_25  joint_26  joint_27  joint_28  joint_29  \\\n",
              "0  0.000015  3.162813e-04  0.000004  0.014214  0.011376  0.018978  0.024117   \n",
              "1  0.000022  9.828599e-07  0.000000  0.010748  0.000000  0.009473  0.011892   \n",
              "2  0.000005  6.626013e-05  0.000003  0.013097  0.006830  0.017065  0.020033   \n",
              "3  0.000007  1.199337e-06  0.000000  0.009505  0.006274  0.020264  0.021371   \n",
              "4  0.000006  1.307199e-06  0.000007  0.004216  0.002132  0.023389  0.021961   \n",
              "\n",
              "   joint_30    label  \n",
              "0       0.5  no_pain  \n",
              "1       0.5  no_pain  \n",
              "2       0.5  no_pain  \n",
              "3       0.5  no_pain  \n",
              "4       0.5  no_pain  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6997f3d7-61b8-4e8b-9c6c-67d0e5b5bff8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>time</th>\n",
              "      <th>pain_survey_1</th>\n",
              "      <th>pain_survey_2</th>\n",
              "      <th>pain_survey_3</th>\n",
              "      <th>pain_survey_4</th>\n",
              "      <th>n_legs</th>\n",
              "      <th>n_hands</th>\n",
              "      <th>n_eyes</th>\n",
              "      <th>joint_00</th>\n",
              "      <th>...</th>\n",
              "      <th>joint_22</th>\n",
              "      <th>joint_23</th>\n",
              "      <th>joint_24</th>\n",
              "      <th>joint_25</th>\n",
              "      <th>joint_26</th>\n",
              "      <th>joint_27</th>\n",
              "      <th>joint_28</th>\n",
              "      <th>joint_29</th>\n",
              "      <th>joint_30</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.777507</td>\n",
              "      <td>...</td>\n",
              "      <td>1.374706e-06</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>3.162813e-04</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.014214</td>\n",
              "      <td>0.011376</td>\n",
              "      <td>0.018978</td>\n",
              "      <td>0.024117</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.806256</td>\n",
              "      <td>...</td>\n",
              "      <td>4.026521e-07</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>9.828599e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009473</td>\n",
              "      <td>0.011892</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.767592</td>\n",
              "      <td>...</td>\n",
              "      <td>1.440847e-08</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>6.626013e-05</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.013097</td>\n",
              "      <td>0.006830</td>\n",
              "      <td>0.017065</td>\n",
              "      <td>0.020033</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666220</td>\n",
              "      <td>...</td>\n",
              "      <td>3.065580e-07</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>1.199337e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009505</td>\n",
              "      <td>0.006274</td>\n",
              "      <td>0.020264</td>\n",
              "      <td>0.021371</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.774297</td>\n",
              "      <td>...</td>\n",
              "      <td>1.723863e-08</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>1.307199e-06</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.004216</td>\n",
              "      <td>0.002132</td>\n",
              "      <td>0.023389</td>\n",
              "      <td>0.021961</td>\n",
              "      <td>0.5</td>\n",
              "      <td>no_pain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 41 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6997f3d7-61b8-4e8b-9c6c-67d0e5b5bff8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6997f3d7-61b8-4e8b-9c6c-67d0e5b5bff8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6997f3d7-61b8-4e8b-9c6c-67d0e5b5bff8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-42a9f0c6-51c9-4a5a-ae5e-400f10338847\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42a9f0c6-51c9-4a5a-ae5e-400f10338847')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-42a9f0c6-51c9-4a5a-ae5e-400f10338847 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDuw27RUo8Rx"
      },
      "source": [
        "### 4.5 Label Distribution Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDhUJUrkQDW6",
        "outputId": "86ce49c5-f430-4d7c-a7da-1e87d3db736f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training labels: {'no_pain': 325, 'low_pain': 60, 'high_pain': 36}\n",
            "Validation labels: {'no_pain': 93, 'low_pain': 17, 'high_pain': 10}\n",
            "Test labels: {'no_pain': 93, 'low_pain': 17, 'high_pain': 10}\n"
          ]
        }
      ],
      "source": [
        "# Initialise a dictionary to count occurrences of each activity in the training set\n",
        "training_labels = {\n",
        "    'no_pain': 0,\n",
        "    'low_pain': 0,\n",
        "    'high_pain': 0\n",
        "}\n",
        "\n",
        "# Count occurrences of each activity for unique IDs in the training set\n",
        "for id in df_train['sample_index'].unique():\n",
        "    label = df_train[df_train['sample_index'] == id]['label'].values[0]\n",
        "    training_labels[label] += 1\n",
        "\n",
        "\n",
        "# Print the distribution of training labels\n",
        "print('Training labels:', training_labels)\n",
        "\n",
        "# Initialise a dictionary to count occurrences of each activity in the training set\n",
        "val_labels = {\n",
        "    'no_pain': 0,\n",
        "    'low_pain': 0,\n",
        "    'high_pain': 0\n",
        "}\n",
        "\n",
        "# Count occurrences of each activity for unique IDs in the training set\n",
        "for id in df_val['sample_index'].unique():\n",
        "    label = df_val[df_val['sample_index'] == id]['label'].values[0]\n",
        "    val_labels[label] += 1\n",
        "\n",
        "# Print the distribution of validation labels\n",
        "print('Validation labels:', val_labels)\n",
        "\n",
        "# Initialise a dictionary to count occurrences of each activity in the test set\n",
        "test_labels = {\n",
        "    'no_pain': 0,\n",
        "    'low_pain': 0,\n",
        "    'high_pain': 0\n",
        "}\n",
        "\n",
        "# Count occurrences of each activity for unique IDs in the test set\n",
        "for id in df_test['sample_index'].unique():\n",
        "    label = df_test[df_test['sample_index'] == id]['label'].values[0]\n",
        "    test_labels[label] += 1\n",
        "\n",
        "# Print the distribution of test labels\n",
        "print('Test labels:', test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "DT3wxqdLQDW7"
      },
      "outputs": [],
      "source": [
        "# Define a training mapping of label names to integer labels\n",
        "label_mapping = {\n",
        "    'no_pain': 0,\n",
        "    'low_pain': 1,\n",
        "    'high_pain': 2\n",
        "}\n",
        "\n",
        "# Map label names to integers in the training set\n",
        "df_train['label'] = df_train['label'].map(label_mapping)\n",
        "\n",
        "# Map label names to integers in the validation set\n",
        "df_val['label'] = df_val['label'].map(label_mapping)\n",
        "\n",
        "# Map label names to integers in the test set\n",
        "df_test['label'] = df_test['label'].map(label_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc0Ve8LYBYaZ",
        "outputId": "f6a85d05-b96a-4789-cf3a-a10ff8ecf470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
            "0             0     0            1.0            0.0            1.0   \n",
            "1             0     1            1.0            1.0            1.0   \n",
            "2             0     2            1.0            0.0            1.0   \n",
            "\n",
            "   pain_survey_4  n_legs  n_hands  n_eyes  joint_00  ...      joint_22  \\\n",
            "0            0.5       2        2       2  0.777507  ...  1.374706e-06   \n",
            "1            1.0       2        2       2  0.806256  ...  4.026521e-07   \n",
            "2            1.0       2        2       2  0.767592  ...  1.440847e-08   \n",
            "\n",
            "   joint_23      joint_24  joint_25  joint_26  joint_27  joint_28  joint_29  \\\n",
            "0  0.000015  3.162813e-04  0.000004  0.014214  0.011376  0.018978  0.024117   \n",
            "1  0.000022  9.828599e-07  0.000000  0.010748  0.000000  0.009473  0.011892   \n",
            "2  0.000005  6.626013e-05  0.000003  0.013097  0.006830  0.017065  0.020033   \n",
            "\n",
            "   joint_30  label  \n",
            "0       0.5      0  \n",
            "1       0.5      0  \n",
            "2       0.5      0  \n",
            "\n",
            "[3 rows x 41 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df_train.head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOi0Yx5bo8Ry"
      },
      "source": [
        "<a id=\"sequence-building\"></a>\n",
        "## 5. Sequence Building\n",
        "\n",
        "Convert variable-length time-series into fixed-size windows for RNN input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "3qv_eAbDQDW7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define window and stride boolean variable -> if True, during training we will visit more time the same pirate with overlapping windows\n",
        "# if False, each pirate will be visited only once during training\n",
        "one_pirate_window = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "sbmKJyH-QDW7"
      },
      "outputs": [],
      "source": [
        "if one_pirate_window:\n",
        "    # Define the window size\n",
        "    WINDOW_SIZE = 30 # before: 80\n",
        "\n",
        "    # Stride size\n",
        "    STRIDE = 10\n",
        "else:\n",
        "    # Define the window size -> select an higher window size in order to get more pirates\n",
        "    WINDOW_SIZE = 160\n",
        "\n",
        "    # Stride size\n",
        "    STRIDE = 160"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut3JifRfo8Ry"
      },
      "source": [
        "### 5.1 Window & Stride Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUdcu3oGo8Ry"
      },
      "source": [
        "### 5.2 Build Sequences Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "dY-ksbv0QDW8"
      },
      "outputs": [],
      "source": [
        "def build_sequences(df, window=200, stride=200):\n",
        "    assert window % stride == 0\n",
        "\n",
        "    dataset = []\n",
        "    labels = []\n",
        "    ids = []  # <--- NEW: to store pirate/sample IDs\n",
        "\n",
        "    for id in df['sample_index'].unique():\n",
        "        columns = [col for col in df.columns if col not in ['sample_index', 'label', 'time']]\n",
        "        temp = df[df['sample_index'] == id][columns].values\n",
        "        label = df[df['sample_index'] == id]['label'].values[0]\n",
        "\n",
        "        remainder = len(temp) % window\n",
        "        padding_len = (window - remainder) % window\n",
        "        if padding_len:\n",
        "            padding = np.zeros((padding_len, len(columns)), dtype='float32')\n",
        "            temp = np.concatenate((temp, padding))\n",
        "\n",
        "        idx = 0\n",
        "        while idx + window <= len(temp):\n",
        "            dataset.append(temp[idx:idx + window])\n",
        "            labels.append(label)\n",
        "            ids.append(id)  # <--- NEW: add same ID for each window\n",
        "            idx += stride\n",
        "\n",
        "    dataset = np.array(dataset)\n",
        "    labels = np.array(labels)\n",
        "    ids = np.array(ids)  # <--- convert to numpy\n",
        "\n",
        "    return dataset, labels, ids  # <--- UPDATED return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utsTrSH5o8Ry"
      },
      "source": [
        "### 5.3 Generate Sequences for Train/Val/Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPVEgwEmQDW8",
        "outputId": "54c2df5b-632f-4a5c-f528-a78f618d8e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (6736, 30, 38), y_train shape: (6736,)\n",
            "X_val shape: (1920, 30, 38), y_val shape: (1920,)\n",
            "X_test shape: (1920, 30, 38), y_test shape: (1920,)\n"
          ]
        }
      ],
      "source": [
        "# Generate sequences and labels for the training set\n",
        "X_train, y_train, ids_train = build_sequences(df_train, WINDOW_SIZE, STRIDE)\n",
        "\n",
        "# Generate sequences and labels for the validation set\n",
        "X_val, y_val, ids_val = build_sequences(df_val, WINDOW_SIZE, STRIDE)\n",
        "\n",
        "# Generate sequences and labels for the test set\n",
        "X_test, y_test, ids_test = build_sequences(df_test, WINDOW_SIZE, STRIDE)\n",
        "\n",
        "# Print the shapes of the generated datasets and their labels\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jLnJ0YMo8Rz"
      },
      "source": [
        "### 5.4 Data Type Conversion & Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "X1mmtqJwQDW8"
      },
      "outputs": [],
      "source": [
        "# Convert dataset into float32 for PyTorch compatibility\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# y_train = y_train.astype('int64')\n",
        "# y_val = y_val.astype('int64')\n",
        "# y_test = y_test.astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxfz2MegQDW8",
        "outputId": "2dc7131f-4f67-46d4-cf32-77c7cce0bbc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Classes: 3\n"
          ]
        }
      ],
      "source": [
        "# Define the input shape based on the training data\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "# Define the number of classes based on the categorical labels\n",
        "num_classes = len(np.unique(y_train))\n",
        "print(f\"Number of Classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "JcSpP3DBQDW8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Discard nan values from the dataset\n",
        "if np.isnan(X_train).any() or np.isnan(X_val).any() or np.isnan(X_test).any():\n",
        "    X_train = np.nan_to_num(X_train)\n",
        "    X_val = np.nan_to_num(X_val)\n",
        "    X_test = np.nan_to_num(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "s45svGakQDW8"
      },
      "outputs": [],
      "source": [
        "# Convert numpy arrays to PyTorch datasets (pairs features with labels)\n",
        "train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b-SGD2to8Rz"
      },
      "source": [
        "<a id=\"dataloaders\"></a>\n",
        "## 6. DataLoaders\n",
        "\n",
        "Create PyTorch DataLoaders for efficient batching and parallel loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "a2dd26aqQDW8"
      },
      "outputs": [],
      "source": [
        "# Define the batch size, which is the number of samples in each batch\n",
        "BATCH_SIZE = 1024 # we can change it depending on the GPU RAM available (by default 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "8CPWMPHOQDW9"
      },
      "outputs": [],
      "source": [
        "def make_loader(ds, batch_size, shuffle, drop_last):\n",
        "    # Determine optimal number of worker processes for data loading\n",
        "    cpu_cores = os.cpu_count() or 2\n",
        "    num_workers = max(2, min(4, cpu_cores))\n",
        "\n",
        "    # Create DataLoader with performance optimizations\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,  # Faster GPU transfer\n",
        "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
        "        prefetch_factor=4,  # Load 4 batches ahead\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "cPlQI3R8QDW9"
      },
      "outputs": [],
      "source": [
        "# Create data loaders with different settings for each phase\n",
        "train_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "val_loader   = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "test_loader  = make_loader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33LHsppfQDW-",
        "outputId": "142df8cf-3346-4b23-ca13-9fced0fda7f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features batch shape: torch.Size([1024, 30, 38])\n",
            "Labels batch shape: torch.Size([1024])\n"
          ]
        }
      ],
      "source": [
        "# Get one batch from the training data loader\n",
        "for xb, yb in train_loader:\n",
        "    print(\"Features batch shape:\", xb.shape)\n",
        "    print(\"Labels batch shape:\", yb.shape)\n",
        "    break # Stop after getting one batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "Jl4n83GrQDW-"
      },
      "outputs": [],
      "source": [
        "def recurrent_summary(model, input_size):\n",
        "    \"\"\"\n",
        "    Custom summary function that emulates torchinfo's output while correctly\n",
        "    counting parameters for RNN/GRU/LSTM layers.\n",
        "\n",
        "    This function is designed for models whose direct children are\n",
        "    nn.Linear, nn.RNN, nn.GRU, or nn.LSTM layers.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to analyze.\n",
        "        input_size (tuple): Shape of the input tensor (e.g., (seq_len, features)).\n",
        "    \"\"\"\n",
        "\n",
        "    # Dictionary to store output shapes captured by forward hooks\n",
        "    output_shapes = {}\n",
        "    # List to track hook handles for later removal\n",
        "    hooks = []\n",
        "\n",
        "    def get_hook(name):\n",
        "        \"\"\"Factory function to create a forward hook for a specific module.\"\"\"\n",
        "        def hook(module, input, output):\n",
        "            # Handle RNN layer outputs (returns a tuple)\n",
        "            if isinstance(output, tuple):\n",
        "                # output[0]: all hidden states with shape (batch, seq_len, hidden*directions)\n",
        "                shape1 = list(output[0].shape)\n",
        "                shape1[0] = -1  # Replace batch dimension with -1\n",
        "\n",
        "                # output[1]: final hidden state h_n (or tuple (h_n, c_n) for LSTM)\n",
        "                if isinstance(output[1], tuple):  # LSTM case: (h_n, c_n)\n",
        "                    shape2 = list(output[1][0].shape)  # Extract h_n only\n",
        "                else:  # RNN/GRU case: h_n only\n",
        "                    shape2 = list(output[1].shape)\n",
        "\n",
        "                # Replace batch dimension (middle position) with -1\n",
        "                shape2[1] = -1\n",
        "\n",
        "                output_shapes[name] = f\"[{shape1}, {shape2}]\"\n",
        "\n",
        "            # Handle standard layer outputs (e.g., Linear)\n",
        "            else:\n",
        "                shape = list(output.shape)\n",
        "                shape[0] = -1  # Replace batch dimension with -1\n",
        "                output_shapes[name] = f\"{shape}\"\n",
        "        return hook\n",
        "\n",
        "    # 1. Determine the device where model parameters reside\n",
        "    try:\n",
        "        device = next(model.parameters()).device\n",
        "    except StopIteration:\n",
        "        device = torch.device(\"cpu\")  # Fallback for models without parameters\n",
        "\n",
        "    # 2. Create a dummy input tensor with batch_size=1\n",
        "    dummy_input = torch.randn(1, *input_size).to(device)\n",
        "\n",
        "    # 3. Register forward hooks on target layers\n",
        "    # Iterate through direct children of the model (e.g., self.rnn, self.classifier)\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, (nn.Linear, nn.RNN, nn.GRU, nn.LSTM)):\n",
        "            # Register the hook and store its handle for cleanup\n",
        "            hook_handle = module.register_forward_hook(get_hook(name))\n",
        "            hooks.append(hook_handle)\n",
        "\n",
        "    # 4. Execute a dummy forward pass in evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            model(dummy_input)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during dummy forward pass: {e}\")\n",
        "            # Clean up hooks even if an error occurs\n",
        "            for h in hooks:\n",
        "                h.remove()\n",
        "            return\n",
        "\n",
        "    # 5. Remove all registered hooks\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    # --- 6. Print the summary table ---\n",
        "\n",
        "    print(\"-\" * 79)\n",
        "    # Column headers\n",
        "    print(f\"{'Layer (type)':<25} {'Output Shape':<28} {'Param #':<18}\")\n",
        "    print(\"=\" * 79)\n",
        "\n",
        "    total_params = 0\n",
        "    total_trainable_params = 0\n",
        "\n",
        "    # Iterate through modules again to collect and display parameter information\n",
        "    for name, module in model.named_children():\n",
        "        if name in output_shapes:\n",
        "            # Count total and trainable parameters for this module\n",
        "            module_params = sum(p.numel() for p in module.parameters())\n",
        "            trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "\n",
        "            total_params += module_params\n",
        "            total_trainable_params += trainable_params\n",
        "\n",
        "            # Format strings for display\n",
        "            layer_name = f\"{name} ({type(module).__name__})\"\n",
        "            output_shape_str = str(output_shapes[name])\n",
        "            params_str = f\"{trainable_params:,}\"\n",
        "\n",
        "            print(f\"{layer_name:<25} {output_shape_str:<28} {params_str:<15}\")\n",
        "\n",
        "    print(\"=\" * 79)\n",
        "    print(f\"Total params: {total_params:,}\")\n",
        "    print(f\"Trainable params: {total_trainable_params:,}\")\n",
        "    print(f\"Non-trainable params: {total_params - total_trainable_params:,}\")\n",
        "    print(\"-\" * 79)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5VULB4UQDW_"
      },
      "source": [
        "<a id=\"hyperparameters\"></a>\n",
        "## 7. Network Hyperparameters\n",
        "\n",
        "Configure training settings, architecture parameters, and regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "0a183G6zQDW_"
      },
      "outputs": [],
      "source": [
        " # Training configuration\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 500\n",
        "PATIENCE = 40\n",
        "\n",
        "# Architecture\n",
        "HIDDEN_LAYERS = 2        # Hidden layers\n",
        "HIDDEN_SIZE = [32,16,32,16]   # Neurons per layer -> prev hidden size = 128\n",
        "\n",
        "# Regularisation\n",
        "DROPOUT_RATE = 0.5     # Dropout probability\n",
        "\n",
        "# For now disable weight decay\n",
        "L1_LAMBDA = 0.0001       # L1 penalty\n",
        "L2_LAMBDA = 0.001         # L2 penalty\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "weights = torch.tensor([0.8, 1.0, 1.2]).to(device)\n",
        "\n",
        "\n",
        "\n",
        "# TO WEIGHT MORE THE \"MORE DIFFICULT\" CASES AND THE LESS FREQUENT LABELS:\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.ce = nn.CrossEntropyLoss(weight=alpha, reduction='none')\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = self.ce(inputs, targets)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "alpha = None  # None if we don't want to alterate the weights of each label losses (FocalLoss already do it)\n",
        "criterion = FocalLoss(alpha=alpha, gamma=1.3)  # gamma = 0 it's like Crossentropy(), gamma < 1 it's like in between Crossentropy and FocalLoss,\n",
        "                                               # gamma = 1 it's a good compromise, gamma = 1.5 or gamma = 2 to weight so much the less present labels\n",
        "\n",
        "\n",
        "#criterion = nn.CrossEntropyLoss(weight=weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "7-RAXl_BQDXA"
      },
      "outputs": [],
      "source": [
        "# Initialize best model tracking variables\n",
        "best_model = None\n",
        "best_performance = float('-inf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouaaN67Ho8R3"
      },
      "source": [
        "<a id=\"model-architecture\"></a>\n",
        "## 8. Model Architecture\n",
        "\n",
        "Custom RNN/LSTM/GRU classifier with configurable bidirectionality and dropout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4I8vKDBo8R4"
      },
      "source": [
        "### 7.1 Recurrent Classifier Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "6nyxSmz4QDW_"
      },
      "outputs": [],
      "source": [
        "class RecurrentClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Generic RNN classifier (RNN, LSTM, GRU).\n",
        "    Uses the last hidden state for classification.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_size,\n",
        "            hidden_size,\n",
        "            num_layers,\n",
        "            num_classes,\n",
        "            rnn_type=  'LSTM',        # 'RNN', 'LSTM', or 'GRU'\n",
        "            bidirectional=False,\n",
        "            dropout_rate=0.2\n",
        "            ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        # Map string name to PyTorch RNN class\n",
        "        rnn_map = {\n",
        "            'RNN': nn.RNN,\n",
        "            'LSTM': nn.LSTM,\n",
        "            'GRU': nn.GRU\n",
        "        }\n",
        "\n",
        "        if rnn_type not in rnn_map:\n",
        "            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
        "\n",
        "        rnn_module = rnn_map[rnn_type]\n",
        "\n",
        "        # Dropout is only applied between layers (if num_layers > 1)\n",
        "        dropout_val = dropout_rate if num_layers > 1 else 0 # dropout between RNN layers, applied for regularization\n",
        "\n",
        "        # Create the recurrent layer\n",
        "        self.rnn = rnn_module(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,       # Input shape: (batch, seq_len, features)\n",
        "            bidirectional=bidirectional, # We are defining a bidirectional RNN since we want to extract also the future contextual information for making better predictions\n",
        "            dropout=dropout_val\n",
        "        )\n",
        "\n",
        "        # Calculate input size for the final classifier\n",
        "        if self.bidirectional:\n",
        "            classifier_input_size = hidden_size * 2 # Concat fwd + bwd\n",
        "        else:\n",
        "            classifier_input_size = hidden_size\n",
        "\n",
        "        # Final classification layer\n",
        "        self.classifier = nn.Linear(classifier_input_size, num_classes) # output layer for classifying\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x shape: (batch_size, seq_length, input_size)\n",
        "        \"\"\"\n",
        "\n",
        "        # rnn_out shape: (batch_size, seq_len, hidden_size * num_directions)\n",
        "        rnn_out, hidden = self.rnn(x) # feeds the input sequence into the RNN layer\n",
        "        # rnn_out -> contains the hidden state output for every timestep\n",
        "\n",
        "        # LSTM returns (h_n, c_n), we only need h_n\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            hidden = hidden[0]  # final hidden state of the last timestep\n",
        "\n",
        "        # hidden shape: (num_layers * num_directions, batch_size, hidden_size)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            # For bidirectional, hidden states are interleaved:\n",
        "            # [layer_0_fwd, layer_0_bwd, layer_1_fwd, layer_1_bwd, ...]\n",
        "            # We want the last layer's forward and backward states\n",
        "            fwd_hidden = hidden[-2, :, :]  # Last layer, forward direction\n",
        "            bwd_hidden = hidden[-1, :, :]  # Last layer, backward direction\n",
        "            hidden_to_classify = torch.cat([fwd_hidden, bwd_hidden], dim=1)\n",
        "        else:\n",
        "            hidden_to_classify = hidden[-1]\n",
        "\n",
        "        # Get logits\n",
        "        logits = self.classifier(hidden_to_classify)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "r82JJturB8f0"
      },
      "outputs": [],
      "source": [
        "class FlexibleRecurrentClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, num_classes,\n",
        "                 rnn_type='LSTM', bidirectional=False, dropout_rate=0.2,\n",
        "                 use_batch_norm=False):\n",
        "        super().__init__()\n",
        "        assert isinstance(hidden_sizes, (list, tuple)) and len(hidden_sizes) >= 1\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.bidirectional = bidirectional\n",
        "        self.num_layers = len(hidden_sizes)\n",
        "        self.use_batch_norm = use_batch_norm\n",
        "\n",
        "        rnn_map = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}\n",
        "        if rnn_type not in rnn_map:\n",
        "            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
        "\n",
        "        rnn_module = rnn_map[rnn_type]\n",
        "        self.rnns = nn.ModuleList()\n",
        "        self.batch_norms = nn.ModuleList() if use_batch_norm else None\n",
        "\n",
        "        input_dim = input_size\n",
        "        for hidden_dim in hidden_sizes:\n",
        "            self.rnns.append(\n",
        "                rnn_module(\n",
        "                    input_size=input_dim,\n",
        "                    hidden_size=hidden_dim,\n",
        "                    num_layers=1,\n",
        "                    batch_first=True,\n",
        "                    bidirectional=bidirectional,\n",
        "                    dropout=0.0\n",
        "                )\n",
        "            )\n",
        "            output_dim = hidden_dim * (2 if bidirectional else 1)\n",
        "\n",
        "            if use_batch_norm:\n",
        "                self.batch_norms.append(nn.BatchNorm1d(output_dim))\n",
        "\n",
        "            input_dim = output_dim\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (batch_size, seq_len, input_size)\n",
        "        Returns:\n",
        "            logits: (batch_size, num_classes)\n",
        "        \"\"\"\n",
        "        out = x\n",
        "\n",
        "        for i, rnn in enumerate(self.rnns):\n",
        "            out, hidden = rnn(out)\n",
        "\n",
        "            if self.use_batch_norm:\n",
        "                # (batch, seq, features) -> (batch, features, seq)\n",
        "                out = out.transpose(1, 2)\n",
        "                out = self.batch_norms[i](out)\n",
        "                out = out.transpose(1, 2)\n",
        "\n",
        "            out = self.dropout(out)\n",
        "\n",
        "        # Use final timestep output (more common than hidden state)\n",
        "        final_output = out[:, -1, :]  # (batch, hidden_dim * num_directions)\n",
        "\n",
        "        logits = self.classifier(final_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLdCrp-qQDXA"
      },
      "source": [
        "<a id=\"training-functions\"></a>\n",
        "## 9. Training Functions\n",
        "\n",
        "Helper functions for training, validation, logging, and early stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "7QgHx0BHQDXA"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n",
        "    \"\"\"\n",
        "    Perform one complete training epoch through the entire training dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to train\n",
        "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
        "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
        "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
        "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "        l1_lambda (float): Lambda for L1 regularization\n",
        "        l2_lambda (float): Lambda for L2 regularization\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
        "    \"\"\"\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Iterate through training batches\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        # Move data to device (GPU/CPU)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Clear gradients from previous step\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Forward pass with mixed precision (if CUDA available)\n",
        "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "            logits = model(inputs)\n",
        "            loss = criterion(logits, targets)\n",
        "\n",
        "            # Add L1 and L2 regularization\n",
        "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
        "            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
        "            loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n",
        "\n",
        "\n",
        "        # Backward pass with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # Accumulate metrics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        predictions = logits.argmax(dim=1)\n",
        "        all_predictions.append(predictions.cpu().numpy())\n",
        "        all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_f1 = f1_score(\n",
        "        np.concatenate(all_targets),\n",
        "        np.concatenate(all_predictions),\n",
        "        average='weighted'\n",
        "    )\n",
        "\n",
        "    return epoch_loss, epoch_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKsdfMrSo8R4"
      },
      "source": [
        "### 9.1 Train One Epoch Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "eVlcqfzqQDXA"
      },
      "outputs": [],
      "source": [
        "def validate_one_epoch(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Perform one complete validation epoch through the entire validation dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
        "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
        "        criterion (nn.Module): Loss function used to calculate validation loss\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n",
        "\n",
        "    Note:\n",
        "        This function automatically sets the model to evaluation mode and disables\n",
        "        gradient computation for efficiency during validation.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Disable gradient computation for validation\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            # Move data to device\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass with mixed precision (if CUDA available)\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "                logits = model(inputs)\n",
        "                loss = criterion(logits, targets)\n",
        "\n",
        "            # Accumulate metrics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            predictions = logits.argmax(dim=1)\n",
        "            all_predictions.append(predictions.cpu().numpy())\n",
        "            all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate epoch metrics\n",
        "    epoch_loss = running_loss / len(val_loader.dataset)\n",
        "    epoch_accuracy = f1_score(\n",
        "        np.concatenate(all_targets),\n",
        "        np.concatenate(all_predictions),\n",
        "        average='weighted'\n",
        "    )\n",
        "\n",
        "    return epoch_loss, epoch_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAGFlt3Fo8R4"
      },
      "source": [
        "### 9.2 Validate One Epoch Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "dZwJNmCZQDXA"
      },
      "outputs": [],
      "source": [
        "def log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model):\n",
        "    \"\"\"\n",
        "    Log training metrics and model parameters to TensorBoard for visualization.\n",
        "\n",
        "    Args:\n",
        "        writer (SummaryWriter): TensorBoard SummaryWriter object for logging\n",
        "        epoch (int): Current epoch number (used as x-axis in TensorBoard plots)\n",
        "        train_loss (float): Training loss for this epoch\n",
        "        train_f1 (float): Training f1 score for this epoch\n",
        "        val_loss (float): Validation loss for this epoch\n",
        "        val_f1 (float): Validation f1 score for this epoch\n",
        "        model (nn.Module): The neural network model (for logging weights/gradients)\n",
        "\n",
        "    Note:\n",
        "        This function logs scalar metrics (loss/f1 score) and histograms of model\n",
        "        parameters and gradients, which helps monitor training progress and detect\n",
        "        issues like vanishing/exploding gradients.\n",
        "    \"\"\"\n",
        "    # Log scalar metrics\n",
        "    writer.add_scalar('Loss/Training', train_loss, epoch)\n",
        "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
        "    writer.add_scalar('F1/Training', train_f1, epoch)\n",
        "    writer.add_scalar('F1/Validation', val_f1, epoch)\n",
        "\n",
        "    # Log model parameters and gradients\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            # Check if the tensor is not empty before adding a histogram\n",
        "            if param.numel() > 0:\n",
        "                writer.add_histogram(f'{name}/weights', param.data, epoch)\n",
        "            if param.grad is not None:\n",
        "                # Check if the gradient tensor is not empty before adding a histogram\n",
        "                if param.grad.numel() > 0:\n",
        "                    if param.grad is not None and torch.isfinite(param.grad).all():\n",
        "                        writer.add_histogram(f'{name}/gradients', param.grad.data, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOa3T9Pho8R4"
      },
      "source": [
        "### 9.3 Fit  Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "KgpOY62qQDXB"
      },
      "outputs": [],
      "source": [
        "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
        "        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
        "        restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\",save_model=True):\n",
        "    \"\"\"\n",
        "    Train the neural network model on the training data and validate on the validation data.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to train\n",
        "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
        "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
        "        epochs (int): Number of training epochs\n",
        "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
        "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
        "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
        "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
        "        l1_lambda (float): L1 regularization coefficient (default: 0)\n",
        "        l2_lambda (float): L2 regularization coefficient (default: 0)\n",
        "        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n",
        "        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n",
        "        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n",
        "        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n",
        "        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n",
        "        verbose (int, optional): Frequency of printing training progress (default: 10)\n",
        "        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, training_history) - Trained model and metrics history\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize metrics tracking\n",
        "    training_history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_f1': [], 'val_f1': []\n",
        "    }\n",
        "\n",
        "    # Configure early stopping if patience is set\n",
        "    if patience > 0:\n",
        "        patience_counter = 0\n",
        "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
        "        best_epoch = 0\n",
        "\n",
        "    print(f\"Training {epochs} epochs...\")\n",
        "\n",
        "    # Main training loop: iterate through epochs\n",
        "    for epoch in range(1, epochs + 1):\n",
        "\n",
        "        # Forward pass through training data, compute gradients, update weights\n",
        "        train_loss, train_f1 = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n",
        "        )\n",
        "\n",
        "        # Evaluate model on validation data without updating weights\n",
        "        val_loss, val_f1 = validate_one_epoch(\n",
        "            model, val_loader, criterion, device\n",
        "        )\n",
        "\n",
        "        # Store metrics for plotting and analysis\n",
        "        training_history['train_loss'].append(train_loss)\n",
        "        training_history['val_loss'].append(val_loss)\n",
        "        training_history['train_f1'].append(train_f1)\n",
        "        training_history['val_f1'].append(val_f1)\n",
        "\n",
        "        # Write metrics to TensorBoard for visualization\n",
        "        if writer is not None:\n",
        "            log_metrics_to_tensorboard(\n",
        "                writer, epoch, train_loss, train_f1, val_loss, val_f1, model\n",
        "            )\n",
        "\n",
        "        # Print progress every N epochs or on first epoch\n",
        "        if verbose > 0:\n",
        "            if epoch % verbose == 0 or epoch == 1:\n",
        "                print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
        "                    f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n",
        "                    f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n",
        "\n",
        "        # Early stopping logic: monitor metric and save best model\n",
        "        if patience > 0:\n",
        "            current_metric = training_history[evaluation_metric][-1]\n",
        "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
        "\n",
        "            if is_improvement :\n",
        "                best_metric = current_metric\n",
        "                best_val_f1 = val_f1\n",
        "                best_epoch = epoch\n",
        "                if save_model:\n",
        "                  torch.save(model.state_dict(), f\"{models_dir}/{experiment_name}_model.pt\")\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(f\"Early stopping triggered after {epoch} epochs.\")\n",
        "                    break\n",
        "    if restore_best_weights and patience > 0:\n",
        "      print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f} and with val_f1 {best_val_f1}\")\n",
        "    # Restore best model weights if early stopping was used\n",
        "    if restore_best_weights and patience > 0 and save_model:\n",
        "        model.load_state_dict(torch.load(f\"{models_dir}/{experiment_name}_model.pt\"))\n",
        "        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f} and with val_f1 {best_val_f1}\")\n",
        "\n",
        "    # Save final model if no early stopping\n",
        "    if patience == 0 and save_model:\n",
        "        torch.save(model.state_dict(), f\"{models_dir}/{experiment_name}_model.pt\")\n",
        "    if not save_model:\n",
        "        print(\"Model saving turned off.\")\n",
        "\n",
        "    # Close TensorBoard writer\n",
        "    if writer is not None:\n",
        "        writer.close()\n",
        "\n",
        "    return model, training_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8g2Pr_To8R5"
      },
      "source": [
        "### 9.4 Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPFmbTlUasqp",
        "outputId": "29c2b3fa-0056-4f46-ca70-aaef65826a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 4 combinations.\n"
          ]
        }
      ],
      "source": [
        "#@ title Set Parameter Grid\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import copy\n",
        "\n",
        "GRID_EPOCHS = 500\n",
        "GRID_PATIENCE = 40\n",
        "\n",
        "#===========================================\n",
        "###########  SET GRID HERE #################\n",
        "#===========================================\n",
        "\n",
        "base_params = {\n",
        "    'RNN_TYPE': ['LSTM'], # Possible values: LSTM, GRU, RNN\n",
        "    'BIDIRECTIONAL': [True], # Possible values: True/False\n",
        "    'HIDDEN_SIZE': [[64,32,32,32],[64,32,64,32],[64,32,32],[32,32,16,8]],\n",
        "    'HIDDEN_LAYERS': [2],\n",
        "    'LEARNING_RATE': [1e-3],\n",
        "    'DROPOUT_RATE': [0.2],\n",
        "    'BATCH_SIZE': [512],\n",
        "    'L1_LAMBDA': [0.0001],\n",
        "    'L2_LAMBDA': [0.001],\n",
        "    'WINDOW': [6],\n",
        "    'STRIDE': [2],\n",
        "    'CRITERION': ['FOCAL'], # You can also use ['CROSS', 'FOCAL']\n",
        "}\n",
        "\n",
        "# Conditional options\n",
        "weights_options = [[1.0, 1.0, 1.0]]\n",
        "gammas_options = [1.3]\n",
        "\n",
        "# List to hold full parameter grids\n",
        "combined_param_grids = []\n",
        "\n",
        "# Loop through each criterion in base_params['CRITERION']\n",
        "for criterion in base_params['CRITERION']:\n",
        "    config = copy.deepcopy(base_params)\n",
        "    config['CRITERION'] = [criterion]\n",
        "\n",
        "    # Add conditionally depending on the criterion\n",
        "    if criterion == 'CROSS':\n",
        "        config['WEIGHTS'] = weights_options\n",
        "        if 'GAMMA' in config: del config['GAMMA']\n",
        "    elif criterion == 'FOCAL':\n",
        "        config['GAMMA'] = gammas_options\n",
        "        if 'WEIGHTS' in config: del config['WEIGHTS']\n",
        "\n",
        "    combined_param_grids.append(config)\n",
        "\n",
        "# Create full parameter grid\n",
        "grid = list(ParameterGrid(combined_param_grids))\n",
        "\n",
        "print(f\"Generated {len(grid)} combinations.\")\n",
        "results = []\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_grid = pd.DataFrame(grid)\n",
        "print(df_grid.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD03sa7Eb_eb",
        "outputId": "09e17a0d-3d30-4800-9f66-8f7581d8f698"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " BATCH_SIZE  BIDIRECTIONAL CRITERION  DROPOUT_RATE  GAMMA  HIDDEN_LAYERS      HIDDEN_SIZE  L1_LAMBDA  L2_LAMBDA  LEARNING_RATE RNN_TYPE  STRIDE  WINDOW\n",
            "        512           True     FOCAL           0.2    1.3              2 [64, 32, 32, 32]     0.0001      0.001          0.001     LSTM       2       6\n",
            "        512           True     FOCAL           0.2    1.3              2 [64, 32, 64, 32]     0.0001      0.001          0.001     LSTM       2       6\n",
            "        512           True     FOCAL           0.2    1.3              2     [64, 32, 32]     0.0001      0.001          0.001     LSTM       2       6\n",
            "        512           True     FOCAL           0.2    1.3              2  [32, 32, 16, 8]     0.0001      0.001          0.001     LSTM       2       6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00tkWSbCQDXB",
        "outputId": "3318ad6b-17fa-4078-b476-c2578f79a54b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configuration 1/4: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.2, 'GAMMA': 1.3, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': [64, 32, 32, 32], 'L1_LAMBDA': 0.0001, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 2, 'WINDOW': 6}\n",
            "Training set size: 33259\n",
            "Validation set size: 9480\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "classifier (Linear)       [-1, 3]                      195            \n",
            "===============================================================================\n",
            "Total params: 195\n",
            "Trainable params: 195\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 160 epochs...\n",
            "Epoch   1/160 | Train: Loss=1.2465, F1 Score=0.6671 | Val: Loss=0.3814, F1 Score=0.6768\n",
            "Epoch   2/160 | Train: Loss=0.6879, F1 Score=0.6726 | Val: Loss=0.3814, F1 Score=0.6768\n",
            "Epoch   4/160 | Train: Loss=0.4330, F1 Score=0.6726 | Val: Loss=0.3812, F1 Score=0.6768\n",
            "Epoch   6/160 | Train: Loss=0.4015, F1 Score=0.6726 | Val: Loss=0.3723, F1 Score=0.6768\n",
            "Epoch   8/160 | Train: Loss=0.3479, F1 Score=0.7446 | Val: Loss=0.3828, F1 Score=0.6961\n",
            "Epoch  10/160 | Train: Loss=0.3383, F1 Score=0.7557 | Val: Loss=0.3839, F1 Score=0.6901\n",
            "Epoch  12/160 | Train: Loss=0.3309, F1 Score=0.7601 | Val: Loss=0.3863, F1 Score=0.6916\n",
            "Epoch  14/160 | Train: Loss=0.3173, F1 Score=0.7799 | Val: Loss=0.3951, F1 Score=0.7259\n",
            "Epoch  16/160 | Train: Loss=0.3070, F1 Score=0.7918 | Val: Loss=0.3898, F1 Score=0.7259\n",
            "Epoch  18/160 | Train: Loss=0.3020, F1 Score=0.7941 | Val: Loss=0.3971, F1 Score=0.7138\n",
            "Epoch  20/160 | Train: Loss=0.3004, F1 Score=0.7946 | Val: Loss=0.3847, F1 Score=0.7293\n",
            "Epoch  22/160 | Train: Loss=0.2986, F1 Score=0.7954 | Val: Loss=0.3850, F1 Score=0.7312\n",
            "Epoch  24/160 | Train: Loss=0.2959, F1 Score=0.7961 | Val: Loss=0.3812, F1 Score=0.7365\n",
            "Epoch  26/160 | Train: Loss=0.2940, F1 Score=0.7955 | Val: Loss=0.3877, F1 Score=0.7238\n",
            "Early stopping triggered after 26 epochs.\n",
            "Best model restored from epoch 6 with val_loss 0.3723 and with val_f1 0.6767605633802817\n",
            "Model saving turned off.\n",
            "[Run 1] Best val_f1 = 0.7365 (epoch 24)\n",
            "Configuration 1 completed in 70.9s\n",
            "\n",
            "Configuration 2/4: {'BATCH_SIZE': 512, 'BIDIRECTIONAL': True, 'CRITERION': 'FOCAL', 'DROPOUT_RATE': 0.2, 'GAMMA': 1.3, 'HIDDEN_LAYERS': 2, 'HIDDEN_SIZE': [64, 32, 64, 32], 'L1_LAMBDA': 0.0001, 'L2_LAMBDA': 0.001, 'LEARNING_RATE': 0.001, 'RNN_TYPE': 'LSTM', 'STRIDE': 2, 'WINDOW': 6}\n",
            "Training set size: 33259\n",
            "Validation set size: 9480\n",
            "-------------------------------------------------------------------------------\n",
            "Layer (type)              Output Shape                 Param #           \n",
            "===============================================================================\n",
            "classifier (Linear)       [-1, 3]                      195            \n",
            "===============================================================================\n",
            "Total params: 195\n",
            "Trainable params: 195\n",
            "Non-trainable params: 0\n",
            "-------------------------------------------------------------------------------\n",
            "Training 160 epochs...\n",
            "Epoch   1/160 | Train: Loss=1.4314, F1 Score=0.6727 | Val: Loss=0.3813, F1 Score=0.6768\n",
            "Epoch   2/160 | Train: Loss=0.7219, F1 Score=0.6726 | Val: Loss=0.3809, F1 Score=0.6768\n",
            "Epoch   4/160 | Train: Loss=0.4281, F1 Score=0.6726 | Val: Loss=0.3773, F1 Score=0.6768\n",
            "Epoch   6/160 | Train: Loss=0.3546, F1 Score=0.7512 | Val: Loss=0.3772, F1 Score=0.6921\n",
            "Epoch   8/160 | Train: Loss=0.3383, F1 Score=0.7588 | Val: Loss=0.3846, F1 Score=0.6979\n",
            "Epoch  10/160 | Train: Loss=0.3229, F1 Score=0.7777 | Val: Loss=0.3921, F1 Score=0.7299\n",
            "Epoch  12/160 | Train: Loss=0.3095, F1 Score=0.7912 | Val: Loss=0.3812, F1 Score=0.7347\n",
            "Epoch  14/160 | Train: Loss=0.3046, F1 Score=0.7942 | Val: Loss=0.3840, F1 Score=0.7363\n",
            "Epoch  16/160 | Train: Loss=0.3022, F1 Score=0.7955 | Val: Loss=0.3822, F1 Score=0.7376\n",
            "Epoch  18/160 | Train: Loss=0.2997, F1 Score=0.7961 | Val: Loss=0.3749, F1 Score=0.7416\n",
            "Epoch  20/160 | Train: Loss=0.2969, F1 Score=0.7969 | Val: Loss=0.3781, F1 Score=0.7445\n",
            "Epoch  22/160 | Train: Loss=0.2958, F1 Score=0.7966 | Val: Loss=0.3767, F1 Score=0.7447\n"
          ]
        }
      ],
      "source": [
        "import os, math, copy, time\n",
        "\n",
        "# --- ensure output directories exist ---\n",
        "os.makedirs(str(logs_dir), exist_ok=True)\n",
        "\n",
        "best_val_f1 = float('-inf')\n",
        "best_params = None\n",
        "best_training_history = None\n",
        "best_state_dict = None\n",
        "best_model_path = None\n",
        "best_run_idx = None\n",
        "best_epoch_in_run = None\n",
        "results = []\n",
        "\n",
        "\n",
        "for idx, params in enumerate(grid, 1):\n",
        "    start_time = time.perf_counter()\n",
        "    print(f\"\\nConfiguration {idx}/{len(grid)}: {params}\")\n",
        "    #Set up Criterion\n",
        "\n",
        "\n",
        "    if params['CRITERION'] == 'CROSS':\n",
        "      weights = torch.tensor(params['WEIGHTS']).to(device)\n",
        "      criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "    else:\n",
        "      criterion = FocalLoss(alpha=None, gamma=params['GAMMA'])\n",
        "    #Build Sequence for the grid step\n",
        "    WINDOW_GRID = params['WINDOW']\n",
        "    STRIDE_GRID = params['STRIDE']\n",
        "    # Generate sequences and labels for the training set\n",
        "    X_train, y_train, _ = build_sequences(df_train, WINDOW_GRID, STRIDE_GRID) # Unpack all three return values\n",
        "    # Generate sequences and labels for the validation set\n",
        "    X_val, y_val, _ = build_sequences(df_val, WINDOW_GRID, STRIDE_GRID) # Unpack all three return values\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_val = X_val.astype('float32')\n",
        "    # Define the input shape based on the training data\n",
        "    input_shape = X_train.shape[1:]\n",
        "    # Define the number of classes based on the categorical labels\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    # Discard nan values from the dataset\n",
        "    if np.isnan(X_train).any() or np.isnan(X_val).any() or np.isnan(X_test).any():\n",
        "        X_train = np.nan_to_num(X_train)\n",
        "        X_val = np.nan_to_num(X_val)\n",
        "    train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "    val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "    train_loader = make_loader(train_ds, batch_size=params['BATCH_SIZE'], shuffle=True, drop_last=False)\n",
        "    val_loader   = make_loader(val_ds, batch_size=params['BATCH_SIZE'], shuffle=False, drop_last=False)\n",
        "    print(f\"Training set size: {len(train_ds)}\")\n",
        "    print(f\"Validation set size: {len(val_ds)}\")\n",
        "\n",
        "\n",
        "    # Build model\n",
        "    rnn_model = FlexibleRecurrentClassifier(\n",
        "        input_size=input_shape[-1],\n",
        "        hidden_sizes=params['HIDDEN_SIZE'], # Changed from hidden_size to hidden_sizes as per FlexibleRecurrentClassifier init\n",
        "        num_classes=num_classes,\n",
        "        dropout_rate=params['DROPOUT_RATE'],\n",
        "        bidirectional=params['BIDIRECTIONAL'], # Changed from BIDIRECTIONAL to params['BIDIRECTIONAL']\n",
        "        rnn_type=params['RNN_TYPE'] # Changed from RNN_TYPE to params['RNN_TYPE']\n",
        "    ).to(device)\n",
        "\n",
        "    # Display architecture summary\n",
        "    try:\n",
        "        recurrent_summary(rnn_model, input_size=input_shape)\n",
        "    except Exception as e:\n",
        "        print(f\"[warn] recurrent_summary failed: {e}\")\n",
        "\n",
        "    # Set up TensorBoard writer\n",
        "    experiment_id = f\"{EXPERIMENT_NAME}_{idx}\"\n",
        "    writer = SummaryWriter(f\"./{logs_dir}/{experiment_id}\")\n",
        "\n",
        "    # Add model graph only once to save time/disk\n",
        "    if idx == 1:\n",
        "        try:\n",
        "            x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n",
        "            x_for_graph = x if getattr(rnn_model, \"batch_first\", True) else x.permute(1, 0, 2)\n",
        "            writer.add_graph(rnn_model, x_for_graph)\n",
        "        except Exception as e:\n",
        "            print(f\"[warn] Skipping add_graph: {e}\")\n",
        "\n",
        "    # Optimizer and AMP scaler\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        rnn_model.parameters(),\n",
        "        lr=params['LEARNING_RATE'],\n",
        "        weight_decay=params['L2_LAMBDA']\n",
        "    )\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
        "\n",
        "    # --- train model ---\n",
        "    try:\n",
        "        rnn_model, training_history = fit(\n",
        "            model=rnn_model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            l1_lambda=params['L1_LAMBDA'],\n",
        "            l2_lambda=0.0, # Always set to zero because we are applying L2 Regularization in Optimizer\n",
        "            epochs=GRID_EPOCHS,\n",
        "            criterion=criterion,\n",
        "            optimizer=optimizer,\n",
        "            scaler=scaler,\n",
        "            device=device,\n",
        "            writer=None, # No Tensorboard saving\n",
        "            verbose=2,\n",
        "            experiment_name=experiment_id,\n",
        "            patience=GRID_PATIENCE,\n",
        "            evaluation_metric=\"val_loss\",\n",
        "            mode= 'min',\n",
        "            save_model=False # No model saving for grid search runs\n",
        "        )\n",
        "\n",
        "        # Extract metrics\n",
        "        val_f1_series = [float(v) for v in training_history.get('val_f1', [])\n",
        "                         if isinstance(v, (int, float)) and math.isfinite(v)]\n",
        "        val_loss_series = [float(v) for v in training_history.get('val_loss', [])\n",
        "                           if isinstance(v, (int, float)) and math.isfinite(v)]\n",
        "\n",
        "        if val_f1_series and val_loss_series:\n",
        "            run_best_f1 = max(val_f1_series)\n",
        "            run_best_epoch = val_f1_series.index(run_best_f1) + 1\n",
        "            run_best_val_loss = val_loss_series[run_best_epoch - 1]\n",
        "            elapsed = time.perf_counter() - start_time\n",
        "\n",
        "            print(f\"[Run {idx}] Best val_f1 = {run_best_f1:.4f} (epoch {run_best_epoch})\")\n",
        "\n",
        "            # Save metrics for summary table\n",
        "            results.append({\n",
        "                'Run': idx,\n",
        "                'Best_Epoch': run_best_epoch,\n",
        "                'Best_Val_F1': run_best_f1,\n",
        "                'Best_Val_Loss': run_best_val_loss,\n",
        "                'Elapsed_s': elapsed,\n",
        "                **params\n",
        "            })\n",
        "\n",
        "            # Track best model\n",
        "            if run_best_f1 > best_val_f1:\n",
        "                best_val_f1 = run_best_f1\n",
        "                best_params = params\n",
        "                best_training_history = training_history\n",
        "                best_state_dict = copy.deepcopy(rnn_model.state_dict())\n",
        "                best_run_idx = idx\n",
        "                best_epoch_in_run = run_best_epoch\n",
        "                #best_model_path = f\"./{logs_dir}/{EXPERIMENT_NAME}_best.pt\"\n",
        "                #torch.save(best_state_dict, best_model_path)\n",
        "\n",
        "        else:\n",
        "            print(\"[warn] No valid val_f1 or val_loss values recorded for this run.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[error] Training failed for configuration {idx}: {e}\")\n",
        "\n",
        "    finally:\n",
        "        try:\n",
        "            writer.close()\n",
        "        except Exception:\n",
        "            pass\n",
        "        del optimizer, scaler, rnn_model\n",
        "        if device.type == 'cuda':\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"Configuration {idx} completed in {time.perf_counter() - start_time:.1f}s\")\n",
        "\n",
        "# --- summary ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"                GRID SEARCH COMPLETE\")\n",
        "print(\"=\"*50)\n",
        "if best_params is not None:\n",
        "    print(f\"Best run: #{best_run_idx} (epoch {best_epoch_in_run})\")\n",
        "    print(f\"Best Validation F1 Score: {best_val_f1:.4f}\")\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "    if best_model_path:\n",
        "        print(f\"Best model saved to: {best_model_path}\")\n",
        "else:\n",
        "    print(\"No successful runs (val_f1 was empty or invalid).\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# --- results table ---\n",
        "if results:\n",
        "    df_results = pd.DataFrame(results)\n",
        "    df_results = df_results.sort_values(by='Best_Val_F1', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\nGrid Search Results Summary:\")\n",
        "    print(df_results.to_string(index=False))\n",
        "\n",
        "    # Optionally save results to CSV\n",
        "    results_path = f\"./{logs_dir}/{EXPERIMENT_NAME}_grid_results.csv\"\n",
        "    df_results.to_csv(results_path, index=False)\n",
        "    print(f\"\\nResults saved to: {results_path}\")\n",
        "else:\n",
        "    print(\"No results to display.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.read_csv(results_path)\n",
        "print(results.to_string(index=False))"
      ],
      "metadata": {
        "id": "Ozg8OJdZiO_d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}